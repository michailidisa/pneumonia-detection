{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Best_notebook2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "G7UMh8jMRzFV",
        "cSzpNMKE2RBS",
        "AZIlmSvKEWLE",
        "czz_AfPCD_LW",
        "ETDeu8cDNGx-",
        "Q_kxDqMvkbR1",
        "CypbrvSq1esj",
        "vP1yh4MKI8wl",
        "rKWKCHYvJx6A",
        "jqwUHGq0LC35",
        "1tBeyxo348rC",
        "-5n68tdlp-9i",
        "g1pTRhgaqwmd"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7UMh8jMRzFV"
      },
      "source": [
        "# Initial Process to Insert the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vq37k8PjDsM3"
      },
      "source": [
        "Import data through Kaggle to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "5_87vLGsMEwg",
        "outputId": "44cae3ba-6d7d-45d6-aed9-2f0319ca6066"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-6e9eac1e3d4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ls'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'KAGGLE_CONFIG_DIR'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/gdrive/MyDrive/ColabNotebooks/inputs\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#changing the working directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms)\u001b[0m\n\u001b[1;32m    107\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m       \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m       ephemeral=True)\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral)\u001b[0m\n\u001b[1;32m    126\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     _message.blocking_request(\n\u001b[0;32m--> 128\u001b[0;31m         'request_auth', request={'authType': 'dfs_ephemeral'}, timeout_sec=None)\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m   \u001b[0mmountpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    173\u001b[0m   request_id = send_request(\n\u001b[1;32m    174\u001b[0m       request_type, request, parent=parent, expect_reply=True)\n\u001b[0;32m--> 175\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!ls\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/MyDrive/ColabNotebooks/inputs\"\n",
        "#changing the working directory\n",
        "%cd \"/content/gdrive/MyDrive/ColabNotebooks/inputs\"\n",
        "#Check the present working directory using pwd command\n",
        "!pwd\n",
        "\n",
        "#kaggle API file\n",
        "! kaggle competitions download -c detect-pneumonia-spring-2022\n",
        "\n",
        "!ls \n",
        "\n",
        "#unzipping the zip files and deleting the zip files\n",
        "!unzip \\*.zip  && rm *.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BpFztTXdGD6f"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLC8soy-JK3Z"
      },
      "source": [
        "\n",
        "\n",
        "> Indented block\n",
        "\n",
        "\n",
        "*   Resize the pictures to 224 x 224 & RGB & Panding\n",
        "\n",
        "*   Get the labels from the file\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qx7yRnFxI9hl"
      },
      "outputs": [],
      "source": [
        "def load_normal(norm_path, labels_path):\n",
        "    norm_files = np.array(os.listdir(norm_path))\n",
        "    labels = pd.read_csv(labels_path)\n",
        "    \n",
        "    norm_images = []\n",
        "    norm_labels = []\n",
        "    BLACK =[0,0,0]\n",
        "    for image in norm_files:\n",
        "        \n",
        "        #get the label of each image in a list \n",
        "        a = labels[labels[\"file_name\"]==str(image)].index.values\n",
        "        b = labels.iloc[a][\"class_id\"].values\n",
        "        norm_labels.append(b)\n",
        "\n",
        "        #transform the images \n",
        "        path = norm_path + \"/\" + image\n",
        "        image = cv2.imread(path)\n",
        "        im_height, im_width, channels = image.shape\n",
        "        if im_height > im_width:\n",
        "          x2 = im_height - im_width\n",
        "          x1 = 0\n",
        "        else:\n",
        "          x1 = im_width - im_height\n",
        "          x2 = 0\n",
        "        constant= cv2.copyMakeBorder(image,x1,x1,x2,x2,cv2.BORDER_CONSTANT, value=BLACK)        \n",
        "        image = cv2.resize(constant, dsize=(224,224))\n",
        "        norm_images.append(image)\n",
        "\n",
        "        \n",
        "    norm_images = np.array(norm_images)\n",
        "    norm_labels = np.array(norm_labels)\n",
        "    \n",
        "    return norm_images, norm_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSzwP1hAbJhE"
      },
      "outputs": [],
      "source": [
        "def load_normal_test(norm_path):\n",
        "\n",
        "    norm_files = np.array(os.listdir(norm_path))\n",
        "    norm_images = []\n",
        "    image_names = []\n",
        "    BLACK =[0,0,0]\n",
        "\n",
        "    for image in norm_files:\n",
        "        \n",
        "        image_names.append(image)\n",
        "        #transform the images \n",
        "        path = norm_path + \"/\" + image\n",
        "        image = cv2.imread(path)\n",
        "        im_height, im_width, channels = image.shape\n",
        "        if im_height > im_width:\n",
        "          x2 = im_height - im_width\n",
        "          x1 = 0\n",
        "        else:\n",
        "          x1 = im_width - im_height\n",
        "          x2 = 0\n",
        "        constant= cv2.copyMakeBorder(image,x1,x1,x2,x2,cv2.BORDER_CONSTANT, value=BLACK)        \n",
        "        image = cv2.resize(constant, dsize=(224,224))\n",
        "        norm_images.append(image)\n",
        "\n",
        "        \n",
        "    norm_images = np.array(norm_images)\n",
        "    image_names = np.array(image_names)                         \n",
        "                         \n",
        "    return norm_images, image_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "um45_zseJrq1"
      },
      "outputs": [],
      "source": [
        "norm_images, norm_labels =  load_normal('/content/gdrive/MyDrive/ColabNotebooks/inputs/train_images', '/content/gdrive/MyDrive/ColabNotebooks/inputs/labels_train.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_AbVtEObK-5"
      },
      "outputs": [],
      "source": [
        "norm_images_test, names =  load_normal_test('/content/gdrive/MyDrive/ColabNotebooks/inputs/test_images')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xIKFwsmaAwA",
        "outputId": "94507a97-9d11-478a-f481-5859ba027588"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4672, 224, 224, 3)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train = norm_images\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7U6ebugAFNoa",
        "outputId": "baa929c6-142d-4992-e5f7-f81e1c78ff86"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4672, 1)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train = norm_labels\n",
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBT1hSbsbQCI",
        "outputId": "3f3218a3-62ec-42bf-a285-a1a6e1915a79"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1168, 224, 224, 3)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_test = norm_images_test\n",
        "X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "v113eIz6FxL2",
        "outputId": "06350aba-3eb8-45f4-f32b-debc18051c67"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/matplotlib/text.py:1165: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  if s != self._text:\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x288 with 14 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, axes = plt.subplots(ncols=7, nrows=2, figsize=(16, 4))\n",
        "\n",
        "indices = np.random.choice(len(X_train), 14)\n",
        "counter = 0\n",
        "\n",
        "for i in range(2):\n",
        "    for j in range(7):\n",
        "        axes[i,j].set_title(y_train[indices[counter]])\n",
        "        axes[i,j].imshow(X_train[indices[counter]], cmap='gray')\n",
        "        axes[i,j].get_xaxis().set_visible(False)\n",
        "        axes[i,j].get_yaxis().set_visible(False)\n",
        "        counter += 1\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Crjzl50bMZch",
        "outputId": "67f02a99-db75-4229-c062-1a63f92b2201"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/ColabNotebooks/inputs\n"
          ]
        }
      ],
      "source": [
        "#changing the working directory\n",
        "%cd \"/content/gdrive/MyDrive/ColabNotebooks/inputs\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZtHXW5sGNyg"
      },
      "outputs": [],
      "source": [
        "# Use this to save variables\n",
        "with open('pneumonia_data3.pickle', 'wb') as f:\n",
        "    pickle.dump((X_train, y_train), f)# Use this to load variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ssZDp47sbChy"
      },
      "outputs": [],
      "source": [
        "# Use this to save variables\n",
        "with open('pneumonia_data_test3.pickle', 'wb') as f:\n",
        "    pickle.dump((X_test), f)# Use this to load variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6dqCAknolrT"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(names).to_csv(\"submission3.csv\", index=False, header = [\"file_name\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSzpNMKE2RBS"
      },
      "source": [
        "#Initial Start for all models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DfhttMNqR-AU"
      },
      "outputs": [],
      "source": [
        "#Already Inserted Previously\n",
        "import os\n",
        "import cv2\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from google.colab import drive\n",
        "from tqdm import tqdm\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras import optimizers\n",
        "from keras.models import Model, load_model, Sequential\n",
        "from keras.layers import Dense, Input, Conv2D, MaxPool2D, Flatten, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
        "from keras.layers import Conv2D, SeparableConv2D, MaxPool2D, LeakyReLU, Activation\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "from keras.regularizers import L1L2\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TCEJ0fhSpto",
        "outputId": "daadc257-6544-4fdf-eee3-130fc8dae0c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chgKQLsqU_B_",
        "outputId": "92ffc34e-78cf-4978-8435-48b8b9f424fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/ColabNotebooks/inputs\n"
          ]
        }
      ],
      "source": [
        "#changing the working directory\n",
        "%cd \"/content/gdrive/MyDrive/ColabNotebooks/inputs\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygPczKofMzEB"
      },
      "outputs": [],
      "source": [
        "with open('pneumonia_data3.pickle', 'rb') as f:\n",
        "    (X_train, y_train) = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aIefp_ROarzi"
      },
      "outputs": [],
      "source": [
        "with open('pneumonia_data_test3.pickle', 'rb') as f:\n",
        "    (X_test) = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8kw-zI3NCIg",
        "outputId": "bf6c09db-eb98-4517-f390-5e2a5cfb31d0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4672, 224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDc5gJcta0jk",
        "outputId": "d55aabab-e710-408a-e2a2-421f5ff12ae2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1168, 224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhlMhvcmmVaZ",
        "outputId": "38420802-4304-446c-d04a-31de071e8e87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4672, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFglv1WgNFlK"
      },
      "outputs": [],
      "source": [
        "one_hot_encoder = OneHotEncoder(sparse=False)\n",
        "y_train = one_hot_encoder.fit_transform(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9iIC3upy2eU",
        "outputId": "736bdb41-1f81-4e4c-cda1-a8c799da13b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4672, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "        rotation_range = 2,\n",
        "        zoom_range = 0.1, \n",
        "        width_shift_range = 0.1, \n",
        "        height_shift_range = 0.1,\n",
        "        brightness_range=[0.6,1.4],\n",
        "        fill_mode= \"nearest\",validation_split=0.1)"
      ],
      "metadata": {
        "id": "jpQWGPqzNaCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datagen.fit(X_train)\n",
        "train_gen = datagen.flow(X_train, y_train, batch_size=32, subset=\"training\")\n",
        "valid_gen = datagen.flow(X_train, y_train, batch_size=32, subset= \"validation\")"
      ],
      "metadata": {
        "id": "A8zqO9PUNaGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Models -> From 22 models only the 16 used on Soft Voting"
      ],
      "metadata": {
        "id": "TSAq0cxG2aQr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZIlmSvKEWLE"
      },
      "source": [
        "###EfficientNetB0 ->  Removed on Final Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1mQAHHdSdiH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c08e414-4721-43a0-c1cb-3031d0aeb5e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "16711680/16705208 [==============================] - 0s 0us/step\n",
            "16719872/16705208 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "base_model = tf.keras.applications.EfficientNetB0(include_top=False,\n",
        "                                     weights='imagenet',\n",
        "                                     input_shape=(224, 224, 3))\n",
        "x = base_model.output\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = Dense(512, activation=None, kernel_regularizer = L1L2(l1=1e-5, l2=1e-3))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('swish')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(512, activation=None, kernel_regularizer = L1L2(l1=1e-5, l2=1e-3))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('swish')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "ouput1 = Dense(3, activation= 'softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=ouput1)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', \n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4, decay = 1e-4 * 0.1), metrics=['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OT2-lxbB24XD",
        "outputId": "ea6fd3f2-a457-4e04-ff64-47b64aac63b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " rescaling (Rescaling)          (None, 224, 224, 3)  0           ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " normalization (Normalization)  (None, 224, 224, 3)  7           ['rescaling[0][0]']              \n",
            "                                                                                                  \n",
            " stem_conv_pad (ZeroPadding2D)  (None, 225, 225, 3)  0           ['normalization[0][0]']          \n",
            "                                                                                                  \n",
            " stem_conv (Conv2D)             (None, 112, 112, 32  864         ['stem_conv_pad[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " stem_bn (BatchNormalization)   (None, 112, 112, 32  128         ['stem_conv[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " stem_activation (Activation)   (None, 112, 112, 32  0           ['stem_bn[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block1a_dwconv (DepthwiseConv2  (None, 112, 112, 32  288        ['stem_activation[0][0]']        \n",
            " D)                             )                                                                 \n",
            "                                                                                                  \n",
            " block1a_bn (BatchNormalization  (None, 112, 112, 32  128        ['block1a_dwconv[0][0]']         \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " block1a_activation (Activation  (None, 112, 112, 32  0          ['block1a_bn[0][0]']             \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " block1a_se_squeeze (GlobalAver  (None, 32)          0           ['block1a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block1a_se_reshape (Reshape)   (None, 1, 1, 32)     0           ['block1a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block1a_se_reduce (Conv2D)     (None, 1, 1, 8)      264         ['block1a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block1a_se_expand (Conv2D)     (None, 1, 1, 32)     288         ['block1a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block1a_se_excite (Multiply)   (None, 112, 112, 32  0           ['block1a_activation[0][0]',     \n",
            "                                )                                 'block1a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block1a_project_conv (Conv2D)  (None, 112, 112, 16  512         ['block1a_se_excite[0][0]']      \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block1a_project_bn (BatchNorma  (None, 112, 112, 16  64         ['block1a_project_conv[0][0]']   \n",
            " lization)                      )                                                                 \n",
            "                                                                                                  \n",
            " block2a_expand_conv (Conv2D)   (None, 112, 112, 96  1536        ['block1a_project_bn[0][0]']     \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block2a_expand_bn (BatchNormal  (None, 112, 112, 96  384        ['block2a_expand_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " block2a_expand_activation (Act  (None, 112, 112, 96  0          ['block2a_expand_bn[0][0]']      \n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " block2a_dwconv_pad (ZeroPaddin  (None, 113, 113, 96  0          ['block2a_expand_activation[0][0]\n",
            " g2D)                           )                                ']                               \n",
            "                                                                                                  \n",
            " block2a_dwconv (DepthwiseConv2  (None, 56, 56, 96)  864         ['block2a_dwconv_pad[0][0]']     \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block2a_bn (BatchNormalization  (None, 56, 56, 96)  384         ['block2a_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block2a_activation (Activation  (None, 56, 56, 96)  0           ['block2a_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block2a_se_squeeze (GlobalAver  (None, 96)          0           ['block2a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block2a_se_reshape (Reshape)   (None, 1, 1, 96)     0           ['block2a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block2a_se_reduce (Conv2D)     (None, 1, 1, 4)      388         ['block2a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block2a_se_expand (Conv2D)     (None, 1, 1, 96)     480         ['block2a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block2a_se_excite (Multiply)   (None, 56, 56, 96)   0           ['block2a_activation[0][0]',     \n",
            "                                                                  'block2a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block2a_project_conv (Conv2D)  (None, 56, 56, 24)   2304        ['block2a_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block2a_project_bn (BatchNorma  (None, 56, 56, 24)  96          ['block2a_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block2b_expand_conv (Conv2D)   (None, 56, 56, 144)  3456        ['block2a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block2b_expand_bn (BatchNormal  (None, 56, 56, 144)  576        ['block2b_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block2b_expand_activation (Act  (None, 56, 56, 144)  0          ['block2b_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block2b_dwconv (DepthwiseConv2  (None, 56, 56, 144)  1296       ['block2b_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block2b_bn (BatchNormalization  (None, 56, 56, 144)  576        ['block2b_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block2b_activation (Activation  (None, 56, 56, 144)  0          ['block2b_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block2b_se_squeeze (GlobalAver  (None, 144)         0           ['block2b_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block2b_se_reshape (Reshape)   (None, 1, 1, 144)    0           ['block2b_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block2b_se_reduce (Conv2D)     (None, 1, 1, 6)      870         ['block2b_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block2b_se_expand (Conv2D)     (None, 1, 1, 144)    1008        ['block2b_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block2b_se_excite (Multiply)   (None, 56, 56, 144)  0           ['block2b_activation[0][0]',     \n",
            "                                                                  'block2b_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block2b_project_conv (Conv2D)  (None, 56, 56, 24)   3456        ['block2b_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block2b_project_bn (BatchNorma  (None, 56, 56, 24)  96          ['block2b_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block2b_drop (Dropout)         (None, 56, 56, 24)   0           ['block2b_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block2b_add (Add)              (None, 56, 56, 24)   0           ['block2b_drop[0][0]',           \n",
            "                                                                  'block2a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block3a_expand_conv (Conv2D)   (None, 56, 56, 144)  3456        ['block2b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block3a_expand_bn (BatchNormal  (None, 56, 56, 144)  576        ['block3a_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block3a_expand_activation (Act  (None, 56, 56, 144)  0          ['block3a_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block3a_dwconv_pad (ZeroPaddin  (None, 59, 59, 144)  0          ['block3a_expand_activation[0][0]\n",
            " g2D)                                                            ']                               \n",
            "                                                                                                  \n",
            " block3a_dwconv (DepthwiseConv2  (None, 28, 28, 144)  3600       ['block3a_dwconv_pad[0][0]']     \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block3a_bn (BatchNormalization  (None, 28, 28, 144)  576        ['block3a_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block3a_activation (Activation  (None, 28, 28, 144)  0          ['block3a_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block3a_se_squeeze (GlobalAver  (None, 144)         0           ['block3a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block3a_se_reshape (Reshape)   (None, 1, 1, 144)    0           ['block3a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block3a_se_reduce (Conv2D)     (None, 1, 1, 6)      870         ['block3a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block3a_se_expand (Conv2D)     (None, 1, 1, 144)    1008        ['block3a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block3a_se_excite (Multiply)   (None, 28, 28, 144)  0           ['block3a_activation[0][0]',     \n",
            "                                                                  'block3a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block3a_project_conv (Conv2D)  (None, 28, 28, 40)   5760        ['block3a_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block3a_project_bn (BatchNorma  (None, 28, 28, 40)  160         ['block3a_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block3b_expand_conv (Conv2D)   (None, 28, 28, 240)  9600        ['block3a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block3b_expand_bn (BatchNormal  (None, 28, 28, 240)  960        ['block3b_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block3b_expand_activation (Act  (None, 28, 28, 240)  0          ['block3b_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block3b_dwconv (DepthwiseConv2  (None, 28, 28, 240)  6000       ['block3b_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block3b_bn (BatchNormalization  (None, 28, 28, 240)  960        ['block3b_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block3b_activation (Activation  (None, 28, 28, 240)  0          ['block3b_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block3b_se_squeeze (GlobalAver  (None, 240)         0           ['block3b_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block3b_se_reshape (Reshape)   (None, 1, 1, 240)    0           ['block3b_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block3b_se_reduce (Conv2D)     (None, 1, 1, 10)     2410        ['block3b_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block3b_se_expand (Conv2D)     (None, 1, 1, 240)    2640        ['block3b_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block3b_se_excite (Multiply)   (None, 28, 28, 240)  0           ['block3b_activation[0][0]',     \n",
            "                                                                  'block3b_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block3b_project_conv (Conv2D)  (None, 28, 28, 40)   9600        ['block3b_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block3b_project_bn (BatchNorma  (None, 28, 28, 40)  160         ['block3b_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block3b_drop (Dropout)         (None, 28, 28, 40)   0           ['block3b_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block3b_add (Add)              (None, 28, 28, 40)   0           ['block3b_drop[0][0]',           \n",
            "                                                                  'block3a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block4a_expand_conv (Conv2D)   (None, 28, 28, 240)  9600        ['block3b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block4a_expand_bn (BatchNormal  (None, 28, 28, 240)  960        ['block4a_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block4a_expand_activation (Act  (None, 28, 28, 240)  0          ['block4a_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block4a_dwconv_pad (ZeroPaddin  (None, 29, 29, 240)  0          ['block4a_expand_activation[0][0]\n",
            " g2D)                                                            ']                               \n",
            "                                                                                                  \n",
            " block4a_dwconv (DepthwiseConv2  (None, 14, 14, 240)  2160       ['block4a_dwconv_pad[0][0]']     \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block4a_bn (BatchNormalization  (None, 14, 14, 240)  960        ['block4a_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block4a_activation (Activation  (None, 14, 14, 240)  0          ['block4a_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block4a_se_squeeze (GlobalAver  (None, 240)         0           ['block4a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block4a_se_reshape (Reshape)   (None, 1, 1, 240)    0           ['block4a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block4a_se_reduce (Conv2D)     (None, 1, 1, 10)     2410        ['block4a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block4a_se_expand (Conv2D)     (None, 1, 1, 240)    2640        ['block4a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block4a_se_excite (Multiply)   (None, 14, 14, 240)  0           ['block4a_activation[0][0]',     \n",
            "                                                                  'block4a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block4a_project_conv (Conv2D)  (None, 14, 14, 80)   19200       ['block4a_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block4a_project_bn (BatchNorma  (None, 14, 14, 80)  320         ['block4a_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block4b_expand_conv (Conv2D)   (None, 14, 14, 480)  38400       ['block4a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block4b_expand_bn (BatchNormal  (None, 14, 14, 480)  1920       ['block4b_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block4b_expand_activation (Act  (None, 14, 14, 480)  0          ['block4b_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block4b_dwconv (DepthwiseConv2  (None, 14, 14, 480)  4320       ['block4b_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block4b_bn (BatchNormalization  (None, 14, 14, 480)  1920       ['block4b_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block4b_activation (Activation  (None, 14, 14, 480)  0          ['block4b_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block4b_se_squeeze (GlobalAver  (None, 480)         0           ['block4b_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block4b_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block4b_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block4b_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block4b_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block4b_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block4b_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block4b_se_excite (Multiply)   (None, 14, 14, 480)  0           ['block4b_activation[0][0]',     \n",
            "                                                                  'block4b_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block4b_project_conv (Conv2D)  (None, 14, 14, 80)   38400       ['block4b_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block4b_project_bn (BatchNorma  (None, 14, 14, 80)  320         ['block4b_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block4b_drop (Dropout)         (None, 14, 14, 80)   0           ['block4b_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block4b_add (Add)              (None, 14, 14, 80)   0           ['block4b_drop[0][0]',           \n",
            "                                                                  'block4a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block4c_expand_conv (Conv2D)   (None, 14, 14, 480)  38400       ['block4b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block4c_expand_bn (BatchNormal  (None, 14, 14, 480)  1920       ['block4c_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block4c_expand_activation (Act  (None, 14, 14, 480)  0          ['block4c_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block4c_dwconv (DepthwiseConv2  (None, 14, 14, 480)  4320       ['block4c_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block4c_bn (BatchNormalization  (None, 14, 14, 480)  1920       ['block4c_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block4c_activation (Activation  (None, 14, 14, 480)  0          ['block4c_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block4c_se_squeeze (GlobalAver  (None, 480)         0           ['block4c_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block4c_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block4c_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block4c_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block4c_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block4c_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block4c_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block4c_se_excite (Multiply)   (None, 14, 14, 480)  0           ['block4c_activation[0][0]',     \n",
            "                                                                  'block4c_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block4c_project_conv (Conv2D)  (None, 14, 14, 80)   38400       ['block4c_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block4c_project_bn (BatchNorma  (None, 14, 14, 80)  320         ['block4c_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block4c_drop (Dropout)         (None, 14, 14, 80)   0           ['block4c_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block4c_add (Add)              (None, 14, 14, 80)   0           ['block4c_drop[0][0]',           \n",
            "                                                                  'block4b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block5a_expand_conv (Conv2D)   (None, 14, 14, 480)  38400       ['block4c_add[0][0]']            \n",
            "                                                                                                  \n",
            " block5a_expand_bn (BatchNormal  (None, 14, 14, 480)  1920       ['block5a_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block5a_expand_activation (Act  (None, 14, 14, 480)  0          ['block5a_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block5a_dwconv (DepthwiseConv2  (None, 14, 14, 480)  12000      ['block5a_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block5a_bn (BatchNormalization  (None, 14, 14, 480)  1920       ['block5a_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block5a_activation (Activation  (None, 14, 14, 480)  0          ['block5a_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block5a_se_squeeze (GlobalAver  (None, 480)         0           ['block5a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block5a_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block5a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block5a_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block5a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block5a_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block5a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block5a_se_excite (Multiply)   (None, 14, 14, 480)  0           ['block5a_activation[0][0]',     \n",
            "                                                                  'block5a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block5a_project_conv (Conv2D)  (None, 14, 14, 112)  53760       ['block5a_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block5a_project_bn (BatchNorma  (None, 14, 14, 112)  448        ['block5a_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block5b_expand_conv (Conv2D)   (None, 14, 14, 672)  75264       ['block5a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block5b_expand_bn (BatchNormal  (None, 14, 14, 672)  2688       ['block5b_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block5b_expand_activation (Act  (None, 14, 14, 672)  0          ['block5b_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block5b_dwconv (DepthwiseConv2  (None, 14, 14, 672)  16800      ['block5b_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block5b_bn (BatchNormalization  (None, 14, 14, 672)  2688       ['block5b_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block5b_activation (Activation  (None, 14, 14, 672)  0          ['block5b_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block5b_se_squeeze (GlobalAver  (None, 672)         0           ['block5b_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block5b_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block5b_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block5b_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block5b_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block5b_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block5b_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block5b_se_excite (Multiply)   (None, 14, 14, 672)  0           ['block5b_activation[0][0]',     \n",
            "                                                                  'block5b_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block5b_project_conv (Conv2D)  (None, 14, 14, 112)  75264       ['block5b_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block5b_project_bn (BatchNorma  (None, 14, 14, 112)  448        ['block5b_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block5b_drop (Dropout)         (None, 14, 14, 112)  0           ['block5b_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block5b_add (Add)              (None, 14, 14, 112)  0           ['block5b_drop[0][0]',           \n",
            "                                                                  'block5a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block5c_expand_conv (Conv2D)   (None, 14, 14, 672)  75264       ['block5b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block5c_expand_bn (BatchNormal  (None, 14, 14, 672)  2688       ['block5c_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block5c_expand_activation (Act  (None, 14, 14, 672)  0          ['block5c_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block5c_dwconv (DepthwiseConv2  (None, 14, 14, 672)  16800      ['block5c_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block5c_bn (BatchNormalization  (None, 14, 14, 672)  2688       ['block5c_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block5c_activation (Activation  (None, 14, 14, 672)  0          ['block5c_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block5c_se_squeeze (GlobalAver  (None, 672)         0           ['block5c_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block5c_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block5c_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block5c_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block5c_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block5c_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block5c_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block5c_se_excite (Multiply)   (None, 14, 14, 672)  0           ['block5c_activation[0][0]',     \n",
            "                                                                  'block5c_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block5c_project_conv (Conv2D)  (None, 14, 14, 112)  75264       ['block5c_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block5c_project_bn (BatchNorma  (None, 14, 14, 112)  448        ['block5c_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block5c_drop (Dropout)         (None, 14, 14, 112)  0           ['block5c_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block5c_add (Add)              (None, 14, 14, 112)  0           ['block5c_drop[0][0]',           \n",
            "                                                                  'block5b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block6a_expand_conv (Conv2D)   (None, 14, 14, 672)  75264       ['block5c_add[0][0]']            \n",
            "                                                                                                  \n",
            " block6a_expand_bn (BatchNormal  (None, 14, 14, 672)  2688       ['block6a_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block6a_expand_activation (Act  (None, 14, 14, 672)  0          ['block6a_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block6a_dwconv_pad (ZeroPaddin  (None, 17, 17, 672)  0          ['block6a_expand_activation[0][0]\n",
            " g2D)                                                            ']                               \n",
            "                                                                                                  \n",
            " block6a_dwconv (DepthwiseConv2  (None, 7, 7, 672)   16800       ['block6a_dwconv_pad[0][0]']     \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block6a_bn (BatchNormalization  (None, 7, 7, 672)   2688        ['block6a_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block6a_activation (Activation  (None, 7, 7, 672)   0           ['block6a_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block6a_se_squeeze (GlobalAver  (None, 672)         0           ['block6a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block6a_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block6a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block6a_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block6a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block6a_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block6a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block6a_se_excite (Multiply)   (None, 7, 7, 672)    0           ['block6a_activation[0][0]',     \n",
            "                                                                  'block6a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block6a_project_conv (Conv2D)  (None, 7, 7, 192)    129024      ['block6a_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block6a_project_bn (BatchNorma  (None, 7, 7, 192)   768         ['block6a_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block6b_expand_conv (Conv2D)   (None, 7, 7, 1152)   221184      ['block6a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block6b_expand_bn (BatchNormal  (None, 7, 7, 1152)  4608        ['block6b_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block6b_expand_activation (Act  (None, 7, 7, 1152)  0           ['block6b_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block6b_dwconv (DepthwiseConv2  (None, 7, 7, 1152)  28800       ['block6b_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block6b_bn (BatchNormalization  (None, 7, 7, 1152)  4608        ['block6b_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block6b_activation (Activation  (None, 7, 7, 1152)  0           ['block6b_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block6b_se_squeeze (GlobalAver  (None, 1152)        0           ['block6b_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block6b_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6b_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block6b_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6b_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block6b_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6b_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block6b_se_excite (Multiply)   (None, 7, 7, 1152)   0           ['block6b_activation[0][0]',     \n",
            "                                                                  'block6b_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block6b_project_conv (Conv2D)  (None, 7, 7, 192)    221184      ['block6b_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block6b_project_bn (BatchNorma  (None, 7, 7, 192)   768         ['block6b_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block6b_drop (Dropout)         (None, 7, 7, 192)    0           ['block6b_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block6b_add (Add)              (None, 7, 7, 192)    0           ['block6b_drop[0][0]',           \n",
            "                                                                  'block6a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block6c_expand_conv (Conv2D)   (None, 7, 7, 1152)   221184      ['block6b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block6c_expand_bn (BatchNormal  (None, 7, 7, 1152)  4608        ['block6c_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block6c_expand_activation (Act  (None, 7, 7, 1152)  0           ['block6c_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block6c_dwconv (DepthwiseConv2  (None, 7, 7, 1152)  28800       ['block6c_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block6c_bn (BatchNormalization  (None, 7, 7, 1152)  4608        ['block6c_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block6c_activation (Activation  (None, 7, 7, 1152)  0           ['block6c_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block6c_se_squeeze (GlobalAver  (None, 1152)        0           ['block6c_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block6c_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6c_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block6c_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6c_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block6c_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6c_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block6c_se_excite (Multiply)   (None, 7, 7, 1152)   0           ['block6c_activation[0][0]',     \n",
            "                                                                  'block6c_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block6c_project_conv (Conv2D)  (None, 7, 7, 192)    221184      ['block6c_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block6c_project_bn (BatchNorma  (None, 7, 7, 192)   768         ['block6c_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block6c_drop (Dropout)         (None, 7, 7, 192)    0           ['block6c_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block6c_add (Add)              (None, 7, 7, 192)    0           ['block6c_drop[0][0]',           \n",
            "                                                                  'block6b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block6d_expand_conv (Conv2D)   (None, 7, 7, 1152)   221184      ['block6c_add[0][0]']            \n",
            "                                                                                                  \n",
            " block6d_expand_bn (BatchNormal  (None, 7, 7, 1152)  4608        ['block6d_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block6d_expand_activation (Act  (None, 7, 7, 1152)  0           ['block6d_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block6d_dwconv (DepthwiseConv2  (None, 7, 7, 1152)  28800       ['block6d_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block6d_bn (BatchNormalization  (None, 7, 7, 1152)  4608        ['block6d_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block6d_activation (Activation  (None, 7, 7, 1152)  0           ['block6d_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block6d_se_squeeze (GlobalAver  (None, 1152)        0           ['block6d_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block6d_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6d_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block6d_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6d_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block6d_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6d_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block6d_se_excite (Multiply)   (None, 7, 7, 1152)   0           ['block6d_activation[0][0]',     \n",
            "                                                                  'block6d_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block6d_project_conv (Conv2D)  (None, 7, 7, 192)    221184      ['block6d_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block6d_project_bn (BatchNorma  (None, 7, 7, 192)   768         ['block6d_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block6d_drop (Dropout)         (None, 7, 7, 192)    0           ['block6d_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block6d_add (Add)              (None, 7, 7, 192)    0           ['block6d_drop[0][0]',           \n",
            "                                                                  'block6c_add[0][0]']            \n",
            "                                                                                                  \n",
            " block7a_expand_conv (Conv2D)   (None, 7, 7, 1152)   221184      ['block6d_add[0][0]']            \n",
            "                                                                                                  \n",
            " block7a_expand_bn (BatchNormal  (None, 7, 7, 1152)  4608        ['block7a_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block7a_expand_activation (Act  (None, 7, 7, 1152)  0           ['block7a_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block7a_dwconv (DepthwiseConv2  (None, 7, 7, 1152)  10368       ['block7a_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block7a_bn (BatchNormalization  (None, 7, 7, 1152)  4608        ['block7a_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block7a_activation (Activation  (None, 7, 7, 1152)  0           ['block7a_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block7a_se_squeeze (GlobalAver  (None, 1152)        0           ['block7a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block7a_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block7a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block7a_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block7a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block7a_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block7a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block7a_se_excite (Multiply)   (None, 7, 7, 1152)   0           ['block7a_activation[0][0]',     \n",
            "                                                                  'block7a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block7a_project_conv (Conv2D)  (None, 7, 7, 320)    368640      ['block7a_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block7a_project_bn (BatchNorma  (None, 7, 7, 320)   1280        ['block7a_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " top_conv (Conv2D)              (None, 7, 7, 1280)   409600      ['block7a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " top_bn (BatchNormalization)    (None, 7, 7, 1280)   5120        ['top_conv[0][0]']               \n",
            "                                                                                                  \n",
            " top_activation (Activation)    (None, 7, 7, 1280)   0           ['top_bn[0][0]']                 \n",
            "                                                                                                  \n",
            " global_average_pooling2d (Glob  (None, 1280)        0           ['top_activation[0][0]']         \n",
            " alAveragePooling2D)                                                                              \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 512)          655872      ['global_average_pooling2d[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 512)         2048        ['dense[0][0]']                  \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 512)          0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 512)          0           ['activation[0][0]']             \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 512)          262656      ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 512)         2048        ['dense_1[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 512)          0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 512)          0           ['activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 3)            1539        ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,973,734\n",
            "Trainable params: 4,929,663\n",
            "Non-trainable params: 44,071\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1yevqqT8__L9"
      },
      "outputs": [],
      "source": [
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', patience = 2, verbose=1,factor=0.3, min_lr=0.00000001)\n",
        "chkpt = ModelCheckpoint(filepath='best_model_effB0.hdf5', monitor='val_loss', save_best_only=True, save_weights_only=True)\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(patience=13, monitor='val_loss', restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Efyom1D5FfIN",
        "outputId": "52830afe-b511-4181-bae5-768ec1aabcfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "132/132 [==============================] - 76s 424ms/step - loss: 2.3447 - acc: 0.6540 - val_loss: 2.2193 - val_acc: 0.7516 - lr: 1.0000e-04\n",
            "Epoch 2/25\n",
            "132/132 [==============================] - 52s 392ms/step - loss: 2.0571 - acc: 0.7731 - val_loss: 2.0654 - val_acc: 0.7816 - lr: 1.0000e-04\n",
            "Epoch 3/25\n",
            "132/132 [==============================] - 52s 389ms/step - loss: 1.9919 - acc: 0.7855 - val_loss: 2.0237 - val_acc: 0.7580 - lr: 1.0000e-04\n",
            "Epoch 4/25\n",
            "132/132 [==============================] - 51s 389ms/step - loss: 1.9087 - acc: 0.8131 - val_loss: 1.9222 - val_acc: 0.7880 - lr: 1.0000e-04\n",
            "Epoch 5/25\n",
            "132/132 [==============================] - 52s 389ms/step - loss: 1.8656 - acc: 0.8174 - val_loss: 1.8846 - val_acc: 0.8223 - lr: 1.0000e-04\n",
            "Epoch 6/25\n",
            "132/132 [==============================] - 52s 390ms/step - loss: 1.8122 - acc: 0.8278 - val_loss: 1.8030 - val_acc: 0.8415 - lr: 1.0000e-04\n",
            "Epoch 7/25\n",
            "132/132 [==============================] - 52s 391ms/step - loss: 1.7659 - acc: 0.8361 - val_loss: 1.7666 - val_acc: 0.8330 - lr: 1.0000e-04\n",
            "Epoch 8/25\n",
            "132/132 [==============================] - 51s 387ms/step - loss: 1.7138 - acc: 0.8457 - val_loss: 1.7229 - val_acc: 0.8266 - lr: 1.0000e-04\n",
            "Epoch 9/25\n",
            "132/132 [==============================] - 52s 389ms/step - loss: 1.6551 - acc: 0.8564 - val_loss: 1.7101 - val_acc: 0.8330 - lr: 1.0000e-04\n",
            "Epoch 10/25\n",
            "132/132 [==============================] - 51s 388ms/step - loss: 1.6077 - acc: 0.8671 - val_loss: 1.6823 - val_acc: 0.8180 - lr: 1.0000e-04\n",
            "Epoch 11/25\n",
            "132/132 [==============================] - 51s 386ms/step - loss: 1.5606 - acc: 0.8775 - val_loss: 1.6771 - val_acc: 0.8437 - lr: 1.0000e-04\n",
            "Epoch 12/25\n",
            "132/132 [==============================] - 51s 381ms/step - loss: 1.5035 - acc: 0.8859 - val_loss: 1.6977 - val_acc: 0.8030 - lr: 1.0000e-04\n",
            "Epoch 13/25\n",
            "132/132 [==============================] - 51s 386ms/step - loss: 1.4647 - acc: 0.8875 - val_loss: 1.5772 - val_acc: 0.8587 - lr: 1.0000e-04\n",
            "Epoch 14/25\n",
            "132/132 [==============================] - 50s 379ms/step - loss: 1.4013 - acc: 0.9061 - val_loss: 1.6778 - val_acc: 0.8137 - lr: 1.0000e-04\n",
            "Epoch 15/25\n",
            "132/132 [==============================] - 51s 386ms/step - loss: 1.3528 - acc: 0.9101 - val_loss: 1.5608 - val_acc: 0.8330 - lr: 1.0000e-04\n",
            "Epoch 16/25\n",
            "132/132 [==============================] - 51s 387ms/step - loss: 1.2976 - acc: 0.9208 - val_loss: 1.5526 - val_acc: 0.8458 - lr: 1.0000e-04\n",
            "Epoch 17/25\n",
            "132/132 [==============================] - 50s 380ms/step - loss: 1.2687 - acc: 0.9113 - val_loss: 1.5787 - val_acc: 0.8287 - lr: 1.0000e-04\n",
            "Epoch 18/25\n",
            "132/132 [==============================] - ETA: 0s - loss: 1.2210 - acc: 0.9320\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 2.9999999242136255e-05.\n",
            "132/132 [==============================] - 50s 380ms/step - loss: 1.2210 - acc: 0.9320 - val_loss: 1.5626 - val_acc: 0.8223 - lr: 1.0000e-04\n",
            "Epoch 19/25\n",
            "132/132 [==============================] - 51s 387ms/step - loss: 1.1876 - acc: 0.9334 - val_loss: 1.4987 - val_acc: 0.8373 - lr: 3.0000e-05\n",
            "Epoch 20/25\n",
            "132/132 [==============================] - 51s 387ms/step - loss: 1.1408 - acc: 0.9496 - val_loss: 1.4876 - val_acc: 0.8522 - lr: 3.0000e-05\n",
            "Epoch 21/25\n",
            "132/132 [==============================] - 50s 379ms/step - loss: 1.1256 - acc: 0.9463 - val_loss: 1.5298 - val_acc: 0.8287 - lr: 3.0000e-05\n",
            "Epoch 22/25\n",
            "132/132 [==============================] - ETA: 0s - loss: 1.1066 - acc: 0.9555\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 8.999999772640877e-06.\n",
            "132/132 [==============================] - 50s 379ms/step - loss: 1.1066 - acc: 0.9555 - val_loss: 1.4944 - val_acc: 0.8266 - lr: 3.0000e-05\n",
            "Epoch 23/25\n",
            "132/132 [==============================] - 51s 387ms/step - loss: 1.0863 - acc: 0.9593 - val_loss: 1.4766 - val_acc: 0.8565 - lr: 9.0000e-06\n",
            "Epoch 24/25\n",
            "132/132 [==============================] - 50s 380ms/step - loss: 1.0900 - acc: 0.9586 - val_loss: 1.5307 - val_acc: 0.8437 - lr: 9.0000e-06\n",
            "Epoch 25/25\n",
            "132/132 [==============================] - ETA: 0s - loss: 1.0789 - acc: 0.9577\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 2.6999998226528985e-06.\n",
            "132/132 [==============================] - 50s 380ms/step - loss: 1.0789 - acc: 0.9577 - val_loss: 1.4915 - val_acc: 0.8501 - lr: 9.0000e-06\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(train_gen, epochs=25, validation_data=valid_gen, callbacks=[learning_rate_reduction, chkpt, early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3H8lXnaT5WWR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "6ddbf460-64e5-4c35-af6f-396affbb616a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAF1CAYAAADFgbLVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3hUxdfA8e+kEwgpdEhCQm+hhipNimJFUBQFRGxg77727s/eRREbRQVFBBGliNJEWugQAoQOEUivpO3O+8csGiAhm2Q3m3I+z5Mn2bu3nA1hz87cmTNKa40QQgghKj43VwcghBBCCPtI0hZCCCEqCUnaQgghRCUhSVsIIYSoJCRpCyGEEJWEJG0hhBCikpCkLYQQQlQSkrSFcAKl1AqlVLJSytvVsQghqg5J2kI4mFIqDOgHaODqcr62R3lez1mqyusQwtEkaQvheDcD64BpwPiCTyilQpRSPyml4pVSiUqpjws8d4dSardSKl0pFa2U6mrbrpVSLQrsN00p9Yrt54FKqWNKqf9TSp0AvlZKBSqlFtqukWz7ObjA8UFKqa+VUnG25+fbtu9USl1VYD9PpVSCUqrLuS9QKVXXdt4UpVSSUmq1UsrtQq9RKeWmlHpGKXVYKXVKKTVDKeVvey7M9jpvU0odAf60bb/V9jtJVkotUUo1tW1XSqn3bOdJU0rtUEp1KMs/mhCVgSRtIRzvZuBb29elSqkGAEopd2AhcBgIA5oAs23PjQJesB1bG9NCT7Tzeg2BIKApcCfm//XXtsehwGng4wL7zwR8gfZAfeA92/YZwNgC+10O/KO13lLINR8BjgH1gAbAU4C+0GsEbrF9XQw0A2qdExfAAKAt5vc23HbekbbrrAZm2fa7BOgPtAL8geux//clROWltZYv+ZIvB30BfYE8oK7tcQzwkO3n3kA84FHIcUuAB4o4pwZaFHg8DXjF9vNAIBfwuUBMnYFk28+NACsQWMh+jYF0oLbt8Y/A40Wc8yXg54Jx2fEa/wDuLvC4te135YFJ8BpoVuD5RcBtBR67AVmYDyODgL1AL8DN1f/u8iVf5fUlLW0hHGs8sFRrnWB7/B3/dZGHAIe11vmFHBcC7C/lNeO11tlnHiilfJVSn9m6odOAVUCArRUcAiRprZPPPYnWOg5YA1yrlAoALsP0FhTmLSAWWKqUOqCUesKO19gY0wI/4zAmYTcosO1ogZ+bAh/YuuBTgCRAAU201n9iWumTgVNKqalKqdpFxCpElSFJWwgHUUrVwHTTDlBKnbDdY34I6KSU6oRJSKFFDLI6CjQv4tRZmO7sMxqe8/y5S/U9gmnF9tRa18Z0I4NJeEeBIFtSLsx0TBf5KGCt1vp4YTtprdO11o9orZthuvIfVkoN5sKvMQ6TiM8IBfKBk0W8lqPARK11QIGvGlrrv20xfKi17ga0w3STP1bEaxKiypCkLYTjXANYMEmks+2rLeZe7M3ABuAf4HWlVE2llI9S6iLbsV8AjyqlutkGWbU4M+gK2ArcpJRyV0oNw9z3vRA/zH3sFKVUEPD8mSe01v9gup0/sQ1Y81RK9S9w7HygK/AA5h53oZRSV9piVECq7XVbi3mNs4CHlFLhSqlawP+A74tolQNMAZ5USrW3XdPfdu8fpVR3pVRPpZQnkAlk264vRJUmSVsIxxkPfK21PqK1PnHmC9ONOwbT0r0KaAEcwQzkugFAaz0HeBXTnZ6OSZ5BtvM+YDsuxXae+cXE8T5QA0jAjGJffM7z4zD3kmOAU8CDZ57QWp8G5gLhwE8XuEZLYBmQAawFPtFaL9daW4p6jcBXmEFwq4CDmER7X1EX0FrPA94AZtu6+XdiuuzBDNb7HEjGdLMnYrrshajSlNbn9qwJIaozpdRzQCut9dhidxZClCspYCCE+JetO/02TGtcCFHBSPe4EAIwxV0wg78Waa1XuToeIcT5pHtcCCGEqCSkpS2EEEJUEpK0hRBCiEqiwg1Eq1u3rg4LC3N1GEIIIUS52bRpU4LWul5x+1W4pB0WFkZUVJSrwxBCCCHKjVLqcPF7Sfe4EEIIUWlI0hZCCCEqCUnaQgghRCVR4e5pFyYvL49jx46RnZ1d/M7VkI+PD8HBwXh6ero6FCGEEE5UKZL2sWPH8PPzIywsDLOokDhDa01iYiLHjh0jPDzc1eEIIYRwokrRPZ6dnU2dOnUkYRdCKUWdOnWkF0IIIaqBSpG0AUnYFyC/GyGEqB4qTdIWQgghqjtJ2kIIIUQlIUm7BK655hq6detG+/btmTp1KgCLFy+ma9eudOrUicGDBwOQkZHBhAkTiIiIoGPHjsydO9eVYQshhKgiKsXo8YJe/GUX0XFpDj1nu8a1ef6q9sXu99VXXxEUFMTp06fp3r07w4cP54477mDVqlWEh4eTlJQEwMsvv4y/vz87duwAIDk52aHxCiGEqJ4qXdJ2pQ8//JB58+YBcPToUaZOnUr//v3/nWoVFBQEwLJly5g9e/a/xwUGBpZ/sEIIUYVk5uSzKy6NfIsVHy93fL3cqeHpTg0vd3y9PKjh6Y67W9UflFvpkrY9LWJnWLFiBcuWLWPt2rX4+voycOBAOnfuTExMjEviEUKIqspq1RxIyGDzkRS2Hk1hy5EU9pxIw6ovfJyXhxs1PM9O6AW/+3qZn2t5e1DL25NaPh74eXtQy8fDbDvncU0vD9wq2AeBSpe0XSU1NZXAwEB8fX2JiYlh3bp1ZGdns2rVKg4ePPhv93hQUBBDhw5l8uTJvP/++4DpHpfWthBCFC4lK5cttuS85UgyW4+mkJ6dD4CfjwedQwIYOqglnUP88fXy4HSehdO55isrz0J2roWsXIttez6n88zjbNv3jJx84tNz/t2emZNPVq7FrthMgv8vkfvZvk8c0JzOIQHO/LUUSpK2nYYNG8aUKVNo27YtrVu3plevXtSrV4+pU6cycuRIrFYr9evX5/fff+eZZ57hnnvuoUOHDri7u/P8888zcuRIV78EIYRwuTyLlT0n0tlyJJktR1PYeiSFAwmZALgpaN2wNld1akyXkAC6hAbSrG5Np7R28y1WMm0JPSM7n4ycPNKz8ws8zj//cU4+Gdl5nEzL5rSdSd/RJGnbydvbm0WLFhX63GWXXXbW41q1ajF9+vTyCEsIISq8tOw8pq85xOp9CWw/nkJ2nhWAurW86BIayHWRwXQJCaRjsD81vcsnLXm4u+Ffww3/GpVrzQZJ2kIIIZwiO8/CzLWHmbwilpSsPDqFBHBjj1C6hAbSJSSA4MAaUtGxhCRpCyGEcKh8i5W5m4/x/rJ9/JOaTf9W9Xj80tZ0aOLv6tAqPbuStlJqGPAB4A58obV+/ZznmwJfAfWAJGCs1vqY7TkLsMO26xGt9dUOil0IIUQForVmya4TvLVkD/vjM+kcEsA713eiT/O6rg6tyig2aSul3IHJwFDgGLBRKbVAax1dYLe3gRla6+lKqUHAa8A423OntdadHRy3EEKICuTv/Qm8sXgP246m0KJ+LaaM7cal7RtI97eD2dPS7gHEaq0PACilZgPDgYJJux3wsO3n5cB8RwYphBCiYtp5PJU3Fsewel8Cjf19ePO6jozs0gQPd6mS7Qz2JO0mwNECj48BPc/ZZxswEtOFPgLwU0rV0VonAj5KqSggH3hday0JXQghykG+xcpbS/awMy6Vtg1r075Jbdo39qdZ3ZplTqoHEzJ5Z+keFm7/hwBfT565oi1jezXFx9PdQdGLwjhqINqjwMdKqVuAVcBx4MwktqZa6+NKqWbAn0qpHVrr/QUPVkrdCdwJEBoa6qCQhBCi+srJt/DArK0s3nWC1g38mHHoMLn5ZqqVt4cbbRrVpn1j89WuUW3aNqptV8I9mZbNB3/s4/uNR/Fyd+O+QS24o38zavtUrqlTlZU9Sfs4EFLgcbBt27+01nGYljZKqVrAtVrrFNtzx23fDyilVgBdgP3nHD8VmAoQGRlZTKG6yqFWrVpkZGS4OgwhRDWUkZPPxJlRrIlN5Lkr23Fr33DyLVb2x2eyKy6VXXFp7IpL5ZdtcXy3/ghgCps0r1fLlsj9//3u72uScWpWHlNW7efrNQexWDVje4Zy76CW1PPzduVLrXbsSdobgZZKqXBMsh4N3FRwB6VUXSBJa20FnsSMJEcpFQhkaa1zbPtcBLzpwPiFEEIUkJyZyy3TNrLzeCrvjOrEtd2CAVNMpHVDP1o39GNkV7Ov1ppjyacLJPI01h5IZP7WuH/P1ySgBm0b+bHxUDJp2XkM79SYh4e2JrSOryteXrVXbNLWWucrpe4FlmCmfH2ltd6llHoJiNJaLwAGAq8ppTSme/we2+Ftgc+UUlbM2t2vnzPqvOQWPQEndhS/X0k0jIDLXr/gLk888QQhISHcc495aS+88AIeHh4sX76c5ORk8vLyeOWVVxg+fHixl8vIyGD48OGFHjdjxgzefvttlFJ07NiRmTNncvLkSSZNmsSBAwcA+PTTT+nTp08ZX7QQoqo5kZrNuC/XczgpiyljuzG0XYML7q+UIiTIl5AgX4Z1aPTv9oSMHKJtSXxXXCq7/0mje1ggDw9tTbvGtZ39MsQFKK0rVm90ZGSkjoqKOmvb7t27adu2rXngoqS9ZcsWHnzwQVauXAlAu3btWLJkCf7+/tSuXZuEhAR69erFvn37UEpdsHs8Pz+frKys846Ljo5mxIgR/P3339StW/ffBUhuuOEGevfuzYMPPojFYiEjIwN//7OLFJz1OxJCVDuHEjIZ++V6kjNz+Xx8pMyNrmSUUpu01pHF7Vf5KqIVk1ydpUuXLpw6dYq4uDji4+MJDAykYcOGPPTQQ6xatQo3NzeOHz/OyZMnadiw4QXPpbXmqaeeOu+4P//8k1GjRlG3rvnPdmZ97j///JMZM2YA4O7ufl7CFkJUb9Fxadz81QYsViuz7uxFx+DyX31KlI/Kl7RdaNSoUfz444+cOHGCG264gW+//Zb4+Hg2bdqEp6cnYWFhZGdnF3ue0h4nhBDnijqUxIRpG6nl7cHsO3vTor6fq0MSTiSz30vghhtuYPbs2fz444+MGjWK1NRU6tevj6enJ8uXL+fw4cN2naeo4wYNGsScOXNITEwEICkpCYDBgwfz6aefAmCxWEhNTXXCqxNCVDYr9pxi7JfrqVvLmzmTJGFXB5K0S6B9+/akp6fTpEkTGjVqxJgxY4iKiiIiIoIZM2bQpk0bu85T1HHt27fn6aefZsCAAXTq1ImHHzZF5j744AOWL19OREQE3bp1Izq6bGP5hBCV3y/b4rh9ehTN6tZizqTeBAfKaO7qoPINRBOFkt+RENXHt+sP88z8nXRvGsQXt0RKYZMqoOoORBNCiGpKa80nK/bz1pI9DGpTn0/GdJWyodWMJG0n2rFjB+PGjTtrm7e3N+vXr3dRREKIykprzWuLYpi66gDDOzfm7VGd8JRFOaodSdpOFBERwdatW10dhhCiksu3WHlq3g5+iDrG+N5Nef6q9ri5yZKX1VGlSdpaa1mXtQgVbVyCEMJxCi78cf/gljw0pKW8F1ZjlSJp+/j4kJiYSJ06deSP9RxaaxITE/Hx8XF1KEIIB7JaNYmZuTz4/RbWxCby7JXtuK1vuKvDEi5WKZJ2cHAwx44dIz4+3tWhVEg+Pj4EBwe7OgwhxAXkW6wkZ+WRnJVLYkYuSZm5JGXmkJhpfk7MzCUp47+fk7NysVg17m7qrIU/RPVWKZK2p6cn4eHyCVMIUXn8Hn2Sz1cdICEzh6TMXFJP51HUnSz/Gp7UqelFUE0vmtbxpWvTAIJqehFU05tuTQPpHCJlSYVRKZK2EEJUJpsOJ3PPd5tpElCDdo1q2xKwF3VqeRHo62USdC2zLdDXS0aBC7tJ0hZCCAc6mpTFxJlRNPb34ae7+hBY08vVIYkqRD7eCSGEg6Rn53H79Chy8618Mb67JGzhcNLSFkIIB7BYNffP2kJsfAbTJ/SgRf1arg5JVEHS0hZCCAd49dfdLN8Tz4tXt6dvy7quDkdUUZK0hRCijL5bf4Sv1hxkwkVhjO3V1NXhiCpMkrYQQpTBmtgEnvt5Jxe3rsczV7RzdTiiipOkLYQQpbQ/PoO7vtlE83q1+PDGLrhLPXDhZJK0hRCiFJIzc7lt2kY83d34YnwkfrKmtSgHMnpcCCFKKDffyl3fbiIuJZtZd/YkJMjX1SGJakJa2kKIKiM338onK2K5fspa5m46hsXq+BXwtNY8O38n6w4k8eZ1HenWNMjh1xCiKJK0hRBVwroDiVzx4WreXLyHo8lZPDJnG1d+9Ber9jp2oaEvVh/k+6ij3DeoBdd0aeLQcwtRHEnaQohKLTEjh0d+2Mboqes4nWfhq1siWfN/g/jwxi5k5ORx81cbGPflenYeTy3ztZZFn+R/i3ZzeURDHhrSygHRC1EyShe17IyLREZG6qioKFeHIYSo4KxWzeyNR3ljcQxZufnc0a8Z9w1qSQ0v93/3ycm38M26I3z05z5ST+dxTecmPHJJK4IDS34POjoujeum/E2L+rX4/s7eZ11HiLJSSm3SWkcWu58kbSFEZRMdl8Yz83ew+UgKPcODeHVEB1rU9yty/9TTeUxZuZ+v/jqI1nDLRWHcM7AF/r72jfg+lZ7NNR+vwaphwb0XUb+2j6NeihCAJG0hRBWUkZPPe7/vZdrfhwio4cnTV7RlRJcmKGXf/Oi4lNO8+/te5m4+Rm0fT+69uAXjejfFx7PoVnN2noXRU9ex50Q6cyb1pkMTf0e9HCH+JUlbCFFlaK1ZvPMEL/4Szcn0bG7sEcrjl7YmwLd0q2jt/ieNNxbHsGJPPE0CavDopa0Y3qkJbucUR9Fac//srSzcHseUsd24tH1DR7wcIc4jSVsIUSUcScziuQU7WbEnnraNavPqiA50DQ10yLnXxCbw2qLd7DyeRvvGtXnysrZnLfbx/rK9vL9sH09c1oZJA5o75JpCFEaSthCiUsvJt/D5qgN89GcsHm6Khy9pzfjeTfFwd+ykF6tV88v2ON5cvIfjKafp36oeTwxrQ2x8BvfP2sKobsG8eV1Hu7vghSgNSdpCiErr7/0JPDN/JwfiM7k8oiHPXdmehv7OHfyVk29h5trDfPRnLGnZeXi4KbqEBvLNbT3x8pDZscK57E3aUsZUCFEhpGXnsflwMvO2HOfnrXGEBvny9YTuXNy6frlc39vDndv7NWNUtxA+WRnLzuOpfHRjV0nYokKRpC2EKHdaa46nnCbqUDJRh5OIOpTMnpPpaA1e7m7cN6gF91zc4oKjup3F39eTJy9rW+7XFcIekrSFEE6Xb7EScyKdqENJRB1OJupQMifSsgGo5e1Bl9AALuvQiO5hgXQKCaCmt7w1CVEY+Z8hhHC4zJx8thxJ+bcVveVIMpm5FgAa+fvQPTyI7mGBdGsaSJuGtWUdaiHsJElbCOEQmTn5fPjHPtbsT2D3P+lYrBqloE3D2ozsGkxkWCCRYUE0Cajh6lCFqLQkaQshyiw7z8KdM6NYuz+RnuF1uHtgcyLDgugSGkBtH/tKhQohiidJWwhRJvkWK/fN2sKa2ETeGdWJa7sFuzokIaosmcsghCg1q1Xz+I/b+T36JC9e3V4SthBOZlfSVkoNU0rtUUrFKqWeKOT5pkqpP5RS25VSK5RSwQWeG6+U2mf7Gu/I4IUQrqO15oVfdvHTluM8ekkrxvcJc3VIQlR5xSZtpZQ7MBm4DGgH3KiUanfObm8DM7TWHYGXgNdsxwYBzwM9gR7A80opxxQNFkK41DtL9zJj7WHu7N+Mey5u4epwhKgW7Glp9wBitdYHtNa5wGxg+Dn7tAP+tP28vMDzlwK/a62TtNbJwO/AsLKHLYRwpc9W7ufj5bHc2COEJy9rI3W5hSgn9iTtJsDRAo+P2bYVtA0Yaft5BOCnlKpj57Eope5USkUppaLi4+PtjV0I4QLfrT/Ca4tiuLJjI165JkISthDlyFED0R4FBiiltgADgOOAxd6DtdZTtdaRWuvIevXqOSgkIYSjLdgWx9Pzd3Bx63q8e31nKYoiRDmzZ8rXcSCkwONg27Z/aa3jsLW0lVK1gGu11ilKqePAwHOOXVGGeIUQLvJnzEke/n4r3cOC+HRsN1lIQwgXsOd/3UagpVIqXCnlBYwGFhTcQSlVVyl15lxPAl/Zfl4CXKKUCrQNQLvEtk0IUYmsO5DIXd9spm2j2nw5PtIlC3kIIexI2lrrfOBeTLLdDfygtd6llHpJKXW1bbeBwB6l1F6gAfCq7dgk4GVM4t8IvGTbJoSoJLYdTeG2aRsJDfJl+q098JMKZ0K4jNJauzqGs0RGRuqoqChXhyGEAPaeTOf6z9bi5+PBnIl9aOjv4+qQhKiSlFKbtNaRxe0nN6WEEIU6kpjF2C/W4+Xuxre39ZKELUQFILXHhRDnOZmWzZgv15FrsfLDxN6E1vF1dUhCCKSlLYQ4R3JmLmO/WE9SRi7TJ/SgVQM/V4ckhLCRlrYQ4l/p2XmM/3oDh5OymD6hB51CAlwdkhCiAGlpCyEAsyb27dOjiI5L49MxXendvI6rQxJCnENa2kJUM1pr0nPyOZWWQ3x6DqfSs4lPz2HZ7pNsOJTE+zd0ZnDbBq4OUwhRCEnaQlQR+RYrCRm5ZyXiU+kmMf+7LSOHU2k55ORbzzu+hqc7/xsRwfDO5y0PIISoICRpC1GJZedZ+CHqKF/9dZDDSVkUVnYhwNeTerW8qefnTbfQQOr5eVPfz8f23Wyv5+eNfw1PWfxDiApOkrYQlVB6dh7frDvCl38dICEjl25NAxneuclZibh+bR/q1vLC20NKjgpRVUjSFqISScrMZdqag0z7+xBp2fn0a1mXey9uQY/wIGklC1ENSNIWohI4kZrN56sP8N36I5zOszCsfUPuvrg5HYNlSpYQ1YkkbSEqsCOJWXy6cj9zNx3DojXDOzXmroHNaSkFT4SoliRpC1EB7TmRzqcrYlmwLQ4PNzdGRQYzsX9zKScqRDUnSVuICmTb0RQmL49lafRJfL3cua1vOLf3a0aD2rJYhxBCkrYQLqe1Zt2BJCYvj+Wv2ARq+3hw/+CWTOgTRmBNL1eHJ4SoQCRpC+FCu+JSeXFBNBsOJVG3ljdPXtaGMb2aUstb/msKIc4n7wxCuEDq6TzeXbqHmesOE+jrxUvD23N9ZAg+njKnWghRNEnaQpQjq1Xz05bjvL5oN0mZuYzt1ZRHhrbG39fT1aEJISoBSdpClJPouDSe+3knUYeT6RIawLQJPejQxN/VYQkhKhFJ2kI4WerpPN77fS8z1h4iwNeLN6/tyHXdgnFzkwpmQoiSkaQthJNorflp83FeW7SbxMxcxvZsyiOXtCLAV0aECyFKR5K2EE4QHZfG8wt2svFQMp1DAvj6lh5EBEtXuBCibCRpC+FAadl5vLvUdIX71/DkjWsjGNUtRLrChRAOIUlbCAfQWjNvy3H+91sMiZk5jOkZyqOXtJaucCGEQ0nSFqKMdv9jRoVvPJRMp5AAvrolUlbfEkI4hSRtIUopIyefd5fuZfraQ9T28eD1kRFcHyld4UII55GkLUQJaa35bccJXlq4i1PpOYzuHsrjl7aWOuFCCKeTpC1ECRxOzOS5n3excm887RrVZsrYbnQJDXR1WEKIakKSthB2yMm38NnKA0xeHounuxvPXdmOm3s3xcPdzdWhCSGqEUnaQhRjTWwCz87fyYGETK7o2Ihnr2hHQ39Z31oIUf4kaQtRhFPp2bz6625+3hpH0zq+TL+1BwNa1XN1WEKIakySthDnsFg1364/zFtL9pCTZ+X+wS25e2BzWTZTCOFykrSFKGDHsVSenr+D7cdSuahFHV4e3oFm9Wq5OiwhhAAkaQsBnF1+NKimNx+M7szVnRqjVDWZc601RH0JbYdDLbkFIERFJUlbVGtaaxZu/4eXFkaTkJHDuF5NeeSS1vjX8HR1aOXr6Ab49RFIiIXLXnd1NEKIIkjSFtXWwYRMnvt5J6v3JRDRxJ8vx1fj8qMxv5jv22fD0BfBw9u18QhRmD2LoX4bCAxzdSQuI0lbVDvZeRY+XbGfT1fux9vdjZeGt2dMz6a4V9fyo1rD7oVQsx5kxkPMQuhwraujEuJsB1fBrBvAyw+ueh8irnN1RC4hlSFEtbJqbzzD3l/FB3/sY1j7hvzxyABu7h1WfRM2QHwMJB+EAf8H/qGweaarIxLibJZ8WPSE+fts0A7m3gY/3wu5Wa6OrNxJS1tUCyfTsnl5YTQLt/9DeN2afHNbT/q2rOvqsCqGmIXme5srISsRVrwOKUcgINS1cQlxxuZpcGoXXD8DWl8OK16D1e/CsY0wahrUb+vqCMuNXS1tpdQwpdQepVSsUuqJQp4PVUotV0ptUUptV0pdbtseppQ6rZTaavua4ugXIMSFWKyaaWsOMvidlSyNPslDQ1qx6IF+krALivkVmkRC7UbQeYzZtuVb18YkHCftH0iLc3UUpZeVBH++AmH9oO3V4O4Jg5+DcT+Z56ZeDJummds81UCxSVsp5Q5MBi4D2gE3KqXanbPbM8APWusuwGjgkwLP7ddad7Z9TXJQ3EIUa9vRFIZP/osXfommS2gASx/szwNDWkqRlIJSj0HcFmhzhXkcEALNL4at34LV4trYRNkdWAGTe8LUgZAR7+poSmfFa5CdCpe9AQWnYDYfBJP+gtBe8MsD8OOtkJ3mujjLiT0t7R5ArNb6gNY6F5gNDD9nHw3Utv3sD1Tij3Wisks9ncez83dyzSdrOJWWw8c3dWHGrT0Iq1vT1aFVPHsWme9trvxvW5dxkHrUvOGLymvzTPjmWvBrAKdTYN5EsFpdHVXJnIyGjV9C5K3QoP35z/s1gLE/mZZ39M/wWT84vtm5MVmtcHC1y+6n25O0mwBHCzw+ZttW0AvAWKXUMeA34L4Cz4Xbus1XKqX6lSVYIS5Ea838LccZ/M5Kvl1/mPG9w/jjkQFc2bEaFUkpqZiFUKcl1Gv137Y2V0CNINg8w3VxidKzWuGPl2DBvaZL+fZlMOw12P8H/P2hq6Ozn9aw+Anw9oOLny56Pzc36PcITPjNDFj78hJYO9nx3eUJsaab/oNOMP1K2PObYzz1IDAAACAASURBVM9vJ0cNRLsRmKa1fkcp1RuYqZTqAPwDhGqtE5VS3YD5Sqn2Wuuz+jCUUncCdwKEhsrgF1Fy++MzeHb+Tv7en0inYH+mTehOhyb+rg6rYjudDIf+gt73nr3dwxs63gAbv4DMRKhZxzXxiZLLy4af74adc6HreLjiHXMPOPJWOLjSJPOmfSCkh6sjLV7MQhPz5W+Db1Dx+4f2gkmrzajyJU+ZKWLDPynb3+/pZNj5E2ybDcc2gHKDZhfDkOfNgDgXsCdpHwdCCjwOtm0r6DZgGIDWeq1Sygeoq7U+BeTYtm9SSu0HWgFRBQ/WWk8FpgJERkZWj9EEwiGy8yx8sjyWKSsP4O3pxsvXdOCmHqHVewqXvfb9Dtb8s7vGz+g6DtZ/Ctu/h953l39souQyE2H2jXB0PQx5ES564L97wErBVR+a8Qs/3mqSW41A18Z7IXnZsORpqN8Ouk2w/zjfIBj9LWyYCkufgSl94dovIOwi+89hyYPYZbBtlrl9ZMmFem1h6EsQcb0ZsOlC9iTtjUBLpVQ4JlmPBm46Z58jwGBgmlKqLeADxCul6gFJWmuLUqoZ0BI44LDoRbW2Ys8pnvt5F0eSshjRpQlPXd6Wen5SyctuMQuhVgNo0u385xq0N9u3zIRed509AKgysFrArRoNOEyIhW+vM6PER02D9iPO36dGAFw3Db66xLRGb/im4v67rv0YUg7DzQvAvYQdwkpBz4kQ0hN+nGC6sgc8Af0fLfpvQms4sR22zoIdcyArAXzrQuRt0Gk0NOpUYX5Xxf42tNb5Sql7gSWAO/CV1nqXUuolIEprvQB4BPhcKfUQZlDaLVprrZTqD7yklMoDrMAkrXWS016NqBb2x2fwxqIYlkafpFm9mnx3e0/6tJApXCWSlw37lkHH6809wcJ0GQcLHzQDe4ILSewVUW4WLHkSdvwI130NrS5xdUTOd2gNzL4J3DzgloUX7voO7gZDXjCt0I1fQI87yitK+6XFmTnYba+CZgNKf57GnWHiKlj4MKz4HxxabVrdfg3/2yf9BGz/wbSqT0WDuxe0Ggadb4IWQ8ythQpG6Qo2ty0yMlJHRUUVv6OoduLTc/jgj73M2nCUGp7u3DWwObf3C8fboxq1qBxl7xL47noYO9e8ORUmOw3eaW0S+1UflG98pXEqBubcAvG7oXYwZJ6yFeO4zNWROc/2H+Dne0wt7pt+gKDw4o+xWk050AMrzCC1Rp2cHWXJzL3DjAS/d4NjaoxrbaYw/vYYePrC1R9BXpZJ1Pv/BG2F4O7Q6UbTQ2HP/XMnUEpt0lpHFrefVEQTFV5mTj6frz7A1FUHyM23MrZnKPcNbkndWlWgKzw3E2aOhPbXmG7o8hKzELxrQ1j/ovfxqQ3troEdc+HS/4FXBZ0yp7Xpxv/tcRPj2Lmma3/mSPh+HIz62rTaqhKtYeWbpgUZ1g9umGn/PWo3N7hmCky5COZMgIkrzQjtiuDIetjxA/R71HGLgigFXcaaxDxngrnvD+AfAn0fNsm6bgvHXKscSNIWFVa+xcr3UUd57/d9JGTkcHlEQx67tA3hVWm+9bIX4Og6SNgD3W4BzxrOv6bVYgbYtBwKHl4X3rfrONj2HeyaD13GOD+2kspOg4UPwc4fIXwAjJz6X/fnzfPNPOU5t8C1X5oPRlVBfi78cr9pKXa6yfSCFPfveK6adUxX8fSrzJKsIz5z/T1bqxUW/x/4NYZ+Dzv+/PVawx1/mN9bnRbQtG/Rt4YqsMoXsXCtTdPMiMxN082bhxNorVm66wSXvr+Kp+ftJLyuLz/d3YdPxnSrWgn7wEozyrVpXzO1ZMec8rnusY1mNa8zVdAuJLS3eYPbUgEXEYnbAp/1h10/waBnYNy8s+9X+vibwhtNupkR0zvnui5WRzmdDN+MNInn4qfhmk9KnrDPCOtrBmht/x62fufYOEtj67fm33Toi87r1fGsYaa/hfevlAkbJGmLktg1H3550JS+/OV++KirqVaUn+OwS2w+ksz1n63lzpmb0MDUcd34YWJvuoZW4OkppZGdZu5FBjWHMXOgQQdYP7V86ifHLAQ3T2gxtPh9lTID0o6shYR9zo/NHlrD2k/gi6FmOs4tv0H/xwofGexT23SXh/SEubfD9nL6YOQMSQfNaz66HkZ+DgMeL3vruP+jpnv9t0chfo9j4iyN7DT440Xz7xQxynVxVAKStIV9Dq6Cn+4wI1MfijZvhH6N4NeH4YPOsP4zyDtd+tMnZHL3t5sY+cnfHEzI4tURHVj6YH8uad+walYzW/o0pB2HEVPAy9dMUTm5Aw7/7dzrnlk7u9kAk9Ds0elGUO4Vo7WdlWRGSi950nTvT/oLmva+8DHefjD2R2h6Ecy700zrqWyOboAvBpupSOPmm8GBjuDmbj4AePqa2whl+D9cJqvehMyE8+uLi/NI0hbFO7EDZo+BoGZw42yTZFoMgduWws0/mwEjix435f3WTi5RTd6EjBye+3knQ99dyYo98Tw0pBUrHxvImJ5N8XCvon+ee5eaEqF97v9vek7EKDOQaL2TF8I7tdusnW1P1/gZfg3MNJits0zhCVc5vNbcmoldBsPegNHf2T/S16umGV0d3h/m31W51gzfNQ+mXWm6+29bVrJCIfao3cjc0z4VDYufdOy57ZEQC+ummMFijbuU//UrmSr6rigcJvmQGczj7Wda1wXfJJWCZgPh1kVwy69moMeSp+CDjrDmA8jJKPK0Wbn5fPTHPga8uZxv1x9hdI8QVjw2kAeGtKSmdxUeH5mVBAvuMxWWLn7qv+2eNUzZyZhfIeVo0ceXVcyv5ntJSzB2HWemUO1b6viYimO1wKq3YNoVpsTqbb9Dr0klb5F5+ZoPnc0vNnW5o752TryOojX89Z5pATfuYhK2s0Y5txxiKqht+tqU7SxPS54yf/+Dnyvf61ZSkrRF0TITzLSZ/BwzoMc/uOh9w/rC+F9gwmJoGAG/PwfvR8Dqd85aLi87z8KMtYcY+NYK3vl9L31b1mXpQ/155ZoI6vv5OP81udqi/zNdnCOmmARUUPfbAA1RXzrv+jELzdSXggO27NFiKNRqWP4t1PQTMHOEWaihw0hTLKNx59Kfz7MGjJ5lXs/CB02BkYrIkmfGjSx7ATpca3q0nF0DftCz5m/jlwfM/fPysO932LfE3J+vVb98rlnJSdIWhcvJgG9HmepEN/0A9dvYd1zT3mYU7+1/mDeAP16C9yPI+eM1vlq2lb5vLOe5n3cRGuTLj5N689m4SJrXq+Xc11JRRC8wc1D7P1Z44gkINd3Wm6Y7595i6jH4Z2vJusbPcPeAzjeaN9i0fxwfW2Fil5nu8GMbYfhkc+/VEfOJPX1MfepWl5npTus/K/s5HSk71fzf2zzD/K2M/MLE7GzunmZqnFKm/KeTZof8Kz/XrOJVpwX0mOjca1UhkrTF+fJz4Yeb4Z9tpjBFaM+SnyM4Esb8QNq4ZcT6dsJ79etct3oYT/v+xJyb2zBnUm8iw1xTecglMhPMfOJGncwygkXpMRFOJ5kynI4WY1tKsLAFQuzRZZypHrXNydODLHnw+/PmtkzNenDnCnO/05EDlDy8TbW0Nlea8RhrJzvu3GWRcgS+vNSU3Bw+2UxlK8+pSYFN4eqPzdSrP1507rU2TIXEWLj0tdJPW6uGJGmLs1mt5n7f/j/gqvdLXQLyZFo2r/4aTa/piQyJm8jLwZ9hDR/IiLRv6T6/P+r3ZyF+r4ODL4H0k2bwS/QC519La9MVm5NmKlFdqJ5xWF+o3960/hw9/StmIdRtBXVblu74Os3NCOwt3zhvalrGKfj6cljzvlnd6Y4/zVgJZ/DwMotrtL3a3Fdd4+JSrcc3weeDTe/W2J/MBxVXaHc1dL/DLNqxZ7FzrpFxCla+AS0vqR714R2oCo/4EaXy+7Om2MKgZ6HrzSU+/GhSFlNW7mdO1DEsWnN1p8bcNbA5rRr4AaPh5C5Y9baZZ/v3R9C4qynO3+Fa59f8zTttBmJtm20+lGir2d77Xhj6svNaNDt+hN2/mIUaGrS78L5nVij65X4zN7ppH8fEcGbt7IvuL9t5ut4M8ybC4TXmA4Yj5aSblaoS9hW9UpWjuXvCdV/BT3eacRjW/Av3hDjL7oVmHnmtemZsiL23o5zlkldMpb75k2DSGvBv4tjz//GSqf996WuOPW81IElb/Ofvj8yn6x53lviNa9/JdD5ZsZ8F2+JwV4rrIoOZ1L85oXV8z96xQXvT5Z5+0lQA2zbbFHZY/CS0utTMCW55ieO6y7SGI+v+K8WZk2YWk+j7kFkbN+pL85qTD5l7pl6+xZ6yRNL+Ma8vuLuZ4mWPiFEmgayf4rikvXcpaEvpu8bPaHu1WXhh80zHJu38HDOt8MROuOl7Mwe7vLh7mn97N3eTTKwWMzCqPGgN6z4xa0c36WpGt1eEAVmePmYZz8/6mw8T438p+RKZRYnbYnpret9TqWp+VxSStIWx7XuzXF+7a2DY63bfP9x+LIXJy2NZsuskNTzdmdAnjDv6N6NB7WIGzvg1gD73mq8TO0zy3v6D6cKtEQQR15l1bBt3Ld29zKSDtnPONgnZsya0G27OGdbvv1b15W+Z+eeLnzTr7jryTVNr02LOzzHd4vau7+zlC93Gw98fm8FjFxq1b6+YhaYYTuOuZTuPl6/5t9k6yxTCqBFQ9tisVpg3CQ6uhGs+Ld+EfYa7h5mr7OYBy181Le6BTzq30Icl39Ta3viF+TA04jPHf2gsi7ot4Mr3TEGalW/AoKfLfk6tzQyKmnXL74NRFSNJW5h1lX++2xSeGDm12OSitWb9wSQmL49l9b4Eavt4cP/glkzoE0ZgzVK0kBtGmK8hL5ql8rbNMiOoN0yFuq1Nou14Q/FddNmppjW9bZbpWkaZyl8DnzQtTO8iRqn3usuM3J57u7mnOGaOY7ont3xj5jUPe6PkLYrut5uej41fwpDnyxZH3mmI/cP8Hh1xC6DLOIj6yizS0f32sp1La3M/eddP5vZB55vKHl9pubmbwV9u7iZJ5Waa0duO+GByrpx0Uw9931LTAzPkxYpZC7vTDebD1Kq3TPGfRp0gIMQs6lGalveOH00Z1qs/NsViRInJetrV3fFNMO0qqNPM1HAuprTl+gOJvLVkD1GHk6lby5vb+4Uzpmcofj4OXiz+dApEzzctuqPr+DcBd7rRLLN4ZkEBSz4cWG4SdcyvkJ9tBlt1utGUeixJKzVuC3x3A+Rlww0zTOGY0ko5Ap/0MVO7bl5Qujfk2WNMWdOHo8u2+teexWb95LE/QYvBpT/PGVqbqVhuHmZZx7L46z0zF7nX3Wb5z4pQwtJqNeV5N30N7t5mMGbnm6D5oAsPIrRX6nHzd3YqGq542yxgUZHlZpoR7Sd3/LdNuUPtJubDbkCI+e4f8t/j2sHn3+LKzYSPIk1P1h3LK+aHFBeydz1tSdrVWUIsfHUJeNUyVab8GhS566m0bF5bFMO8Lcdp7O/DXQObMyoyBB9PO7t8yyLpgOm+3zYLUg7/19XtG2Tui2ecNK2ADteZucSl7VIHU43su+shYS9c+b6pBFZSVivMHA7HN8Nda0q/LvDBVWbpxOGTyzaS+Od7IfpneGy/48YKrJtiunYn/WV6SUpjy7emh6fDdbZ7yhXoTVxr8yFu22zzN3Y6yUw/i7je9Fg06li68/6zzSTsnAy4fpopB1wZWPIg+TCkHjEfSFOOmu+ptu9pcUDBXKLM7ZiCST35kFlp7dalpZtGWsVJ0hYXln4Cvhxq6oTfttRM5ylEvsXK9LWHee/3veTmW5k4oBl3D2xBDa9ySNbnslpNq3urbVBZ/mlTE7vTaGh5qeMSUnaqKR25/0/o+7AZSV+ShLLhczP47Mr3IXJC6ePQGj7tY7prJ64u3QcRqwXebmV6Da5zYKW1rCR4p7WZlnX5myU/fu8SmHUjhPeDm+ZU7Hm6+bkQ+7v50LhnMVjzzKpsnUabQYP2VpfbuwTmTDDd7Tf9AA07ODfu8pSfaxbAOZPEz0rsR0zvgraYHrARTq6vX0lJ0hZFy06Fr68wLdhbFppRq4XYcDCJ537eScyJdAa0qscLV7evOOtZ5502n/7tXamqpCx5plrW5unQfqQZIGVPVarE/abrOLS3qdVe1u7eqK/NHO8Ji4tfzaowh9fC18Pguq9NGVBHmjPBfLB5ZE/JKnYd3Wh6EOq1MjXrHVHlrLxkJZnW4rZZ5taScoPmg00Cb3NF0bcxNnxuirg0jIAbvzeLdFQnlnzTI1arvmNuMVRB9ibtCtQfJcpFXra5VxofA6O/KTRhn0rP5uHvt3L9Z2tJz87ns3HdmDahe8VJ2GDeHJ2VsMG8sVz1gRkgtOsnmHG1qWp2IVYLzL/brFV99UeOuT/b8XrwCSj96l8xC8HdyzndsF1vhuwUcw17xe+F72yt0zE/Vq6EDeaWTI87TNGXezbCRQ+ae9NzbzM9GgvuMx+UzjSGrBYzM+G3R01v0IRF1S9hgxm05t9EErYDyOjx6sRqMWtiH1ptagw3H3TW0/kWKzPXHebdpXvJybdy78UtuOdiF3WFVwRKQd8HzT3peRPhiyFmZHlRFcXWfWK670d85rhiFF41TXJcO9l0MZbkvFqbwXnhJVg7uyTCB5h7lVtmmmlgxUmLg29GmgFs436qGPORy6JeKzOyf9Cz5v/UtlmwY66pGR4YBh1Hm+mMe36FnnfBpa/aP+1PiCJIS7s62TAVdi8wo3TPeZPdeCiJKz/6ixd/iaZzaACLH+zHo5e2rr4Ju6D218D4hWaazhdD4NCa8/c5FQN/vAytrzDT0xyp++2UavWvU9ElXzu7JNzcoPNYOLDCDDK6kNPJppb46WTTwg5q5pyYXMHNzcxsGDEFHt1r5uQHNDXTxvYugsvehMtel4QtHEKSdnWRm2mWyQzvbyoR2cSn5/DID9sYNWUtaafzmDK2KzNu7UGz6rLylr1CusPty0zrcMZwM5r9DEu+KffoVdPUa3f0tKXApmb9603TzO0Ne8X8CqiSr51dEp1vMtfY8m3R++Sdhlk3mfKkN3xTtqU1KzrvWmYGw/gF8NBOuDfKlKUVwkEkaVcXG7+EzHgY+BRgusKnrTnIoHdWsGDbce4e2JxljwxgWIdGqIowV7YiCgo3I+1De5kqUSteN13Qf71npgdd+a7zunx73AlZiWYQlL3+XTu76Kl8ZRYQYm6zbP3W3H45l9ViitYcWQsjP4PmFzsvlorGP7jIWRlClJYk7eogJ8OsmtR8EDTtTdShJK76eA0v/BJN55AAFj/Yn8eHtcHXS4Y4FKtGoClS0ukmWPGamba08g2z4IkzF7gI7w/12poBafbM+Eg5auYEO6trvKCu48x0n/3Lz96utRmBH7PQlMbtcK3zYxGiipOkXR1smApZiexufS+PztnGdVPWkpKVy6djTFd4c+kKLxkPL7jmE7j4GXPP0jcILn/buddUCnreCSe2mzKQxdlTxrWzS6L15aZe/JYZZ29f+YapKtb3Ieg1yflxCFENSNOqisrOs7D1aApb9h5h7Pp32aS7cMtP2Xi6H+eugc25b1ALaVmXhVIw4DFzr7tmPecvKwpmgNuyF0xrO7TXhfeNWWjqtpfHKkoe3mae8obPzbS4mnXN7ZgVr0HnMTC4jLXThRD/knftKiIrN5/Nh1NYfzCR9QeS2Ho0hVyLlfs85uHnkc7etvcypUM3eoYHlW5RD1G4ZgPL71peNc1iHes+vfD0r6wkM8K974PlF1uXcWbK2/bvzTSw3x41S6xe9UHFqCcuRBUhSbuSysjJJ+pQEusPJrH+QCLbj6WSb9W4KejQxJ/xfZpyURNPBixaCmFXcOdoO+bRioqvxx1mznbUVzD42cL32Xdm7exyuJ99RoN20CTSLCealQhNusGoaVJMQwgHk6RdSWitWbUvgTWxCaw/kMjOuDQsVo2Hm6JjsD939G9Gz/AgujUN/G/FreWvQU4qDHzCtcELxwkMM6tObfraLBtZWPnQmIVm6cRGXco3tq7j4JcHzCprN/3w30psQgiHkaRdSUz7+xAv/hKNl7sbnUMCuHtgc3qG16Fr04DC701nJZnuyrZXl35FIlEx9ZxoBprt+un89afPrJ3d+abyXzWr4w2Qccpcuzzu8QtRDUnSrgSOp5zmrSV76N+qHlPHdbNvOcy1H5sKXgOfdH6AonyFD4B6bcy97U43nn3P+MAKyMsq367xMzxrwIDHy/+6QlQjMuWrgtNa8/zPO9EaXr2mg30JOzPRrHfcfoS51yiqFqVMsZXCpn/FLARvf2ja1zWxCSGcSpJ2Bbd45wmW7T7Fw0NbERLka99Bf39gWltyL7vq6jTaJOf1n/23zWqBPYug1SUVe31qIUSpSdKuwFJP5/H8gl20b1ybCReF2XdQxikzXzZiFNRr7dT4hAt51TQDv6J/NqtngWl1ZyW6pmtcCFEuJGlXYG8ujiEhI4fXRkbg4W7nP9WaDyA/Gwb8n3ODE67X/XbQVjP9C8wCIc5aO1sIUSFI0q6gog4l8e36I9zSJ5yOwQH2HZR+AjZ+YdbxLY9KWMK1gsKh1TCI+tqs/hWz0BR78fZzdWRCCCeRpF0B5eZbefKnHTQJqMEjl7Sy/8C/3gNLnimvKaqHnhMhKwGWv2LWtJaucSGqNJnyVQFNXbWffacy+OqWSGp62/lPlHrctLi6jIGgZs4NUFQczQaaGuN/fwQoaHWZiwMSQjiTtLQrmAPxGXz4ZyxXRDRiUJsSrIO8+h1zf7Pfo84LTlQ8Z1b/Agjp4dy1s4UQLmdX0lZKDVNK7VFKxSqlzptHpJQKVUotV0ptUUptV0pdXuC5J23H7VFKXerI4KsarTVPz9uJt4cbz19VgvnVKUdg8wwzmjiwqfMCFBVTx9EQGA5dxro6EiGEkxXb96qUcgcmA0OBY8BGpdQCrXV0gd2eAX7QWn+qlGoH/AaE2X4eDbQHGgPLlFKttNYWR7+QquDHTcdYeyCR/42IoH7tQmpKF2XV26bF1e8R5wUnKi7vWvDAVldHIYQoB/a0tHsAsVrrA1rrXGA2MPycfTRQ2/azP2CbOMpwYLbWOkdrfRCItZ1PnCMxI4dXf9tNZNNARncPsf/ApIOw9Vvodgv4BzstPiGEEK5nT9JuAhwt8PiYbVtBLwBjlVLHMK3s+0pwLEqpO5VSUUqpqPj4eDtDr1pe+XU3mTn5vDYyAje3Eqw/vOptUO7Q92HnBSeEEKJCcNRAtBuBaVrrYOByYKZSyu5za62naq0jtdaR9erVc1BIlcfqffHM23KcuwY0p2WDEsyxTdwP22ZB99ugdiPnBSiEEKJCsGc+0XGgYH9tsG1bQbcBwwC01muVUj5AXTuPrdZO51p4et5OmtWtyd0Xl7Agyso3TQWsix50TnBCCCEqFHtawxuBlkqpcKWUF2Zg2YJz9jkCDAZQSrUFfIB4236jlVLeSqlwoCWwwVHBVwUf/LGPI0lZ/G9khH0reJ0Rvxd2/AA9bpdpPkIIUU0U29LWWucrpe4FlgDuwFda611KqZeAKK31AuAR4HOl1EOYQWm3aK01sEsp9QMQDeQD98jI8f9Ex6Xx+eoDXB8ZTK9mdUp28Mo3wKOGtLKFEKIasavcltb6N8wAs4LbnivwczRwURHHvgq8WoYYqySLVfPkvB0E1PDkqcvbluzgU7th51zo+yDUrOucAIUQQlQ4UhHNRWauPcS2oyk8d1U7AnxLuPbxitfAqxb0ud8psQkhhKiYJGm7QFzKad5asof+repxdafGJTv4xA6zhnKvu8A3yDkBCiGEqJAkaZczrTXP/bwLi9a8ek0HlCrBnGyAFa+Dtz/0vts5AQohhKiwJGmXsyW7TrBs90keGtKKkCDfkh0ct8Wsmdz7HqgR6JwAhRBCVFiStMtRWnYezy/YRbtGtbmtb3jJT7DidfAJgF6THB+cEEKICk+Sdjl6a/Ee4tNzeG1kBB7uJfzVH90AexdDn/vAx985AQohhKjQJGmXk02Hk/lm/WHG9wmjU0hAyQ62WmHR/0GthtBzonMCFEIIUeHZNU9blE1mTj5P/bSDRrV9eOSS1iU/wfbZELcZrpkC3iWoTS6EEKJKkaTtZFuPpvDg7C0cTsriy/GR1PIu4a88Jx2WvQBNIqHjDU6JUQghROUgSdtJLFbNpytieW/ZPhr4eTP7jl70LGmpUoBVb0HGSRg9C9zkboYQQlRnkrSd4FhyFg9/v40Nh5K4smMjXh0RgX8Nz5KfKHE/rP0EOt0Ewd0cH6gQQohKRZJ2cfKyYcX/oNONUL/4GuE/bz3OM/N2ooF3r+/EiC5NSl5A5YwlT4OHNwx5vnTHCyGEqFIkaRdn3WRY8wHs/gUmripyIFhadh7Pzd/J/K1xdGsayPs3dC558ZSCYpfB3kUw5EXwa1j68wghhKgy5CbphaTFwap3oGFHSD4ECx8Crc/bbeOhJC57fzW/bP+Hh4a04vs7e5UtYVvyYPGTENTM1BgXQgghkJb2hS17Eax5cP102PEjLH8VwgdA13EA5FmsfPjHPiYvjyU40Jc5k3rTNdQB5UU3fA4Je+HG2aZ7XAghhECSdtGObjTzo/s+ZFq8/R6BQ6vht8cguDuH3EJ44PutbDuawrVdg3lxePuST+cqTGaCKVfafDC0Glb28wkhhKgyJGkXxmqFRY+bCmT9HjHb3Nxh5OfoTy8ideZYRqQ+h8XNm49v6sKVHUu4vOaF/Pky5GXCsNehtAPYhBBCVElyT7sw274zFciGvnjWwLMU9yA+DniMgPR9vFXrOxY/2N+xCfufbbBpOvSYCPVaOe68QgghqgRJ2ufKTjP3soO7Q8T1/27+OzaBYe+v5oNDoWwOuYUhWYtofOw3x11Xa1Nf3LcODHjccecVQghRZUj3+LlWvQWZp8wgnw+FTgAAERFJREFUMFsFsreWxPDJiv2E16nJvLsvIqLRUPg6GhY8AI27mHveZbVzLhxZC1d9ADVKuKCIEEKIakFa2gUlxMK6T6HzmH8rkB1OzGTy8v1c2bExC+/vS0SwP7h7wnVfmqT+462Qn1u26+Zmwe/PmallXcY54IUIIYSoiiRpF7T0afDwgcH/VSA7EJ8JwPjeTfH1KtAxERAKwz+BuC1mQY+yWPM+pB2Hy94wA96EEEKIQkjSPmPfMti7GAY8Bn4N/t18IMEk7bC6Nc8/pu2V0ONOUzVtz6LSXTfliKm41uFaaNqndOcQQghRLUjSBtO9vfgJc2+656SznjqUkImfjwd1anoVfuzQl6FhBMy/C1KPlfzaS58FFAx9qeTHCiGEqFYkaQNs/BwS98Glr51XgexgQibhdWsWveiHpw9cN82UHp17O1jy7b/uwdUQPR/6PQz+waWPXwghRLUgSTsj3lQgazEEWl163tNnkvYF1W0BV75nRn+vfN2+61ryTevePxT63FeKwIUQQlQ3krT/fAnyskwr+5zWdHaehbjU04TVKSZpA3S8HjqPhVVvw4EVxe+/eTqc3AmXvAyeNUoXuxBCiGqleiftuC2weWaRFciOJGWhNcW3tM+4/E2o2wrm3gEZp4re73Qy/PkKhPWDdsNLGbwQQojqpvomba1h0RMXrEB20DZy3O6k7VUTRn0NOWkwb6KpYV6Y5a9BdorUFxdCCFEi1Tdp75wLR9fB4OeKrEB28ELTvYrSoL1Jxvv/NPOvz3VqN2z8ArpNgIYdShO5EEKIaqp6Ju3cTDPVqmFH6DK2yN0OJWRSp6YX/jU8S3b+brdA+xGmC/zI+v+2a20Gn3n7waBnShe7EEKIaqt6Ju2/3of0OLjszQtWIDuQkFmyVvYZSpka4gEhpsxpVpLZHvOrGaR28dPgG1S62IUQQlRb1S9pJx+Gvz+EDtdB094X3PX/27vf2Lrq+47j72+cf5jQ4CQuLfnrTEEgrRJUHusGmtgDWLpNg0kTCo+oJi2TtqCNB1NZN7WIqSqatnVPUDUm0rXSCqq6jUUTGkUCxLR1W0LFRhMGTW2zxIUkdhIg1/ln57sH93i9mCS+177Jveee90uy7HvuOddf/3SiT845vz9jE7Xmeo5fzMrV8Btfh1NHYM9DcP4MPP8FGLwFhn9zYZ8pSaq06oX2d/8YYsm8M5DVzk5z9IOzbB1cYGgDrP90fU3u//kn+JtfgZNvw2cfhz4XV5Mkta5aoT36CryxB+58GFavv/yus53QFnqlPeszvwM3bYfxfXDzr8LWuxb3eZKkyqrOJd/MdH2I1/XNzUA2NtnicK9LiYD7vlZfp/vndi3usyRJlVad0H7163B0P9z/zaZmIBs9Njvcq3/xv7t/DWz/yuI/R5JUadW4PT51HF76cn0Gslt+ralDRidrfOJjKz+8hrYkSR1UjdB++Stw5r2WZiAbm6i15ypbkqQ2aSq0I2J7RLwZEQcj4pGLvP/ViHit+HorIk42vDfT8N6edhbflCMHYO9T9WFWLcxA1tTqXpIkXUXz3vuNiD7gCeBu4DCwNyL2ZOaB2X0y8+GG/R8Cbmv4iNOZeWv7Sm5BJvzz5+szkP3iHzV92Mmpc5yYOm9oS5K6SjNX2rcDBzNzJDPPAc8Al1ua6gHg6XYUt2injsLxsfqUoS3MQNa24V6SJLVRM72s1gOHGl4fBn72YjtGxGZgCHixYfPKiNgHTAOPZ+azC6y1ddfdALv+E5a0Nnf47HCvRU2sIklSm7W7a/QO4DuZOdOwbXNmjkfEVuDFiHg9M3/UeFBE7AR2AmzatKm9FTUxvGuu0WM1lgRsXGNHNElS92jm9vg4sLHh9YZi28XsYM6t8cwcL76PAC/z4efds/s8mZnDmTk8ODjYRElX1ujkFOsHrmHF0ksvJiJJ0tXWTGjvBbZFxFBELKcezB/pBR4RNwMDwPcatg1ExIri53XAHcCBucd2m0UtFCJJ0hUyb2hn5jSwC3geeAP4dmbuj4jHIqJxppIdwDOZmQ3bbgH2RcR/AS9Rf6bd1aGdmQ73kiR1paaeaWfmc8Bzc7Z9cc7rRy9y3L8Bn1pEfVfdxKlznDo7bWhLkrpONWZEa8H/D/cytCVJXcbQnmOsCO2thrYkqcsY2nOMTtZYuiRYf33rQ8UkSbqSDO05Ro/V2LSmn6V9No0kqbuYTHOMTdpzXJLUnQztBhcu1Id72QlNktSNDO0G775/hrPTF7zSliR1JUO7wWzPcUNbktSNDO0GI4a2JKmLGdoNxiZqrFi6hE98bGWnS5Ek6SMM7QajxUIhS5ZEp0uRJOkjDO0Gow73kiR1MUO7MD1zgUPHpxzuJUnqWoZ2Yfzkac7PpHOOS5K6lqFdcHUvSVK3M7QLPwnt/g5XIknSxRnahbGJGqtWLGVw1YpOlyJJ0kUZ2oWRiRpb1vUT4XAvSVJ3MrQL9dW9VnW6DEmSLsnQBs5OzzB+4jRDa32eLUnqXoY2cOj4FBcShgbtOS5J6l6GNjA6MQXAlrWGtiSpexnawOjEKcDVvSRJ3c3Qpn6lPdC/jOv7l3e6FEmSLsnQpj5G25nQJEndztCmPhuat8YlSd2u8qE9dW6ad98/w5Cd0CRJXa7yoT1W9Bx3uJckqdsZ2pPFQiFeaUuSulzlQ9slOSVJZWFoT9T4+HUrWLViaadLkSTpsiof2g73kiSVReVDe3SixlZDW5JUApUO7fdOn2eyds4rbUlSKVQ6tMcm7DkuSSqPaod2Mdxrq2O0JUklUOnQHp2oEQGb1vR3uhRJkuZV+dC+cfU1rFzW1+lSJEmaV6VDe8yFQiRJJVLZ0M5MRgxtSVKJNBXaEbE9It6MiIMR8chF3v9qRLxWfL0VEScb3nswIn5YfD3YzuIX43jtHB+cmXa4lySpNOaduzMi+oAngLuBw8DeiNiTmQdm98nMhxv2fwi4rfh5DfAlYBhI4NXi2BNt/SsWYLbn+NA6O6FJksqhmSvt24GDmTmSmeeAZ4B7L7P/A8DTxc+/BLyQmceLoH4B2L6Ygttl5NhsaK/qcCWSJDWnmdBeDxxqeH242PYREbEZGAJebOXYiNgZEfsiYt+xY8eaqXvRxiZr9C0JNgxcc1V+nyRJi9Xujmg7gO9k5kwrB2Xmk5k5nJnDg4ODbS7p4kYnamxa08+yvsr2xZMklUwziTUObGx4vaHYdjE7+Mmt8VaPvapGJ6bYstbn2ZKk8mgmtPcC2yJiKCKWUw/mPXN3ioibgQHgew2bnwfuiYiBiBgA7im2dVRmuiSnJKl05u09npnTEbGLetj2Abszc39EPAbsy8zZAN8BPJOZ2XDs8Yj4E+rBD/BYZh5v75/QuiPvn+X0+RmX5JQklcq8oQ2Qmc8Bz83Z9sU5rx+9xLG7gd0LrO+KGJ1d3cvQliSVSCV7Yc2GtrOhSZLKpJKhPTZZY/nSJdy42uFekqTyqGRojxyrsWVtP0uWRKdLkSSpaZUM7bHJGlvWemtcklQulQvtmQvJ/05O+TxbklQ6lQvtH588zbmZC4a2JKl0KhfaDveSJJVVZUPbiVUkSWVTydC+dnkfg9et6HQpkiS1pHKhPTZZn3M8wuFekqRyqVxoj7pQiCSppCoV2uemL3D4xGmGHKMtSSqhSoX2oRNTzFxIh3tJkkqpUqE95nAvSVKJVSq0He4lSSqzyoX26muWMXDt8k6XIklSyyoV2rPDvSRJKqNKhfbosZq3xiVJpVWZ0D5zfoYfv3fGJTklSaVVmdB+e3IKgKFBQ1uSVE6VCe3RiVMATqwiSSqtCoV2/Up7y7r+DlciSdLCVCi0T7Fu1QquW7ms06VIkrQglQntsYkphrzKliSVWGVCe2Si5pzjkqRSq0Rof3DmPBOnzjqxiiSp1CoR2rPDvZxYRZJUZpUI7RFX95Ik9YBKhPbskpyb1xjakqTyqkRoj07UuHH1Sq5Z3tfpUiRJWrDKhLa3xiVJZVeJ0B6bdLiXJKn8ej60T9TOcXLqvKEtSSq9ng/t0cl6JzRDW5JUdr0f2scc7iVJ6g09H9pjkzWWBGwccN5xSVK59Xxoj07U2Limn+VLe/5PlST1uJ5PstGJGlvWemtcklR+PR3amcmYq3tJknpEU6EdEdsj4s2IOBgRj1xin/sj4kBE7I+IbzVsn4mI14qvPe0qvBmnz8/wma1ruW3T9Vfz10qSdEUsnW+HiOgDngDuBg4DeyNiT2YeaNhnG/CHwB2ZeSIiPt7wEacz89Y2192U/uVLeepzP9OJXy1JUts1c6V9O3AwM0cy8xzwDHDvnH1+C3giM08AZObR9pYpSZKaCe31wKGG14eLbY1uAm6KiH+NiH+PiO0N762MiH3F9vsWWa8kSZU17+3xFj5nG3AXsAF4JSI+lZkngc2ZOR4RW4EXI+L1zPxR48ERsRPYCbBp06Y2lSRJUm9p5kp7HNjY8HpDsa3RYWBPZp7PzFHgLeohTmaOF99HgJeB2+b+gsx8MjOHM3N4cHCw5T9CkqQqaCa09wLbImIoIpYDO4C5vcCfpX6VTUSso367fCQiBiJiRcP2O4ADSJKkls17ezwzpyNiF/A80Afszsz9EfEYsC8z9xTv3RMRB4AZ4A8yczIifh74q4i4QP0/CI839jqXJEnNi8zsdA0fMjw8nPv27et0GZIkXTUR8WpmDs+3X0/PiCZJUi8xtCVJKglDW5KkkjC0JUkqCUNbkqSSMLQlSSqJrhvyFRHHgLfb/LHrgIk2f2aV2Z7tZ5u2l+3ZfrZpe81tz82ZOe+UoF0X2ldCROxrZvybmmN7tp9t2l62Z/vZpu210Pb09rgkSSVhaEuSVBJVCe0nO11Aj7E92882bS/bs/1s0/ZaUHtW4pm2JEm9oCpX2pIklV5Ph3ZEbI+INyPiYEQ80ul6ekFEjEXE6xHxWkS4HNsCRMTuiDgaET9o2LYmIl6IiB8W3wc6WWOZXKI9H42I8eI8fS0ifrmTNZZJRGyMiJci4kBE7I+I3yu2e44u0GXatOXztGdvj0dEH/AWcDdwGNgLPOB63osTEWPAcGY6XnOBIuIXgFPANzPzp4ttfwocz8zHi/9gDmTm5ztZZ1lcoj0fBU5l5p91srYyiohPAp/MzO9HxHXAq8B9wOfwHF2Qy7Tp/bR4nvbylfbtwMHMHMnMc8AzwL0drkkiM18Bjs/ZfC/wjeLnb1D/B60mXKI9tUCZ+U5mfr/4+QPgDWA9nqMLdpk2bVkvh/Z64FDD68MssJH0IQl8NyJejYidnS6mh9yQme8UP78L3NDJYnrEroj47+L2ubdyFyAitgC3Af+B52hbzGlTaPE87eXQ1pVxZ2Z+Gvgs8LvFrUm1UdafWfXmc6ur52vATwG3Au8Af97ZcsonIlYBfwf8fma+3/ie5+jCXKRNWz5Pezm0x4GNDa83FNu0CJk5Xnw/CvwD9ccQWrwjxXOv2edfRztcT6ll5pHMnMnMC8Bf43nakohYRj1c/jYz/77Y7Dm6CBdr04Wcp70c2nuBbRExFBHLgR3Ang7XVGoRcW3RiYKIuBa4B/jB5Y9Sk/YADxY/Pwj8YwdrKb3ZcCn8Op6nTYuIAJ4C3sjMv2h4y3N0gS7Vpgs5T3u29zhA0X3+L4E+YHdmfrnDJZVaRGylfnUNsBT4lm3auoh4GriL+io/R4AvAc8C3wY2UV/l7v7MtHNVEy7RnndRv+WYwBjw2w3PY3UZEXEn8C/A68CFYvMXqD+D9RxdgMu06QO0eJ72dGhLktRLevn2uCRJPcXQliSpJAxtSZJKwtCWJKkkDG1JkkrC0JYkqSQMbUmSSsLQliSpJP4PYG9/Q+kw7loAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.figure(figsize=(8,6))\n",
        "plt.title('Accuracy scores')\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.legend(['acc', 'val_acc'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZCohnN9fI83-"
      },
      "outputs": [],
      "source": [
        "model.load_weights(\"best_model_effB0.hdf5\")\n",
        "preds = model.predict(X_test)\n",
        "labelled_preds = one_hot_encoder.inverse_transform(preds)\n",
        "pred = pd.DataFrame(labelled_preds, columns =[\"class_id\"])\n",
        "df = pd.read_csv('submission3.csv')\n",
        "df ['class_id']= pred\n",
        "df.to_csv(\"final_submission51.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czz_AfPCD_LW"
      },
      "source": [
        "###EfficienNetB1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3k4xGHGhDrxB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47ed3d66-7446-42f1-d947-ba130862ae82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb1_notop.h5\n",
            "27025408/27018416 [==============================] - 0s 0us/step\n",
            "27033600/27018416 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "base_model1 = tf.keras.applications.EfficientNetB1(include_top=False,\n",
        "                                     weights='imagenet',\n",
        "                                     input_shape=(224, 224, 3))\n",
        "x = base_model1.output\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = Dense(512, activation=None, kernel_regularizer = L1L2(l1=1e-5, l2=1e-3))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('swish')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(512, activation=None, kernel_regularizer = L1L2(l1=1e-5, l2=1e-3))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('swish')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "ouput1 = Dense(3, activation= 'softmax')(x)\n",
        "\n",
        "model1 = Model(inputs=base_model1.input, outputs=ouput1)\n",
        "\n",
        "model1.compile(loss='categorical_crossentropy', \n",
        "              optimizer=tf.keras.optimizers.Adam(1e-3, decay = 1e-3 * 0.1), metrics=['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-EoTlwfJErhA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ffae4a4-4f93-47d0-f677-9545d347b0bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "132/132 [==============================] - 66s 409ms/step - loss: 2.1128 - acc: 0.7358 - val_loss: 2.2550 - val_acc: 0.7837 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "132/132 [==============================] - 52s 392ms/step - loss: 1.6266 - acc: 0.8036 - val_loss: 1.4536 - val_acc: 0.7966 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "132/132 [==============================] - 52s 390ms/step - loss: 1.2768 - acc: 0.8124 - val_loss: 1.2425 - val_acc: 0.7752 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "132/132 [==============================] - 52s 393ms/step - loss: 0.9949 - acc: 0.8273 - val_loss: 0.8790 - val_acc: 0.8223 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "132/132 [==============================] - 51s 384ms/step - loss: 0.7947 - acc: 0.8350 - val_loss: 3.7587 - val_acc: 0.5225 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "132/132 [==============================] - 52s 394ms/step - loss: 0.6548 - acc: 0.8447 - val_loss: 0.5964 - val_acc: 0.8137 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "132/132 [==============================] - 51s 385ms/step - loss: 0.5273 - acc: 0.8635 - val_loss: 0.6030 - val_acc: 0.8308 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.4787 - acc: 0.8618\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "132/132 [==============================] - 51s 384ms/step - loss: 0.4787 - acc: 0.8618 - val_loss: 0.6134 - val_acc: 0.8073 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "132/132 [==============================] - 53s 397ms/step - loss: 0.3662 - acc: 0.8996 - val_loss: 0.4513 - val_acc: 0.8373 - lr: 3.0000e-04\n",
            "Epoch 10/50\n",
            "132/132 [==============================] - 51s 386ms/step - loss: 0.2966 - acc: 0.9175 - val_loss: 0.4762 - val_acc: 0.8437 - lr: 3.0000e-04\n",
            "Epoch 11/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.2777 - acc: 0.9234\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "132/132 [==============================] - 51s 385ms/step - loss: 0.2777 - acc: 0.9234 - val_loss: 0.4551 - val_acc: 0.8480 - lr: 3.0000e-04\n",
            "Epoch 12/50\n",
            "132/132 [==============================] - 51s 386ms/step - loss: 0.2108 - acc: 0.9503 - val_loss: 0.4886 - val_acc: 0.8608 - lr: 9.0000e-05\n",
            "Epoch 13/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.1856 - acc: 0.9570\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "132/132 [==============================] - 51s 385ms/step - loss: 0.1856 - acc: 0.9570 - val_loss: 0.5647 - val_acc: 0.8565 - lr: 9.0000e-05\n",
            "Epoch 14/50\n",
            "132/132 [==============================] - 51s 385ms/step - loss: 0.1679 - acc: 0.9627 - val_loss: 0.5205 - val_acc: 0.8587 - lr: 2.7000e-05\n",
            "Epoch 15/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.1573 - acc: 0.9658\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
            "132/132 [==============================] - 51s 384ms/step - loss: 0.1573 - acc: 0.9658 - val_loss: 0.5602 - val_acc: 0.8630 - lr: 2.7000e-05\n",
            "Epoch 16/50\n",
            "132/132 [==============================] - 51s 385ms/step - loss: 0.1586 - acc: 0.9669 - val_loss: 0.5492 - val_acc: 0.8587 - lr: 8.1000e-06\n",
            "Epoch 17/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.1489 - acc: 0.9707\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 2.429999949526973e-06.\n",
            "132/132 [==============================] - 51s 382ms/step - loss: 0.1489 - acc: 0.9707 - val_loss: 0.5450 - val_acc: 0.8672 - lr: 8.1000e-06\n",
            "Epoch 18/50\n",
            "132/132 [==============================] - 51s 384ms/step - loss: 0.1545 - acc: 0.9653 - val_loss: 0.6204 - val_acc: 0.8522 - lr: 2.4300e-06\n",
            "Epoch 19/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.1490 - acc: 0.9693\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 7.289999985005124e-07.\n",
            "132/132 [==============================] - 51s 385ms/step - loss: 0.1490 - acc: 0.9693 - val_loss: 0.5471 - val_acc: 0.8522 - lr: 2.4300e-06\n",
            "Epoch 20/50\n",
            "132/132 [==============================] - 51s 384ms/step - loss: 0.1481 - acc: 0.9688 - val_loss: 0.5849 - val_acc: 0.8651 - lr: 7.2900e-07\n",
            "Epoch 21/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.1484 - acc: 0.9679\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 2.1870000637136398e-07.\n",
            "132/132 [==============================] - 51s 385ms/step - loss: 0.1484 - acc: 0.9679 - val_loss: 0.5941 - val_acc: 0.8608 - lr: 7.2900e-07\n",
            "Epoch 22/50\n",
            "132/132 [==============================] - 52s 388ms/step - loss: 0.1509 - acc: 0.9650 - val_loss: 0.5586 - val_acc: 0.8522 - lr: 2.1870e-07\n"
          ]
        }
      ],
      "source": [
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', patience = 2, verbose=1,factor=0.3, min_lr=0.00000001)\n",
        "chkpt = ModelCheckpoint(filepath='best_model_effB1.hdf5', monitor='val_loss', save_best_only=True, save_weights_only=True)\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(patience=13, monitor='val_loss', restore_best_weights=True)\n",
        "\n",
        "history = model1.fit(train_gen, epochs=50, validation_data=valid_gen, callbacks=[learning_rate_reduction, chkpt, early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HpXxI7QvE35b"
      },
      "outputs": [],
      "source": [
        "model1.load_weights(\"best_model_effB1.hdf5\")\n",
        "preds = model1.predict(X_test)\n",
        "labelled_preds = one_hot_encoder.inverse_transform(preds)\n",
        "pred = pd.DataFrame(labelled_preds, columns =[\"class_id\"])\n",
        "df = pd.read_csv('submission3.csv')\n",
        "df ['class_id']= pred\n",
        "df.to_csv(\"final_submission52.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETDeu8cDNGx-"
      },
      "source": [
        "### EfficienNetB2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pkM8CDwjNJph",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c8a2090-8e25-46b6-a127-827116d48f06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb2_notop.h5\n",
            "31793152/31790344 [==============================] - 0s 0us/step\n",
            "31801344/31790344 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "base_model2 = tf.keras.applications.EfficientNetB2(include_top=False,\n",
        "                                     weights='imagenet',\n",
        "                                     input_shape=(224, 224, 3))\n",
        "x = base_model2.output\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = Dense(512, activation=None, kernel_regularizer = L1L2(l1=1e-5, l2=1e-3))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('swish')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(512, activation=None, kernel_regularizer = L1L2(l1=1e-5, l2=1e-3))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('swish')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "ouput1 = Dense(3, activation= 'softmax')(x)\n",
        "\n",
        "model2 = Model(inputs=base_model2.input, outputs=ouput1)\n",
        "\n",
        "model2.compile(loss='categorical_crossentropy', \n",
        "              optimizer=tf.keras.optimizers.Adam(1e-3, decay = 1e-3 * 0.1), metrics=['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liKrCAVONWHW",
        "outputId": "516084a4-546e-4960-e1f4-a987d5534943"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "132/132 [==============================] - 67s 416ms/step - loss: 2.1077 - acc: 0.7317 - val_loss: 1.8626 - val_acc: 0.7645 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "132/132 [==============================] - 53s 396ms/step - loss: 1.6126 - acc: 0.7979 - val_loss: 1.7177 - val_acc: 0.7859 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "132/132 [==============================] - 52s 389ms/step - loss: 1.2582 - acc: 0.8052 - val_loss: 2.4651 - val_acc: 0.7473 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "132/132 [==============================] - 52s 395ms/step - loss: 0.9797 - acc: 0.8157 - val_loss: 1.0910 - val_acc: 0.6467 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "132/132 [==============================] - 53s 397ms/step - loss: 1.0581 - acc: 0.7434 - val_loss: 0.9519 - val_acc: 0.7195 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "132/132 [==============================] - 53s 397ms/step - loss: 0.8164 - acc: 0.7857 - val_loss: 0.9020 - val_acc: 0.7730 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "132/132 [==============================] - 53s 397ms/step - loss: 0.7053 - acc: 0.7929 - val_loss: 0.8893 - val_acc: 0.6788 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "132/132 [==============================] - 53s 398ms/step - loss: 0.6600 - acc: 0.7995 - val_loss: 0.6657 - val_acc: 0.7580 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "132/132 [==============================] - 53s 398ms/step - loss: 0.5477 - acc: 0.8174 - val_loss: 0.6153 - val_acc: 0.8158 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "132/132 [==============================] - 52s 395ms/step - loss: 0.5368 - acc: 0.8188 - val_loss: 0.6930 - val_acc: 0.7452 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "132/132 [==============================] - 53s 400ms/step - loss: 0.5250 - acc: 0.8228 - val_loss: 0.5989 - val_acc: 0.7709 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "132/132 [==============================] - 53s 399ms/step - loss: 0.4909 - acc: 0.8228 - val_loss: 0.5904 - val_acc: 0.7752 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "132/132 [==============================] - 52s 391ms/step - loss: 0.5345 - acc: 0.8171 - val_loss: 0.7307 - val_acc: 0.7645 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "132/132 [==============================] - 53s 397ms/step - loss: 0.4762 - acc: 0.8392 - val_loss: 0.5025 - val_acc: 0.8351 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "132/132 [==============================] - 52s 389ms/step - loss: 0.4627 - acc: 0.8369 - val_loss: 0.5149 - val_acc: 0.8073 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.4523 - acc: 0.8430\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "132/132 [==============================] - 52s 388ms/step - loss: 0.4523 - acc: 0.8430 - val_loss: 1.3685 - val_acc: 0.7859 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "132/132 [==============================] - 53s 399ms/step - loss: 0.4344 - acc: 0.8471 - val_loss: 0.4466 - val_acc: 0.8415 - lr: 3.0000e-04\n",
            "Epoch 18/50\n",
            "132/132 [==============================] - 52s 388ms/step - loss: 0.3775 - acc: 0.8642 - val_loss: 0.4974 - val_acc: 0.8201 - lr: 3.0000e-04\n",
            "Epoch 19/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.3949 - acc: 0.8597\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "132/132 [==============================] - 52s 388ms/step - loss: 0.3949 - acc: 0.8597 - val_loss: 0.4971 - val_acc: 0.8223 - lr: 3.0000e-04\n",
            "Epoch 20/50\n",
            "132/132 [==============================] - 53s 400ms/step - loss: 0.3483 - acc: 0.8735 - val_loss: 0.4200 - val_acc: 0.8394 - lr: 9.0000e-05\n",
            "Epoch 21/50\n",
            "132/132 [==============================] - 52s 388ms/step - loss: 0.3279 - acc: 0.8832 - val_loss: 0.4249 - val_acc: 0.8480 - lr: 9.0000e-05\n",
            "Epoch 22/50\n",
            "132/132 [==============================] - 53s 398ms/step - loss: 0.3202 - acc: 0.8861 - val_loss: 0.4115 - val_acc: 0.8351 - lr: 9.0000e-05\n",
            "Epoch 23/50\n",
            "132/132 [==============================] - 52s 392ms/step - loss: 0.3069 - acc: 0.8904 - val_loss: 0.4420 - val_acc: 0.8415 - lr: 9.0000e-05\n",
            "Epoch 24/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.3049 - acc: 0.8882\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "132/132 [==============================] - 52s 391ms/step - loss: 0.3049 - acc: 0.8882 - val_loss: 0.4335 - val_acc: 0.8394 - lr: 9.0000e-05\n",
            "Epoch 25/50\n",
            "132/132 [==============================] - 52s 389ms/step - loss: 0.2938 - acc: 0.8966 - val_loss: 0.4460 - val_acc: 0.8244 - lr: 2.7000e-05\n",
            "Epoch 26/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.2753 - acc: 0.9077\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
            "132/132 [==============================] - 52s 391ms/step - loss: 0.2753 - acc: 0.9077 - val_loss: 0.4710 - val_acc: 0.8287 - lr: 2.7000e-05\n",
            "Epoch 27/50\n",
            "132/132 [==============================] - 52s 395ms/step - loss: 0.2815 - acc: 0.9006 - val_loss: 0.4567 - val_acc: 0.8180 - lr: 8.1000e-06\n",
            "Epoch 28/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.2773 - acc: 0.9025\n",
            "Epoch 28: ReduceLROnPlateau reducing learning rate to 2.429999949526973e-06.\n",
            "132/132 [==============================] - 51s 387ms/step - loss: 0.2773 - acc: 0.9025 - val_loss: 0.4533 - val_acc: 0.8287 - lr: 8.1000e-06\n",
            "Epoch 29/50\n",
            "132/132 [==============================] - 51s 386ms/step - loss: 0.2766 - acc: 0.9039 - val_loss: 0.4470 - val_acc: 0.8308 - lr: 2.4300e-06\n",
            "Epoch 30/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.2787 - acc: 0.9025\n",
            "Epoch 30: ReduceLROnPlateau reducing learning rate to 7.289999985005124e-07.\n",
            "132/132 [==============================] - 52s 389ms/step - loss: 0.2787 - acc: 0.9025 - val_loss: 0.4401 - val_acc: 0.8330 - lr: 2.4300e-06\n",
            "Epoch 31/50\n",
            "132/132 [==============================] - 52s 389ms/step - loss: 0.2645 - acc: 0.9099 - val_loss: 0.4545 - val_acc: 0.8223 - lr: 7.2900e-07\n",
            "Epoch 32/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.2708 - acc: 0.9008\n",
            "Epoch 32: ReduceLROnPlateau reducing learning rate to 2.1870000637136398e-07.\n",
            "132/132 [==============================] - 51s 386ms/step - loss: 0.2708 - acc: 0.9008 - val_loss: 0.4655 - val_acc: 0.8201 - lr: 7.2900e-07\n",
            "Epoch 33/50\n",
            "132/132 [==============================] - 52s 388ms/step - loss: 0.2722 - acc: 0.9049 - val_loss: 0.4686 - val_acc: 0.8244 - lr: 2.1870e-07\n",
            "Epoch 34/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.2683 - acc: 0.9006\n",
            "Epoch 34: ReduceLROnPlateau reducing learning rate to 6.561000276406048e-08.\n",
            "132/132 [==============================] - 51s 388ms/step - loss: 0.2683 - acc: 0.9006 - val_loss: 0.4448 - val_acc: 0.8373 - lr: 2.1870e-07\n",
            "Epoch 35/50\n",
            "132/132 [==============================] - 52s 388ms/step - loss: 0.2775 - acc: 0.9025 - val_loss: 0.4614 - val_acc: 0.8266 - lr: 6.5610e-08\n"
          ]
        }
      ],
      "source": [
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', patience = 2, verbose=1,factor=0.3, min_lr=0.00000001)\n",
        "chkpt = ModelCheckpoint(filepath='best_model_effB2.hdf5', monitor='val_loss', save_best_only=True, save_weights_only=True)\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(patience=13, monitor='val_loss', restore_best_weights=True)\n",
        "\n",
        "history2 = model2.fit(train_gen, epochs=50, validation_data=valid_gen, callbacks=[learning_rate_reduction, chkpt, early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZCH0uWBLNa7t"
      },
      "outputs": [],
      "source": [
        "model2.load_weights(\"best_model_effB2.hdf5\")\n",
        "preds = model2.predict(X_test)\n",
        "labelled_preds = one_hot_encoder.inverse_transform(preds)\n",
        "pred = pd.DataFrame(labelled_preds, columns =[\"class_id\"])\n",
        "df = pd.read_csv('submission3.csv')\n",
        "df ['class_id']= pred\n",
        "df.to_csv(\"final_submission53.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_kxDqMvkbR1"
      },
      "source": [
        "###EfficientNetB3 -> B3_2 & B3_6 Removed on Final Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e867793-ba3a-4fa0-b3a4-91f82a84be46",
        "id": "qCeVn_bJkbR9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb3_notop.h5\n",
            "43941888/43941136 [==============================] - 0s 0us/step\n",
            "43950080/43941136 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "base_model3 = tf.keras.applications.EfficientNetB3(include_top=False,\n",
        "                                     weights='imagenet',\n",
        "                                     input_shape=(224, 224, 3))\n",
        "x = base_model3.output\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = Dense(512, activation=None, kernel_regularizer = L1L2(l1=1e-5, l2=1e-3))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('swish')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(512, activation=None, kernel_regularizer = L1L2(l1=1e-5, l2=1e-3))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('swish')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "ouput1 = Dense(3, activation= 'softmax')(x)\n",
        "\n",
        "model3 = Model(inputs=base_model3.input, outputs=ouput1)\n",
        "\n",
        "model3.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', metrics=['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10eda9b9-4367-49f8-8b9e-645643390ec7",
        "id": "0kPa11QwkbR9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "132/132 [==============================] - 92s 514ms/step - loss: 1.6898 - acc: 0.7453 - val_loss: 1.4207 - val_acc: 0.7173 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "132/132 [==============================] - 61s 460ms/step - loss: 0.9286 - acc: 0.8048 - val_loss: 0.6943 - val_acc: 0.7859 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "132/132 [==============================] - 61s 464ms/step - loss: 0.5483 - acc: 0.8166 - val_loss: 0.5136 - val_acc: 0.8158 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "132/132 [==============================] - 61s 461ms/step - loss: 0.3795 - acc: 0.8333 - val_loss: 0.4615 - val_acc: 0.7088 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "132/132 [==============================] - 61s 462ms/step - loss: 0.3179 - acc: 0.8426 - val_loss: 0.3392 - val_acc: 0.8137 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "132/132 [==============================] - 60s 452ms/step - loss: 0.2858 - acc: 0.8499 - val_loss: 0.5332 - val_acc: 0.6852 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.2773 - acc: 0.8597\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "132/132 [==============================] - 59s 448ms/step - loss: 0.2773 - acc: 0.8597 - val_loss: 0.4920 - val_acc: 0.7709 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "132/132 [==============================] - 61s 460ms/step - loss: 0.2074 - acc: 0.9049 - val_loss: 0.2943 - val_acc: 0.8223 - lr: 3.0000e-04\n",
            "Epoch 9/50\n",
            "132/132 [==============================] - 60s 449ms/step - loss: 0.1632 - acc: 0.9225 - val_loss: 0.3189 - val_acc: 0.8073 - lr: 3.0000e-04\n",
            "Epoch 10/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.1433 - acc: 0.9303\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "132/132 [==============================] - 60s 450ms/step - loss: 0.1433 - acc: 0.9303 - val_loss: 0.3043 - val_acc: 0.8308 - lr: 3.0000e-04\n",
            "Epoch 11/50\n",
            "132/132 [==============================] - 60s 449ms/step - loss: 0.1099 - acc: 0.9486 - val_loss: 0.3006 - val_acc: 0.8351 - lr: 9.0000e-05\n",
            "Epoch 12/50\n",
            "132/132 [==============================] - 61s 461ms/step - loss: 0.0808 - acc: 0.9681 - val_loss: 0.2862 - val_acc: 0.8437 - lr: 9.0000e-05\n",
            "Epoch 13/50\n",
            "132/132 [==============================] - 60s 449ms/step - loss: 0.0727 - acc: 0.9691 - val_loss: 0.3024 - val_acc: 0.8522 - lr: 9.0000e-05\n",
            "Epoch 14/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0668 - acc: 0.9715\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "132/132 [==============================] - 60s 450ms/step - loss: 0.0668 - acc: 0.9715 - val_loss: 0.3789 - val_acc: 0.8415 - lr: 9.0000e-05\n",
            "Epoch 15/50\n",
            "132/132 [==============================] - 60s 449ms/step - loss: 0.0568 - acc: 0.9786 - val_loss: 0.3823 - val_acc: 0.8330 - lr: 2.7000e-05\n",
            "Epoch 16/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0563 - acc: 0.9774\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
            "132/132 [==============================] - 60s 450ms/step - loss: 0.0563 - acc: 0.9774 - val_loss: 0.3852 - val_acc: 0.8394 - lr: 2.7000e-05\n",
            "Epoch 17/50\n",
            "132/132 [==============================] - 60s 450ms/step - loss: 0.0506 - acc: 0.9776 - val_loss: 0.3684 - val_acc: 0.8415 - lr: 8.1000e-06\n",
            "Epoch 18/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0474 - acc: 0.9831\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 2.429999949526973e-06.\n",
            "132/132 [==============================] - 60s 449ms/step - loss: 0.0474 - acc: 0.9831 - val_loss: 0.3965 - val_acc: 0.8394 - lr: 8.1000e-06\n",
            "Epoch 19/50\n",
            "132/132 [==============================] - 60s 449ms/step - loss: 0.0440 - acc: 0.9834 - val_loss: 0.3899 - val_acc: 0.8480 - lr: 2.4300e-06\n",
            "Epoch 20/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0458 - acc: 0.9812\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 7.289999985005124e-07.\n",
            "132/132 [==============================] - 60s 449ms/step - loss: 0.0458 - acc: 0.9812 - val_loss: 0.4008 - val_acc: 0.8330 - lr: 2.4300e-06\n",
            "Epoch 21/50\n",
            "132/132 [==============================] - 60s 450ms/step - loss: 0.0419 - acc: 0.9855 - val_loss: 0.4032 - val_acc: 0.8458 - lr: 7.2900e-07\n",
            "Epoch 22/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0471 - acc: 0.9798\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 2.1870000637136398e-07.\n",
            "132/132 [==============================] - 59s 446ms/step - loss: 0.0471 - acc: 0.9798 - val_loss: 0.4217 - val_acc: 0.8308 - lr: 7.2900e-07\n",
            "Epoch 23/50\n",
            "132/132 [==============================] - 60s 451ms/step - loss: 0.0454 - acc: 0.9817 - val_loss: 0.4031 - val_acc: 0.8373 - lr: 2.1870e-07\n",
            "Epoch 24/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0437 - acc: 0.9834\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 6.561000276406048e-08.\n",
            "132/132 [==============================] - 60s 450ms/step - loss: 0.0437 - acc: 0.9834 - val_loss: 0.3589 - val_acc: 0.8522 - lr: 2.1870e-07\n",
            "Epoch 25/50\n",
            "132/132 [==============================] - 60s 451ms/step - loss: 0.0403 - acc: 0.9848 - val_loss: 0.4114 - val_acc: 0.8158 - lr: 6.5610e-08\n"
          ]
        }
      ],
      "source": [
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', patience = 2, verbose=1,factor=0.3, min_lr=0.00000001)\n",
        "chkpt = ModelCheckpoint(filepath='best_model_effB3.hdf5', monitor='val_loss', save_best_only=True, save_weights_only=True)\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(patience=13, monitor='val_loss', restore_best_weights=True)\n",
        "\n",
        "history3 = model3.fit(train_gen, epochs=50, validation_data=valid_gen, callbacks=[learning_rate_reduction, chkpt, early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0gGpuw0kbR9"
      },
      "outputs": [],
      "source": [
        "model3.load_weights(\"best_model_effB3.hdf5\")\n",
        "preds = model3.predict(X_test)\n",
        "labelled_preds = one_hot_encoder.inverse_transform(preds)\n",
        "pred = pd.DataFrame(labelled_preds, columns =[\"class_id\"])\n",
        "df = pd.read_csv('submission3.csv')\n",
        "df ['class_id']= pred\n",
        "df.to_csv(\"final_submission54.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8uxmuG1V31c",
        "outputId": "e3ce9df0-8fd2-4553-bd2b-b031ee20578b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "132/132 [==============================] - 82s 498ms/step - loss: 1.6582 - acc: 0.7527 - val_loss: 1.4054 - val_acc: 0.6831 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "132/132 [==============================] - 60s 451ms/step - loss: 0.9021 - acc: 0.8012 - val_loss: 1.3075 - val_acc: 0.6681 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "132/132 [==============================] - 61s 457ms/step - loss: 0.5361 - acc: 0.8112 - val_loss: 0.4975 - val_acc: 0.7966 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "132/132 [==============================] - 59s 447ms/step - loss: 0.3923 - acc: 0.8226 - val_loss: 0.3967 - val_acc: 0.7687 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.3402 - acc: 0.8333\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "132/132 [==============================] - 59s 446ms/step - loss: 0.3402 - acc: 0.8333 - val_loss: 0.5264 - val_acc: 0.6895 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "132/132 [==============================] - 60s 449ms/step - loss: 0.2769 - acc: 0.8595 - val_loss: 0.3411 - val_acc: 0.7944 - lr: 3.0000e-04\n",
            "Epoch 7/50\n",
            "132/132 [==============================] - 61s 459ms/step - loss: 0.2321 - acc: 0.8837 - val_loss: 0.3040 - val_acc: 0.8180 - lr: 3.0000e-04\n",
            "Epoch 8/50\n",
            "132/132 [==============================] - 60s 449ms/step - loss: 0.2009 - acc: 0.9037 - val_loss: 0.3216 - val_acc: 0.7966 - lr: 3.0000e-04\n",
            "Epoch 9/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.1743 - acc: 0.9180\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "132/132 [==============================] - 59s 446ms/step - loss: 0.1743 - acc: 0.9180 - val_loss: 0.3451 - val_acc: 0.8137 - lr: 3.0000e-04\n",
            "Epoch 10/50\n",
            "132/132 [==============================] - 61s 459ms/step - loss: 0.1357 - acc: 0.9346 - val_loss: 0.3140 - val_acc: 0.8330 - lr: 9.0000e-05\n",
            "Epoch 11/50\n",
            "132/132 [==============================] - 59s 448ms/step - loss: 0.1171 - acc: 0.9463 - val_loss: 0.3031 - val_acc: 0.8266 - lr: 9.0000e-05\n",
            "Epoch 12/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.1042 - acc: 0.9555\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "132/132 [==============================] - 59s 446ms/step - loss: 0.1042 - acc: 0.9555 - val_loss: 0.3458 - val_acc: 0.8201 - lr: 9.0000e-05\n",
            "Epoch 13/50\n",
            "132/132 [==============================] - 61s 458ms/step - loss: 0.0747 - acc: 0.9696 - val_loss: 0.3409 - val_acc: 0.8373 - lr: 2.7000e-05\n",
            "Epoch 14/50\n",
            "132/132 [==============================] - 60s 450ms/step - loss: 0.0784 - acc: 0.9679 - val_loss: 0.3711 - val_acc: 0.8266 - lr: 2.7000e-05\n",
            "Epoch 15/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0738 - acc: 0.9707\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
            "132/132 [==============================] - 59s 447ms/step - loss: 0.0738 - acc: 0.9707 - val_loss: 0.3762 - val_acc: 0.8330 - lr: 2.7000e-05\n",
            "Epoch 16/50\n",
            "132/132 [==============================] - 59s 445ms/step - loss: 0.0622 - acc: 0.9750 - val_loss: 0.3541 - val_acc: 0.8287 - lr: 8.1000e-06\n",
            "Epoch 17/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0639 - acc: 0.9755\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 2.429999949526973e-06.\n",
            "132/132 [==============================] - 59s 446ms/step - loss: 0.0639 - acc: 0.9755 - val_loss: 0.3832 - val_acc: 0.8330 - lr: 8.1000e-06\n",
            "Epoch 18/50\n",
            "132/132 [==============================] - 59s 446ms/step - loss: 0.0654 - acc: 0.9724 - val_loss: 0.3922 - val_acc: 0.8308 - lr: 2.4300e-06\n",
            "Epoch 19/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0625 - acc: 0.9736\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 7.289999985005124e-07.\n",
            "132/132 [==============================] - 59s 446ms/step - loss: 0.0625 - acc: 0.9736 - val_loss: 0.3896 - val_acc: 0.8330 - lr: 2.4300e-06\n",
            "Epoch 20/50\n",
            "132/132 [==============================] - 59s 448ms/step - loss: 0.0584 - acc: 0.9767 - val_loss: 0.3857 - val_acc: 0.8373 - lr: 7.2900e-07\n",
            "Epoch 21/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0643 - acc: 0.9746\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 2.1870000637136398e-07.\n",
            "132/132 [==============================] - 59s 446ms/step - loss: 0.0643 - acc: 0.9746 - val_loss: 0.3969 - val_acc: 0.8201 - lr: 7.2900e-07\n",
            "Epoch 22/50\n",
            "132/132 [==============================] - 59s 448ms/step - loss: 0.0646 - acc: 0.9734 - val_loss: 0.4260 - val_acc: 0.8244 - lr: 2.1870e-07\n",
            "Epoch 23/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0625 - acc: 0.9757\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 6.561000276406048e-08.\n",
            "132/132 [==============================] - 59s 448ms/step - loss: 0.0625 - acc: 0.9757 - val_loss: 0.4012 - val_acc: 0.8373 - lr: 2.1870e-07\n",
            "Epoch 24/50\n",
            "132/132 [==============================] - 60s 449ms/step - loss: 0.0614 - acc: 0.9760 - val_loss: 0.3803 - val_acc: 0.8308 - lr: 6.5610e-08\n",
            "Epoch 25/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0556 - acc: 0.9815\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 1.9683000829218145e-08.\n",
            "132/132 [==============================] - 59s 445ms/step - loss: 0.0556 - acc: 0.9815 - val_loss: 0.4240 - val_acc: 0.8244 - lr: 6.5610e-08\n",
            "Epoch 26/50\n",
            "132/132 [==============================] - 59s 447ms/step - loss: 0.0658 - acc: 0.9722 - val_loss: 0.3872 - val_acc: 0.8266 - lr: 1.9683e-08\n"
          ]
        }
      ],
      "source": [
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience = 2, verbose=1,factor=0.3, min_lr=0.00000001)\n",
        "chkpt = ModelCheckpoint(filepath='best_model_effB3_vol2.hdf5', monitor='val_acc', save_best_only=True, save_weights_only=True)\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(patience=13, monitor='val_acc', restore_best_weights=True)\n",
        "\n",
        "history3 = model3.fit(train_gen, epochs=50, validation_data=valid_gen, callbacks=[learning_rate_reduction, chkpt, early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bcUjyVDBV35H"
      },
      "outputs": [],
      "source": [
        "model3.load_weights(\"best_model_effB3_vol2.hdf5\")\n",
        "preds = model3.predict(X_test)\n",
        "labelled_preds = one_hot_encoder.inverse_transform(preds)\n",
        "pred = pd.DataFrame(labelled_preds, columns =[\"class_id\"])\n",
        "df = pd.read_csv('submission3.csv')\n",
        "df ['class_id']= pred\n",
        "df.to_csv(\"final_submission54_vol2.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRZVrDxGeoX0"
      },
      "source": [
        "31) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wL5VLQBg2zHi"
      },
      "outputs": [],
      "source": [
        "base_model31 = tf.keras.applications.EfficientNetB3(include_top=False,\n",
        "                                     weights='imagenet',\n",
        "                                     input_shape=(224, 224, 3))\n",
        "x = base_model31.output\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = Dense(512, activation=None, kernel_regularizer = L1L2(l1=1e-6, l2=1e-4))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('swish')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "x = Dense(512, activation=None, kernel_regularizer = L1L2(l1=1e-6, l2=1e-4))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('swish')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "ouput1 = Dense(3, activation= 'softmax')(x)\n",
        "\n",
        "model31 = Model(inputs=base_model31.input, outputs=ouput1)\n",
        "\n",
        "model31.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', metrics=['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmL5RTX-22-7",
        "outputId": "38ee1d97-490b-4db4-8164-128d4783d037"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "132/132 [==============================] - 77s 478ms/step - loss: 0.5388 - acc: 0.7565 - val_loss: 0.6924 - val_acc: 0.7645 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "132/132 [==============================] - 61s 456ms/step - loss: 0.4446 - acc: 0.8064 - val_loss: 0.4197 - val_acc: 0.8094 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "132/132 [==============================] - 59s 448ms/step - loss: 0.3956 - acc: 0.8195 - val_loss: 0.4476 - val_acc: 0.8030 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.3620 - acc: 0.8266\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "132/132 [==============================] - 60s 449ms/step - loss: 0.3620 - acc: 0.8266 - val_loss: 0.7402 - val_acc: 0.4882 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "132/132 [==============================] - 61s 457ms/step - loss: 0.2947 - acc: 0.8735 - val_loss: 0.3524 - val_acc: 0.8244 - lr: 3.0000e-04\n",
            "Epoch 6/50\n",
            "132/132 [==============================] - 60s 449ms/step - loss: 0.2581 - acc: 0.8908 - val_loss: 0.3558 - val_acc: 0.8266 - lr: 3.0000e-04\n",
            "Epoch 7/50\n",
            "132/132 [==============================] - 61s 461ms/step - loss: 0.2372 - acc: 0.9027 - val_loss: 0.3377 - val_acc: 0.8201 - lr: 3.0000e-04\n",
            "Epoch 8/50\n",
            "132/132 [==============================] - 59s 448ms/step - loss: 0.2136 - acc: 0.9120 - val_loss: 0.3467 - val_acc: 0.8073 - lr: 3.0000e-04\n",
            "Epoch 9/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.1876 - acc: 0.9279\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "132/132 [==============================] - 59s 447ms/step - loss: 0.1876 - acc: 0.9279 - val_loss: 0.3813 - val_acc: 0.8266 - lr: 3.0000e-04\n",
            "Epoch 10/50\n",
            "132/132 [==============================] - 59s 447ms/step - loss: 0.1535 - acc: 0.9463 - val_loss: 0.3535 - val_acc: 0.8373 - lr: 9.0000e-05\n",
            "Epoch 11/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.1204 - acc: 0.9658\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "132/132 [==============================] - 59s 448ms/step - loss: 0.1204 - acc: 0.9658 - val_loss: 0.3800 - val_acc: 0.8394 - lr: 9.0000e-05\n",
            "Epoch 12/50\n",
            "132/132 [==============================] - 60s 450ms/step - loss: 0.1118 - acc: 0.9693 - val_loss: 0.4053 - val_acc: 0.8266 - lr: 2.7000e-05\n",
            "Epoch 13/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.1069 - acc: 0.9741\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
            "132/132 [==============================] - 59s 448ms/step - loss: 0.1069 - acc: 0.9741 - val_loss: 0.3949 - val_acc: 0.8330 - lr: 2.7000e-05\n",
            "Epoch 14/50\n",
            "132/132 [==============================] - 60s 452ms/step - loss: 0.1018 - acc: 0.9746 - val_loss: 0.4221 - val_acc: 0.8330 - lr: 8.1000e-06\n",
            "Epoch 15/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0960 - acc: 0.9795\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 2.429999949526973e-06.\n",
            "132/132 [==============================] - 59s 448ms/step - loss: 0.0960 - acc: 0.9795 - val_loss: 0.3943 - val_acc: 0.8394 - lr: 8.1000e-06\n",
            "Epoch 16/50\n",
            "132/132 [==============================] - 59s 447ms/step - loss: 0.0939 - acc: 0.9815 - val_loss: 0.4059 - val_acc: 0.8308 - lr: 2.4300e-06\n",
            "Epoch 17/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0953 - acc: 0.9791\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 7.289999985005124e-07.\n",
            "132/132 [==============================] - 60s 449ms/step - loss: 0.0953 - acc: 0.9791 - val_loss: 0.3857 - val_acc: 0.8544 - lr: 2.4300e-06\n",
            "Epoch 18/50\n",
            "132/132 [==============================] - 60s 450ms/step - loss: 0.1026 - acc: 0.9748 - val_loss: 0.4342 - val_acc: 0.8137 - lr: 7.2900e-07\n",
            "Epoch 19/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0953 - acc: 0.9793\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 2.1870000637136398e-07.\n",
            "132/132 [==============================] - 60s 449ms/step - loss: 0.0953 - acc: 0.9793 - val_loss: 0.4385 - val_acc: 0.8223 - lr: 7.2900e-07\n",
            "Epoch 20/50\n",
            "132/132 [==============================] - 60s 451ms/step - loss: 0.0984 - acc: 0.9776 - val_loss: 0.4174 - val_acc: 0.8266 - lr: 2.1870e-07\n"
          ]
        }
      ],
      "source": [
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', patience = 2, verbose=1,factor=0.3, min_lr=0.00000001)\n",
        "chkpt = ModelCheckpoint(filepath='best_model_effB3_1.hdf5', monitor='val_loss', save_best_only=True, save_weights_only=True)\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(patience=13, monitor='val_loss', restore_best_weights=True)\n",
        "\n",
        "history31 = model31.fit(train_gen, epochs=50, validation_data=valid_gen, callbacks=[learning_rate_reduction, chkpt, early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0xKjRN03KXG"
      },
      "outputs": [],
      "source": [
        "model31.load_weights(\"best_model_effB3_1.hdf5\")\n",
        "preds = model31.predict(X_test)\n",
        "labelled_preds = one_hot_encoder.inverse_transform(preds)\n",
        "pred = pd.DataFrame(labelled_preds, columns =[\"class_id\"])\n",
        "df = pd.read_csv('submission3.csv')\n",
        "df ['class_id']= pred\n",
        "df.to_csv(\"final_submission65.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrrHuYvcdaXy",
        "outputId": "094ff355-91d0-49b9-933c-2d6f4bbf17d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "132/132 [==============================] - 82s 492ms/step - loss: 0.5457 - acc: 0.7467 - val_loss: 0.4880 - val_acc: 0.7944 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "132/132 [==============================] - 68s 517ms/step - loss: 0.4474 - acc: 0.8105 - val_loss: 0.4456 - val_acc: 0.7880 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "132/132 [==============================] - 61s 460ms/step - loss: 0.4079 - acc: 0.8202 - val_loss: 0.4241 - val_acc: 0.8180 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "132/132 [==============================] - 60s 453ms/step - loss: 0.3719 - acc: 0.8378 - val_loss: 0.3940 - val_acc: 0.8051 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.3366 - acc: 0.8428\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "132/132 [==============================] - 60s 452ms/step - loss: 0.3366 - acc: 0.8428 - val_loss: 0.5471 - val_acc: 0.6660 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "132/132 [==============================] - 61s 460ms/step - loss: 0.2642 - acc: 0.8894 - val_loss: 0.3291 - val_acc: 0.8308 - lr: 3.0000e-04\n",
            "Epoch 7/50\n",
            "132/132 [==============================] - 61s 460ms/step - loss: 0.2371 - acc: 0.9027 - val_loss: 0.3436 - val_acc: 0.8373 - lr: 3.0000e-04\n",
            "Epoch 8/50\n",
            "132/132 [==============================] - 60s 449ms/step - loss: 0.2162 - acc: 0.9120 - val_loss: 0.3513 - val_acc: 0.8266 - lr: 3.0000e-04\n",
            "Epoch 9/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.1862 - acc: 0.9263\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "132/132 [==============================] - 60s 449ms/step - loss: 0.1862 - acc: 0.9263 - val_loss: 0.3615 - val_acc: 0.8223 - lr: 3.0000e-04\n",
            "Epoch 10/50\n",
            "132/132 [==============================] - 60s 449ms/step - loss: 0.1457 - acc: 0.9484 - val_loss: 0.3659 - val_acc: 0.8223 - lr: 9.0000e-05\n",
            "Epoch 11/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.1256 - acc: 0.9615\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "132/132 [==============================] - 59s 447ms/step - loss: 0.1256 - acc: 0.9615 - val_loss: 0.3832 - val_acc: 0.8266 - lr: 9.0000e-05\n",
            "Epoch 12/50\n",
            "132/132 [==============================] - 59s 448ms/step - loss: 0.1173 - acc: 0.9646 - val_loss: 0.3983 - val_acc: 0.8330 - lr: 2.7000e-05\n",
            "Epoch 13/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.1080 - acc: 0.9722\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
            "132/132 [==============================] - 60s 449ms/step - loss: 0.1080 - acc: 0.9722 - val_loss: 0.3777 - val_acc: 0.8351 - lr: 2.7000e-05\n",
            "Epoch 14/50\n",
            "132/132 [==============================] - 60s 450ms/step - loss: 0.1020 - acc: 0.9755 - val_loss: 0.4107 - val_acc: 0.8351 - lr: 8.1000e-06\n",
            "Epoch 15/50\n",
            "132/132 [==============================] - 61s 461ms/step - loss: 0.1088 - acc: 0.9727 - val_loss: 0.3870 - val_acc: 0.8501 - lr: 8.1000e-06\n",
            "Epoch 16/50\n",
            "132/132 [==============================] - 60s 449ms/step - loss: 0.1026 - acc: 0.9746 - val_loss: 0.4042 - val_acc: 0.8480 - lr: 8.1000e-06\n",
            "Epoch 17/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.1040 - acc: 0.9760\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 2.429999949526973e-06.\n",
            "132/132 [==============================] - 60s 450ms/step - loss: 0.1040 - acc: 0.9760 - val_loss: 0.3994 - val_acc: 0.8458 - lr: 8.1000e-06\n",
            "Epoch 18/50\n",
            "132/132 [==============================] - 61s 460ms/step - loss: 0.1036 - acc: 0.9743 - val_loss: 0.3915 - val_acc: 0.8522 - lr: 2.4300e-06\n",
            "Epoch 19/50\n",
            "132/132 [==============================] - 60s 449ms/step - loss: 0.1008 - acc: 0.9748 - val_loss: 0.3921 - val_acc: 0.8501 - lr: 2.4300e-06\n",
            "Epoch 20/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0965 - acc: 0.9769\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 7.289999985005124e-07.\n",
            "132/132 [==============================] - 60s 449ms/step - loss: 0.0965 - acc: 0.9769 - val_loss: 0.4018 - val_acc: 0.8501 - lr: 2.4300e-06\n",
            "Epoch 21/50\n",
            "132/132 [==============================] - 59s 448ms/step - loss: 0.1001 - acc: 0.9762 - val_loss: 0.4236 - val_acc: 0.8373 - lr: 7.2900e-07\n",
            "Epoch 22/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0946 - acc: 0.9795\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 2.1870000637136398e-07.\n",
            "132/132 [==============================] - 60s 450ms/step - loss: 0.0946 - acc: 0.9795 - val_loss: 0.4054 - val_acc: 0.8330 - lr: 7.2900e-07\n",
            "Epoch 23/50\n",
            "132/132 [==============================] - 61s 457ms/step - loss: 0.0913 - acc: 0.9798 - val_loss: 0.3944 - val_acc: 0.8544 - lr: 2.1870e-07\n",
            "Epoch 24/50\n",
            "132/132 [==============================] - 59s 448ms/step - loss: 0.0952 - acc: 0.9795 - val_loss: 0.4249 - val_acc: 0.8458 - lr: 2.1870e-07\n",
            "Epoch 25/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0913 - acc: 0.9807\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 6.561000276406048e-08.\n",
            "132/132 [==============================] - 60s 450ms/step - loss: 0.0913 - acc: 0.9807 - val_loss: 0.4196 - val_acc: 0.8480 - lr: 2.1870e-07\n",
            "Epoch 26/50\n",
            "132/132 [==============================] - 60s 450ms/step - loss: 0.1002 - acc: 0.9772 - val_loss: 0.3974 - val_acc: 0.8394 - lr: 6.5610e-08\n",
            "Epoch 27/50\n",
            "132/132 [==============================] - 61s 462ms/step - loss: 0.0915 - acc: 0.9805 - val_loss: 0.3793 - val_acc: 0.8565 - lr: 6.5610e-08\n",
            "Epoch 28/50\n",
            "132/132 [==============================] - 60s 449ms/step - loss: 0.0927 - acc: 0.9815 - val_loss: 0.4189 - val_acc: 0.8330 - lr: 6.5610e-08\n",
            "Epoch 29/50\n",
            "132/132 [==============================] - 61s 458ms/step - loss: 0.0971 - acc: 0.9788 - val_loss: 0.3777 - val_acc: 0.8587 - lr: 6.5610e-08\n",
            "Epoch 30/50\n",
            "132/132 [==============================] - 59s 446ms/step - loss: 0.0954 - acc: 0.9784 - val_loss: 0.4145 - val_acc: 0.8480 - lr: 6.5610e-08\n",
            "Epoch 31/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0952 - acc: 0.9786\n",
            "Epoch 31: ReduceLROnPlateau reducing learning rate to 1.9683000829218145e-08.\n",
            "132/132 [==============================] - 59s 448ms/step - loss: 0.0952 - acc: 0.9786 - val_loss: 0.4028 - val_acc: 0.8415 - lr: 6.5610e-08\n",
            "Epoch 32/50\n",
            "132/132 [==============================] - 59s 448ms/step - loss: 0.1013 - acc: 0.9774 - val_loss: 0.4151 - val_acc: 0.8330 - lr: 1.9683e-08\n",
            "Epoch 33/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.1015 - acc: 0.9748\n",
            "Epoch 33: ReduceLROnPlateau reducing learning rate to 1e-08.\n",
            "132/132 [==============================] - 59s 448ms/step - loss: 0.1015 - acc: 0.9748 - val_loss: 0.3986 - val_acc: 0.8480 - lr: 1.9683e-08\n",
            "Epoch 34/50\n",
            "132/132 [==============================] - 60s 449ms/step - loss: 0.0960 - acc: 0.9769 - val_loss: 0.4023 - val_acc: 0.8565 - lr: 1.0000e-08\n",
            "Epoch 35/50\n",
            "132/132 [==============================] - 60s 449ms/step - loss: 0.0974 - acc: 0.9757 - val_loss: 0.3939 - val_acc: 0.8480 - lr: 1.0000e-08\n",
            "Epoch 36/50\n",
            "132/132 [==============================] - 59s 447ms/step - loss: 0.0957 - acc: 0.9793 - val_loss: 0.4324 - val_acc: 0.8244 - lr: 1.0000e-08\n",
            "Epoch 37/50\n",
            "132/132 [==============================] - 60s 451ms/step - loss: 0.0967 - acc: 0.9798 - val_loss: 0.4211 - val_acc: 0.8394 - lr: 1.0000e-08\n",
            "Epoch 38/50\n",
            "132/132 [==============================] - 59s 448ms/step - loss: 0.0966 - acc: 0.9795 - val_loss: 0.4285 - val_acc: 0.8480 - lr: 1.0000e-08\n",
            "Epoch 39/50\n",
            "132/132 [==============================] - 59s 447ms/step - loss: 0.0972 - acc: 0.9755 - val_loss: 0.4282 - val_acc: 0.8308 - lr: 1.0000e-08\n",
            "Epoch 40/50\n",
            "132/132 [==============================] - 59s 448ms/step - loss: 0.0989 - acc: 0.9762 - val_loss: 0.4299 - val_acc: 0.8330 - lr: 1.0000e-08\n",
            "Epoch 41/50\n",
            "132/132 [==============================] - 60s 449ms/step - loss: 0.1007 - acc: 0.9765 - val_loss: 0.4045 - val_acc: 0.8373 - lr: 1.0000e-08\n",
            "Epoch 42/50\n",
            "132/132 [==============================] - 60s 449ms/step - loss: 0.0962 - acc: 0.9788 - val_loss: 0.4080 - val_acc: 0.8522 - lr: 1.0000e-08\n"
          ]
        }
      ],
      "source": [
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience = 2, verbose=1,factor=0.3, min_lr=0.00000001)\n",
        "chkpt = ModelCheckpoint(filepath='best_model_effB3_1_vol2.hdf5', monitor='val_acc', save_best_only=True, save_weights_only=True)\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(patience=13, monitor='val_acc', restore_best_weights=True)\n",
        "\n",
        "history31 = model31.fit(train_gen, epochs=50, validation_data=valid_gen, callbacks=[learning_rate_reduction, chkpt, early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "md6f-KBOdafD"
      },
      "outputs": [],
      "source": [
        "model31.load_weights(\"best_model_effB3_1_vol2.hdf5\")\n",
        "preds = model31.predict(X_test)\n",
        "labelled_preds = one_hot_encoder.inverse_transform(preds)\n",
        "pred = pd.DataFrame(labelled_preds, columns =[\"class_id\"])\n",
        "df = pd.read_csv('submission3.csv')\n",
        "df ['class_id']= pred\n",
        "df.to_csv(\"final_submission65_vol2.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzZce1zP6shK"
      },
      "source": [
        "32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQQvBJDS3KZv"
      },
      "outputs": [],
      "source": [
        "base_model32 = tf.keras.applications.EfficientNetB3(include_top=False,\n",
        "                                     weights='imagenet',\n",
        "                                     input_shape=(224, 224, 3))\n",
        "x = base_model32.output\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = Dense(512, activation=None, kernel_regularizer = L1L2(l1=1e-5, l2=1e-3))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('swish')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(512, activation=None, kernel_regularizer = L1L2(l1=1e-5, l2=1e-3))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('swish')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "ouput1 = Dense(3, activation= 'sigmoid')(x)\n",
        "\n",
        "model32 = Model(inputs=base_model32.input, outputs=ouput1)\n",
        "\n",
        "model32.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', metrics=['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpqHUDIS3ITF",
        "outputId": "3a3e2bcf-f47e-4913-f4ef-ca62382aed8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "132/132 [==============================] - 78s 489ms/step - loss: 1.7552 - acc: 0.7396 - val_loss: 1.4863 - val_acc: 0.7409 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "132/132 [==============================] - 60s 454ms/step - loss: 1.0696 - acc: 0.8000 - val_loss: 0.8772 - val_acc: 0.8158 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "132/132 [==============================] - 61s 459ms/step - loss: 0.6488 - acc: 0.8197 - val_loss: 0.5593 - val_acc: 0.7944 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "132/132 [==============================] - 61s 457ms/step - loss: 0.4568 - acc: 0.8347 - val_loss: 0.4788 - val_acc: 0.7944 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "132/132 [==============================] - 61s 458ms/step - loss: 0.3677 - acc: 0.8376 - val_loss: 0.4429 - val_acc: 0.8030 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "132/132 [==============================] - 61s 459ms/step - loss: 0.3267 - acc: 0.8423 - val_loss: 0.3952 - val_acc: 0.7645 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "132/132 [==============================] - 60s 450ms/step - loss: 0.3035 - acc: 0.8599 - val_loss: 0.4292 - val_acc: 0.7859 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.2800 - acc: 0.8683\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "132/132 [==============================] - 59s 447ms/step - loss: 0.2800 - acc: 0.8683 - val_loss: 0.4545 - val_acc: 0.7516 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "132/132 [==============================] - 61s 457ms/step - loss: 0.2146 - acc: 0.9037 - val_loss: 0.3358 - val_acc: 0.8244 - lr: 3.0000e-04\n",
            "Epoch 10/50\n",
            "132/132 [==============================] - 61s 458ms/step - loss: 0.1612 - acc: 0.9334 - val_loss: 0.3212 - val_acc: 0.8201 - lr: 3.0000e-04\n",
            "Epoch 11/50\n",
            "132/132 [==============================] - 59s 447ms/step - loss: 0.1450 - acc: 0.9384 - val_loss: 0.3421 - val_acc: 0.8266 - lr: 3.0000e-04\n",
            "Epoch 12/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.1284 - acc: 0.9451\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "132/132 [==============================] - 59s 447ms/step - loss: 0.1284 - acc: 0.9451 - val_loss: 0.3522 - val_acc: 0.8051 - lr: 3.0000e-04\n",
            "Epoch 13/50\n",
            "132/132 [==============================] - 59s 448ms/step - loss: 0.0948 - acc: 0.9643 - val_loss: 0.3390 - val_acc: 0.8373 - lr: 9.0000e-05\n",
            "Epoch 14/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0757 - acc: 0.9736\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "132/132 [==============================] - 59s 446ms/step - loss: 0.0757 - acc: 0.9736 - val_loss: 0.3459 - val_acc: 0.8415 - lr: 9.0000e-05\n",
            "Epoch 15/50\n",
            "132/132 [==============================] - 59s 448ms/step - loss: 0.0722 - acc: 0.9738 - val_loss: 0.3709 - val_acc: 0.8480 - lr: 2.7000e-05\n",
            "Epoch 16/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0609 - acc: 0.9784\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
            "132/132 [==============================] - 59s 448ms/step - loss: 0.0609 - acc: 0.9784 - val_loss: 0.3665 - val_acc: 0.8373 - lr: 2.7000e-05\n",
            "Epoch 17/50\n",
            "132/132 [==============================] - 60s 450ms/step - loss: 0.0580 - acc: 0.9807 - val_loss: 0.3837 - val_acc: 0.8330 - lr: 8.1000e-06\n",
            "Epoch 18/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0566 - acc: 0.9815\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 2.429999949526973e-06.\n",
            "132/132 [==============================] - 60s 449ms/step - loss: 0.0566 - acc: 0.9815 - val_loss: 0.4060 - val_acc: 0.8330 - lr: 8.1000e-06\n",
            "Epoch 19/50\n",
            "132/132 [==============================] - 59s 448ms/step - loss: 0.0587 - acc: 0.9791 - val_loss: 0.3717 - val_acc: 0.8458 - lr: 2.4300e-06\n",
            "Epoch 20/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0566 - acc: 0.9786\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 7.289999985005124e-07.\n",
            "132/132 [==============================] - 60s 449ms/step - loss: 0.0566 - acc: 0.9786 - val_loss: 0.3979 - val_acc: 0.8522 - lr: 2.4300e-06\n",
            "Epoch 21/50\n",
            "132/132 [==============================] - 60s 451ms/step - loss: 0.0505 - acc: 0.9848 - val_loss: 0.3712 - val_acc: 0.8458 - lr: 7.2900e-07\n",
            "Epoch 22/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0524 - acc: 0.9795\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 2.1870000637136398e-07.\n",
            "132/132 [==============================] - 59s 447ms/step - loss: 0.0524 - acc: 0.9795 - val_loss: 0.3453 - val_acc: 0.8651 - lr: 7.2900e-07\n",
            "Epoch 23/50\n",
            "132/132 [==============================] - 60s 449ms/step - loss: 0.0573 - acc: 0.9800 - val_loss: 0.3959 - val_acc: 0.8458 - lr: 2.1870e-07\n"
          ]
        }
      ],
      "source": [
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', patience = 2, verbose=1,factor=0.3, min_lr=0.00000001)\n",
        "chkpt = ModelCheckpoint(filepath='best_model_effB3_2.hdf5', monitor='val_loss', save_best_only=True, save_weights_only=True)\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(patience=13, monitor='val_loss', restore_best_weights=True)\n",
        "\n",
        "history32 = model32.fit(train_gen, epochs=50, validation_data=valid_gen, callbacks=[learning_rate_reduction, chkpt, early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28ymisEQ3pwJ"
      },
      "outputs": [],
      "source": [
        "model32.load_weights(\"best_model_effB3_2.hdf5\")\n",
        "preds = model32.predict(X_test)\n",
        "labelled_preds = one_hot_encoder.inverse_transform(preds)\n",
        "pred = pd.DataFrame(labelled_preds, columns =[\"class_id\"])\n",
        "df = pd.read_csv('submission3.csv')\n",
        "df ['class_id']= pred\n",
        "df.to_csv(\"final_submission66.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5T-DE1f4d1mH",
        "outputId": "a00c4017-fda0-405b-bf5f-82fca4c95776"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "132/132 [==============================] - 81s 514ms/step - loss: 1.7897 - acc: 0.7356 - val_loss: 1.4909 - val_acc: 0.7816 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "132/132 [==============================] - 59s 446ms/step - loss: 1.1272 - acc: 0.7902 - val_loss: 0.9439 - val_acc: 0.7537 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.7202 - acc: 0.8012\n",
            "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "132/132 [==============================] - 59s 446ms/step - loss: 0.7202 - acc: 0.8012 - val_loss: 1.2123 - val_acc: 0.7238 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "132/132 [==============================] - 61s 457ms/step - loss: 0.5031 - acc: 0.8409 - val_loss: 0.5017 - val_acc: 0.8009 - lr: 3.0000e-04\n",
            "Epoch 5/50\n",
            "132/132 [==============================] - 60s 455ms/step - loss: 0.4114 - acc: 0.8623 - val_loss: 0.4491 - val_acc: 0.8137 - lr: 3.0000e-04\n",
            "Epoch 6/50\n",
            "132/132 [==============================] - 61s 459ms/step - loss: 0.3540 - acc: 0.8716 - val_loss: 0.3925 - val_acc: 0.8373 - lr: 3.0000e-04\n",
            "Epoch 7/50\n",
            "132/132 [==============================] - 59s 445ms/step - loss: 0.3055 - acc: 0.8856 - val_loss: 0.3868 - val_acc: 0.8116 - lr: 3.0000e-04\n",
            "Epoch 8/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.2676 - acc: 0.8954\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "132/132 [==============================] - 59s 447ms/step - loss: 0.2676 - acc: 0.8954 - val_loss: 0.4677 - val_acc: 0.7602 - lr: 3.0000e-04\n",
            "Epoch 9/50\n",
            "132/132 [==============================] - 59s 447ms/step - loss: 0.2047 - acc: 0.9291 - val_loss: 0.3455 - val_acc: 0.8287 - lr: 9.0000e-05\n",
            "Epoch 10/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.1813 - acc: 0.9436\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "132/132 [==============================] - 59s 446ms/step - loss: 0.1813 - acc: 0.9436 - val_loss: 0.3488 - val_acc: 0.8351 - lr: 9.0000e-05\n",
            "Epoch 11/50\n",
            "132/132 [==============================] - 59s 448ms/step - loss: 0.1567 - acc: 0.9493 - val_loss: 0.3704 - val_acc: 0.8330 - lr: 2.7000e-05\n",
            "Epoch 12/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.1407 - acc: 0.9665\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
            "132/132 [==============================] - 59s 446ms/step - loss: 0.1407 - acc: 0.9665 - val_loss: 0.3985 - val_acc: 0.8266 - lr: 2.7000e-05\n",
            "Epoch 13/50\n",
            "132/132 [==============================] - 59s 445ms/step - loss: 0.1292 - acc: 0.9677 - val_loss: 0.3962 - val_acc: 0.8223 - lr: 8.1000e-06\n",
            "Epoch 14/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.1309 - acc: 0.9660\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 2.429999949526973e-06.\n",
            "132/132 [==============================] - 59s 445ms/step - loss: 0.1309 - acc: 0.9660 - val_loss: 0.3955 - val_acc: 0.8308 - lr: 8.1000e-06\n",
            "Epoch 15/50\n",
            "132/132 [==============================] - 61s 457ms/step - loss: 0.1253 - acc: 0.9672 - val_loss: 0.3910 - val_acc: 0.8415 - lr: 2.4300e-06\n",
            "Epoch 16/50\n",
            "132/132 [==============================] - 59s 447ms/step - loss: 0.1206 - acc: 0.9738 - val_loss: 0.4186 - val_acc: 0.8223 - lr: 2.4300e-06\n",
            "Epoch 17/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.1262 - acc: 0.9658\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 7.289999985005124e-07.\n",
            "132/132 [==============================] - 59s 447ms/step - loss: 0.1262 - acc: 0.9658 - val_loss: 0.4044 - val_acc: 0.8373 - lr: 2.4300e-06\n",
            "Epoch 18/50\n",
            "132/132 [==============================] - 59s 445ms/step - loss: 0.1237 - acc: 0.9679 - val_loss: 0.4076 - val_acc: 0.8330 - lr: 7.2900e-07\n",
            "Epoch 19/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.1194 - acc: 0.9712\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 2.1870000637136398e-07.\n",
            "132/132 [==============================] - 59s 445ms/step - loss: 0.1194 - acc: 0.9712 - val_loss: 0.4188 - val_acc: 0.8244 - lr: 7.2900e-07\n",
            "Epoch 20/50\n",
            "132/132 [==============================] - 59s 446ms/step - loss: 0.1263 - acc: 0.9679 - val_loss: 0.4064 - val_acc: 0.8308 - lr: 2.1870e-07\n",
            "Epoch 21/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.1242 - acc: 0.9703\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 6.561000276406048e-08.\n",
            "132/132 [==============================] - 59s 448ms/step - loss: 0.1242 - acc: 0.9703 - val_loss: 0.4071 - val_acc: 0.8308 - lr: 2.1870e-07\n",
            "Epoch 22/50\n",
            "132/132 [==============================] - 59s 446ms/step - loss: 0.1216 - acc: 0.9698 - val_loss: 0.4352 - val_acc: 0.8394 - lr: 6.5610e-08\n",
            "Epoch 23/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.1236 - acc: 0.9686\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 1.9683000829218145e-08.\n",
            "132/132 [==============================] - 59s 445ms/step - loss: 0.1236 - acc: 0.9686 - val_loss: 0.4127 - val_acc: 0.8287 - lr: 6.5610e-08\n",
            "Epoch 24/50\n",
            "132/132 [==============================] - 59s 446ms/step - loss: 0.1224 - acc: 0.9688 - val_loss: 0.4060 - val_acc: 0.8244 - lr: 1.9683e-08\n",
            "Epoch 25/50\n",
            "132/132 [==============================] - 61s 459ms/step - loss: 0.1220 - acc: 0.9707 - val_loss: 0.4013 - val_acc: 0.8458 - lr: 1.9683e-08\n",
            "Epoch 26/50\n",
            "132/132 [==============================] - 59s 446ms/step - loss: 0.1314 - acc: 0.9634 - val_loss: 0.4063 - val_acc: 0.8373 - lr: 1.9683e-08\n",
            "Epoch 27/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.1263 - acc: 0.9658\n",
            "Epoch 27: ReduceLROnPlateau reducing learning rate to 1e-08.\n",
            "132/132 [==============================] - 59s 445ms/step - loss: 0.1263 - acc: 0.9658 - val_loss: 0.4097 - val_acc: 0.8330 - lr: 1.9683e-08\n",
            "Epoch 28/50\n",
            "132/132 [==============================] - 59s 447ms/step - loss: 0.1212 - acc: 0.9691 - val_loss: 0.4123 - val_acc: 0.8287 - lr: 1.0000e-08\n",
            "Epoch 29/50\n",
            "132/132 [==============================] - 59s 445ms/step - loss: 0.1220 - acc: 0.9705 - val_loss: 0.4104 - val_acc: 0.8308 - lr: 1.0000e-08\n",
            "Epoch 30/50\n",
            "132/132 [==============================] - 59s 447ms/step - loss: 0.1212 - acc: 0.9693 - val_loss: 0.4234 - val_acc: 0.8415 - lr: 1.0000e-08\n",
            "Epoch 31/50\n",
            "132/132 [==============================] - 59s 446ms/step - loss: 0.1176 - acc: 0.9715 - val_loss: 0.4018 - val_acc: 0.8415 - lr: 1.0000e-08\n",
            "Epoch 32/50\n",
            "132/132 [==============================] - 59s 445ms/step - loss: 0.1243 - acc: 0.9686 - val_loss: 0.4194 - val_acc: 0.8394 - lr: 1.0000e-08\n",
            "Epoch 33/50\n",
            "132/132 [==============================] - 59s 447ms/step - loss: 0.1255 - acc: 0.9681 - val_loss: 0.4229 - val_acc: 0.8351 - lr: 1.0000e-08\n",
            "Epoch 34/50\n",
            "132/132 [==============================] - 60s 456ms/step - loss: 0.1296 - acc: 0.9639 - val_loss: 0.3772 - val_acc: 0.8501 - lr: 1.0000e-08\n",
            "Epoch 35/50\n",
            "132/132 [==============================] - 59s 444ms/step - loss: 0.1269 - acc: 0.9686 - val_loss: 0.4329 - val_acc: 0.8287 - lr: 1.0000e-08\n",
            "Epoch 36/50\n",
            "132/132 [==============================] - 59s 445ms/step - loss: 0.1222 - acc: 0.9707 - val_loss: 0.4020 - val_acc: 0.8415 - lr: 1.0000e-08\n",
            "Epoch 37/50\n",
            "132/132 [==============================] - 59s 447ms/step - loss: 0.1190 - acc: 0.9729 - val_loss: 0.4448 - val_acc: 0.8244 - lr: 1.0000e-08\n",
            "Epoch 38/50\n",
            "132/132 [==============================] - 59s 447ms/step - loss: 0.1240 - acc: 0.9691 - val_loss: 0.3997 - val_acc: 0.8287 - lr: 1.0000e-08\n",
            "Epoch 39/50\n",
            "132/132 [==============================] - 59s 446ms/step - loss: 0.1246 - acc: 0.9686 - val_loss: 0.4466 - val_acc: 0.8373 - lr: 1.0000e-08\n",
            "Epoch 40/50\n",
            "132/132 [==============================] - 59s 445ms/step - loss: 0.1255 - acc: 0.9698 - val_loss: 0.4102 - val_acc: 0.8266 - lr: 1.0000e-08\n",
            "Epoch 41/50\n",
            "132/132 [==============================] - 59s 447ms/step - loss: 0.1233 - acc: 0.9719 - val_loss: 0.4100 - val_acc: 0.8308 - lr: 1.0000e-08\n",
            "Epoch 42/50\n",
            "132/132 [==============================] - 61s 458ms/step - loss: 0.1244 - acc: 0.9684 - val_loss: 0.3878 - val_acc: 0.8522 - lr: 1.0000e-08\n",
            "Epoch 43/50\n",
            "132/132 [==============================] - 59s 448ms/step - loss: 0.1222 - acc: 0.9691 - val_loss: 0.3993 - val_acc: 0.8415 - lr: 1.0000e-08\n",
            "Epoch 44/50\n",
            "132/132 [==============================] - 59s 447ms/step - loss: 0.1267 - acc: 0.9686 - val_loss: 0.3840 - val_acc: 0.8501 - lr: 1.0000e-08\n",
            "Epoch 45/50\n",
            "132/132 [==============================] - 59s 445ms/step - loss: 0.1265 - acc: 0.9677 - val_loss: 0.3904 - val_acc: 0.8394 - lr: 1.0000e-08\n",
            "Epoch 46/50\n",
            "132/132 [==============================] - 59s 444ms/step - loss: 0.1256 - acc: 0.9686 - val_loss: 0.4190 - val_acc: 0.8394 - lr: 1.0000e-08\n",
            "Epoch 47/50\n",
            "132/132 [==============================] - 59s 446ms/step - loss: 0.1268 - acc: 0.9660 - val_loss: 0.4203 - val_acc: 0.8223 - lr: 1.0000e-08\n",
            "Epoch 48/50\n",
            "132/132 [==============================] - 59s 446ms/step - loss: 0.1209 - acc: 0.9712 - val_loss: 0.4266 - val_acc: 0.8373 - lr: 1.0000e-08\n",
            "Epoch 49/50\n",
            "132/132 [==============================] - 59s 446ms/step - loss: 0.1236 - acc: 0.9684 - val_loss: 0.4040 - val_acc: 0.8373 - lr: 1.0000e-08\n",
            "Epoch 50/50\n",
            "132/132 [==============================] - 59s 446ms/step - loss: 0.1285 - acc: 0.9650 - val_loss: 0.4003 - val_acc: 0.8437 - lr: 1.0000e-08\n"
          ]
        }
      ],
      "source": [
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience = 2, verbose=1,factor=0.3, min_lr=0.00000001)\n",
        "chkpt = ModelCheckpoint(filepath='best_model_effB3_2_vol2.hdf5', monitor='val_acc', save_best_only=True, save_weights_only=True)\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(patience=13, monitor='val_acc', restore_best_weights=True)\n",
        "\n",
        "history32 = model32.fit(train_gen, epochs=50, validation_data=valid_gen, callbacks=[learning_rate_reduction, chkpt, early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkEprY6yd1o_"
      },
      "outputs": [],
      "source": [
        "model32.load_weights(\"best_model_effB3_2_vol2.hdf5\")\n",
        "preds = model32.predict(X_test)\n",
        "labelled_preds = one_hot_encoder.inverse_transform(preds)\n",
        "pred = pd.DataFrame(labelled_preds, columns =[\"class_id\"])\n",
        "df = pd.read_csv('submission3.csv')\n",
        "df ['class_id']= pred\n",
        "df.to_csv(\"final_submission66_vol2.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLbneLbW4yDt"
      },
      "source": [
        "33)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHZV8m7M41-S"
      },
      "outputs": [],
      "source": [
        "base_model33 = tf.keras.applications.EfficientNetB3(include_top=False,\n",
        "                                     weights='imagenet',\n",
        "                                     input_shape=(224, 224, 3))\n",
        "x = base_model33.output\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = Dense(512, activation=None, kernel_regularizer = L1L2(l1=1e-5, l2=1e-3))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('swish')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(256, activation=None, kernel_regularizer = L1L2(l1=1e-5, l2=1e-3))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('swish')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "ouput1 = Dense(3, activation= 'softmax')(x)\n",
        "\n",
        "model33 = Model(inputs=base_model33.input, outputs=ouput1)\n",
        "\n",
        "model33.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', metrics=['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xH0GTPz942Ec",
        "outputId": "92474e8c-fcba-4738-c786-20416157c4a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "132/132 [==============================] - 80s 494ms/step - loss: 1.5700 - acc: 0.7484 - val_loss: 1.4567 - val_acc: 0.5246 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "132/132 [==============================] - 61s 458ms/step - loss: 0.9561 - acc: 0.7902 - val_loss: 0.7686 - val_acc: 0.8051 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "132/132 [==============================] - 61s 459ms/step - loss: 0.5940 - acc: 0.8214 - val_loss: 0.5365 - val_acc: 0.7859 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "132/132 [==============================] - 61s 457ms/step - loss: 0.4543 - acc: 0.8228 - val_loss: 0.4306 - val_acc: 0.7923 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "132/132 [==============================] - 61s 460ms/step - loss: 0.3690 - acc: 0.8309 - val_loss: 0.3772 - val_acc: 0.7966 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "132/132 [==============================] - 61s 460ms/step - loss: 0.3183 - acc: 0.8366 - val_loss: 0.3657 - val_acc: 0.7816 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "132/132 [==============================] - 60s 449ms/step - loss: 0.3017 - acc: 0.8559 - val_loss: 0.3994 - val_acc: 0.7602 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "132/132 [==============================] - 61s 459ms/step - loss: 0.2801 - acc: 0.8587 - val_loss: 0.3319 - val_acc: 0.7966 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "132/132 [==============================] - 60s 449ms/step - loss: 0.2597 - acc: 0.8711 - val_loss: 0.4640 - val_acc: 0.7537 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.2495 - acc: 0.8780\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "132/132 [==============================] - 60s 449ms/step - loss: 0.2495 - acc: 0.8780 - val_loss: 0.4206 - val_acc: 0.7923 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "132/132 [==============================] - 60s 449ms/step - loss: 0.1820 - acc: 0.9163 - val_loss: 0.3321 - val_acc: 0.8158 - lr: 3.0000e-04\n",
            "Epoch 12/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.1386 - acc: 0.9401\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "132/132 [==============================] - 60s 449ms/step - loss: 0.1386 - acc: 0.9401 - val_loss: 0.3678 - val_acc: 0.8009 - lr: 3.0000e-04\n",
            "Epoch 13/50\n",
            "132/132 [==============================] - 61s 460ms/step - loss: 0.1099 - acc: 0.9541 - val_loss: 0.2969 - val_acc: 0.8287 - lr: 9.0000e-05\n",
            "Epoch 14/50\n",
            "132/132 [==============================] - 60s 449ms/step - loss: 0.0861 - acc: 0.9667 - val_loss: 0.3235 - val_acc: 0.8287 - lr: 9.0000e-05\n",
            "Epoch 15/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0807 - acc: 0.9655\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "132/132 [==============================] - 59s 447ms/step - loss: 0.0807 - acc: 0.9655 - val_loss: 0.3182 - val_acc: 0.8480 - lr: 9.0000e-05\n",
            "Epoch 16/50\n",
            "132/132 [==============================] - 60s 450ms/step - loss: 0.0699 - acc: 0.9748 - val_loss: 0.3382 - val_acc: 0.8351 - lr: 2.7000e-05\n",
            "Epoch 17/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0687 - acc: 0.9762\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
            "132/132 [==============================] - 59s 448ms/step - loss: 0.0687 - acc: 0.9762 - val_loss: 0.3314 - val_acc: 0.8437 - lr: 2.7000e-05\n",
            "Epoch 18/50\n",
            "132/132 [==============================] - 59s 448ms/step - loss: 0.0623 - acc: 0.9793 - val_loss: 0.3570 - val_acc: 0.8373 - lr: 8.1000e-06\n",
            "Epoch 19/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0622 - acc: 0.9774\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 2.429999949526973e-06.\n",
            "132/132 [==============================] - 60s 449ms/step - loss: 0.0622 - acc: 0.9774 - val_loss: 0.3367 - val_acc: 0.8544 - lr: 8.1000e-06\n",
            "Epoch 20/50\n",
            "132/132 [==============================] - 60s 450ms/step - loss: 0.0627 - acc: 0.9776 - val_loss: 0.3633 - val_acc: 0.8373 - lr: 2.4300e-06\n",
            "Epoch 21/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0647 - acc: 0.9765\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 7.289999985005124e-07.\n",
            "132/132 [==============================] - 59s 448ms/step - loss: 0.0647 - acc: 0.9765 - val_loss: 0.3384 - val_acc: 0.8565 - lr: 2.4300e-06\n",
            "Epoch 22/50\n",
            "132/132 [==============================] - 60s 450ms/step - loss: 0.0587 - acc: 0.9805 - val_loss: 0.3307 - val_acc: 0.8480 - lr: 7.2900e-07\n",
            "Epoch 23/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0612 - acc: 0.9767\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 2.1870000637136398e-07.\n",
            "132/132 [==============================] - 60s 450ms/step - loss: 0.0612 - acc: 0.9767 - val_loss: 0.3629 - val_acc: 0.8351 - lr: 7.2900e-07\n",
            "Epoch 24/50\n",
            "132/132 [==============================] - 60s 450ms/step - loss: 0.0618 - acc: 0.9769 - val_loss: 0.3136 - val_acc: 0.8522 - lr: 2.1870e-07\n",
            "Epoch 25/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0587 - acc: 0.9800\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 6.561000276406048e-08.\n",
            "132/132 [==============================] - 59s 448ms/step - loss: 0.0587 - acc: 0.9800 - val_loss: 0.3307 - val_acc: 0.8394 - lr: 2.1870e-07\n",
            "Epoch 26/50\n",
            "132/132 [==============================] - 60s 449ms/step - loss: 0.0615 - acc: 0.9769 - val_loss: 0.3449 - val_acc: 0.8437 - lr: 6.5610e-08\n"
          ]
        }
      ],
      "source": [
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', patience = 2, verbose=1,factor=0.3, min_lr=0.00000001)\n",
        "chkpt = ModelCheckpoint(filepath='best_model_effB3_3.hdf5', monitor='val_loss', save_best_only=True, save_weights_only=True)\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(patience=13, monitor='val_loss', restore_best_weights=True)\n",
        "\n",
        "history33 = model33.fit(train_gen, epochs=50, validation_data=valid_gen, callbacks=[learning_rate_reduction, chkpt, early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93_-Cer_5H5a"
      },
      "outputs": [],
      "source": [
        "model33.load_weights(\"best_model_effB3_3.hdf5\")\n",
        "preds = model33.predict(X_test)\n",
        "labelled_preds = one_hot_encoder.inverse_transform(preds)\n",
        "pred = pd.DataFrame(labelled_preds, columns =[\"class_id\"])\n",
        "df = pd.read_csv('submission3.csv')\n",
        "df ['class_id']= pred\n",
        "df.to_csv(\"final_submission67.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ld2UJ8lPpk-O",
        "outputId": "e7d6d4b7-b056-4ad6-d3ea-c9e37c04dea7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "132/132 [==============================] - 76s 473ms/step - loss: 1.5697 - acc: 0.7398 - val_loss: 1.2292 - val_acc: 0.8094 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "132/132 [==============================] - 59s 448ms/step - loss: 0.9530 - acc: 0.7960 - val_loss: 0.8177 - val_acc: 0.7987 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.5973 - acc: 0.8205\n",
            "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "132/132 [==============================] - 59s 448ms/step - loss: 0.5973 - acc: 0.8205 - val_loss: 0.6276 - val_acc: 0.7452 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "132/132 [==============================] - 61s 461ms/step - loss: 0.4285 - acc: 0.8523 - val_loss: 0.4241 - val_acc: 0.8308 - lr: 3.0000e-04\n",
            "Epoch 5/50\n",
            "132/132 [==============================] - 59s 446ms/step - loss: 0.3631 - acc: 0.8683 - val_loss: 0.4132 - val_acc: 0.8223 - lr: 3.0000e-04\n",
            "Epoch 6/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.3136 - acc: 0.8873\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "132/132 [==============================] - 59s 447ms/step - loss: 0.3136 - acc: 0.8873 - val_loss: 0.4432 - val_acc: 0.7944 - lr: 3.0000e-04\n",
            "Epoch 7/50\n",
            "132/132 [==============================] - 61s 460ms/step - loss: 0.2526 - acc: 0.9151 - val_loss: 0.3494 - val_acc: 0.8437 - lr: 9.0000e-05\n",
            "Epoch 8/50\n",
            "132/132 [==============================] - 60s 449ms/step - loss: 0.2278 - acc: 0.9279 - val_loss: 0.3702 - val_acc: 0.8223 - lr: 9.0000e-05\n",
            "Epoch 9/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.2055 - acc: 0.9317\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "132/132 [==============================] - 59s 447ms/step - loss: 0.2055 - acc: 0.9317 - val_loss: 0.3711 - val_acc: 0.8308 - lr: 9.0000e-05\n",
            "Epoch 10/50\n",
            "132/132 [==============================] - 61s 458ms/step - loss: 0.1803 - acc: 0.9510 - val_loss: 0.3489 - val_acc: 0.8501 - lr: 2.7000e-05\n",
            "Epoch 11/50\n",
            "132/132 [==============================] - 59s 448ms/step - loss: 0.1738 - acc: 0.9484 - val_loss: 0.3324 - val_acc: 0.8415 - lr: 2.7000e-05\n",
            "Epoch 12/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.1629 - acc: 0.9572\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
            "132/132 [==============================] - 59s 448ms/step - loss: 0.1629 - acc: 0.9572 - val_loss: 0.3698 - val_acc: 0.8415 - lr: 2.7000e-05\n",
            "Epoch 13/50\n",
            "132/132 [==============================] - 59s 446ms/step - loss: 0.1448 - acc: 0.9639 - val_loss: 0.4134 - val_acc: 0.8351 - lr: 8.1000e-06\n",
            "Epoch 14/50\n",
            "132/132 [==============================] - 61s 459ms/step - loss: 0.1555 - acc: 0.9593 - val_loss: 0.3658 - val_acc: 0.8522 - lr: 8.1000e-06\n",
            "Epoch 15/50\n",
            "132/132 [==============================] - 61s 458ms/step - loss: 0.1508 - acc: 0.9636 - val_loss: 0.3561 - val_acc: 0.8544 - lr: 8.1000e-06\n",
            "Epoch 16/50\n",
            "132/132 [==============================] - 59s 448ms/step - loss: 0.1482 - acc: 0.9646 - val_loss: 0.3821 - val_acc: 0.8415 - lr: 8.1000e-06\n",
            "Epoch 17/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.1449 - acc: 0.9653\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 2.429999949526973e-06.\n",
            "132/132 [==============================] - 59s 447ms/step - loss: 0.1449 - acc: 0.9653 - val_loss: 0.3751 - val_acc: 0.8394 - lr: 8.1000e-06\n",
            "Epoch 18/50\n",
            "132/132 [==============================] - 59s 448ms/step - loss: 0.1443 - acc: 0.9650 - val_loss: 0.3621 - val_acc: 0.8522 - lr: 2.4300e-06\n",
            "Epoch 19/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.1394 - acc: 0.9660\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 7.289999985005124e-07.\n",
            "132/132 [==============================] - 60s 450ms/step - loss: 0.1394 - acc: 0.9660 - val_loss: 0.4035 - val_acc: 0.8330 - lr: 2.4300e-06\n",
            "Epoch 20/50\n",
            "132/132 [==============================] - 59s 447ms/step - loss: 0.1443 - acc: 0.9629 - val_loss: 0.3655 - val_acc: 0.8437 - lr: 7.2900e-07\n",
            "Epoch 21/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.1394 - acc: 0.9674\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 2.1870000637136398e-07.\n",
            "132/132 [==============================] - 60s 449ms/step - loss: 0.1394 - acc: 0.9674 - val_loss: 0.3994 - val_acc: 0.8373 - lr: 7.2900e-07\n",
            "Epoch 22/50\n",
            "132/132 [==============================] - 59s 446ms/step - loss: 0.1374 - acc: 0.9662 - val_loss: 0.3951 - val_acc: 0.8330 - lr: 2.1870e-07\n",
            "Epoch 23/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.1364 - acc: 0.9693\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 6.561000276406048e-08.\n",
            "132/132 [==============================] - 60s 449ms/step - loss: 0.1364 - acc: 0.9693 - val_loss: 0.3898 - val_acc: 0.8437 - lr: 2.1870e-07\n",
            "Epoch 24/50\n",
            "132/132 [==============================] - 59s 448ms/step - loss: 0.1393 - acc: 0.9703 - val_loss: 0.3659 - val_acc: 0.8501 - lr: 6.5610e-08\n",
            "Epoch 25/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.1392 - acc: 0.9679\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 1.9683000829218145e-08.\n",
            "132/132 [==============================] - 60s 451ms/step - loss: 0.1392 - acc: 0.9679 - val_loss: 0.4166 - val_acc: 0.8330 - lr: 6.5610e-08\n",
            "Epoch 26/50\n",
            "132/132 [==============================] - 59s 447ms/step - loss: 0.1419 - acc: 0.9669 - val_loss: 0.3675 - val_acc: 0.8544 - lr: 1.9683e-08\n",
            "Epoch 27/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.1385 - acc: 0.9646\n",
            "Epoch 27: ReduceLROnPlateau reducing learning rate to 1e-08.\n",
            "132/132 [==============================] - 60s 449ms/step - loss: 0.1385 - acc: 0.9646 - val_loss: 0.3860 - val_acc: 0.8330 - lr: 1.9683e-08\n",
            "Epoch 28/50\n",
            "132/132 [==============================] - 60s 451ms/step - loss: 0.1400 - acc: 0.9612 - val_loss: 0.3779 - val_acc: 0.8287 - lr: 1.0000e-08\n"
          ]
        }
      ],
      "source": [
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience = 2, verbose=1,factor=0.3, min_lr=0.00000001)\n",
        "chkpt = ModelCheckpoint(filepath='best_model_effB3_3_vol2.hdf5', monitor='val_acc', save_best_only=True, save_weights_only=True)\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(patience=13, monitor='val_acc', restore_best_weights=True)\n",
        "\n",
        "history33 = model33.fit(train_gen, epochs=50, validation_data=valid_gen, callbacks=[learning_rate_reduction, chkpt, early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GNy5hh2NplB5"
      },
      "outputs": [],
      "source": [
        "model33.load_weights(\"best_model_effB3_3_vol2.hdf5\")\n",
        "preds = model33.predict(X_test)\n",
        "labelled_preds = one_hot_encoder.inverse_transform(preds)\n",
        "pred = pd.DataFrame(labelled_preds, columns =[\"class_id\"])\n",
        "df = pd.read_csv('submission3.csv')\n",
        "df ['class_id']= pred\n",
        "df.to_csv(\"final_submission67_vol2.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxajfbxX6JXv"
      },
      "source": [
        "34)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-_KfCKa6JDG"
      },
      "outputs": [],
      "source": [
        "base_model34 = tf.keras.applications.EfficientNetB3(include_top=False,\n",
        "                                     weights='imagenet',\n",
        "                                     input_shape=(224, 224, 3))\n",
        "x = base_model34.output\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = Dense(256, activation=None, kernel_regularizer = L1L2(l1=1e-5, l2=1e-3))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('swish')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(256, activation=None, kernel_regularizer = L1L2(l1=1e-5, l2=1e-3))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('swish')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "ouput1 = Dense(3, activation= 'softmax')(x)\n",
        "\n",
        "model34 = Model(inputs=base_model34.input, outputs=ouput1)\n",
        "\n",
        "model34.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', metrics=['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zIF1W1m6aAy",
        "outputId": "52385f28-376c-4da0-e518-a253cd64fa3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "132/132 [==============================] - 77s 473ms/step - loss: 1.1164 - acc: 0.7432 - val_loss: 1.2949 - val_acc: 0.6081 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "132/132 [==============================] - 61s 456ms/step - loss: 0.7312 - acc: 0.7924 - val_loss: 0.7025 - val_acc: 0.7537 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "132/132 [==============================] - 60s 455ms/step - loss: 0.4956 - acc: 0.8205 - val_loss: 0.4583 - val_acc: 0.7923 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "132/132 [==============================] - 61s 460ms/step - loss: 0.3907 - acc: 0.8283 - val_loss: 0.3841 - val_acc: 0.8009 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "132/132 [==============================] - 59s 448ms/step - loss: 0.3131 - acc: 0.8433 - val_loss: 0.4088 - val_acc: 0.7901 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "132/132 [==============================] - 61s 461ms/step - loss: 0.2853 - acc: 0.8518 - val_loss: 0.3288 - val_acc: 0.8223 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "132/132 [==============================] - 59s 448ms/step - loss: 0.2676 - acc: 0.8592 - val_loss: 0.3928 - val_acc: 0.7452 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "132/132 [==============================] - 61s 456ms/step - loss: 0.2473 - acc: 0.8678 - val_loss: 0.3125 - val_acc: 0.8223 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "132/132 [==============================] - 59s 448ms/step - loss: 0.2257 - acc: 0.8780 - val_loss: 0.5588 - val_acc: 0.6788 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.2066 - acc: 0.8946\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "132/132 [==============================] - 60s 449ms/step - loss: 0.2066 - acc: 0.8946 - val_loss: 0.3571 - val_acc: 0.7987 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "132/132 [==============================] - 61s 457ms/step - loss: 0.1432 - acc: 0.9294 - val_loss: 0.2939 - val_acc: 0.8351 - lr: 3.0000e-04\n",
            "Epoch 12/50\n",
            "132/132 [==============================] - 59s 448ms/step - loss: 0.1082 - acc: 0.9512 - val_loss: 0.3067 - val_acc: 0.8137 - lr: 3.0000e-04\n",
            "Epoch 13/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0926 - acc: 0.9600\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "132/132 [==============================] - 60s 449ms/step - loss: 0.0926 - acc: 0.9600 - val_loss: 0.3607 - val_acc: 0.8158 - lr: 3.0000e-04\n",
            "Epoch 14/50\n",
            "132/132 [==============================] - 59s 446ms/step - loss: 0.0688 - acc: 0.9698 - val_loss: 0.3396 - val_acc: 0.8266 - lr: 9.0000e-05\n",
            "Epoch 15/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0541 - acc: 0.9769\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "132/132 [==============================] - 60s 451ms/step - loss: 0.0541 - acc: 0.9769 - val_loss: 0.2990 - val_acc: 0.8437 - lr: 9.0000e-05\n",
            "Epoch 16/50\n",
            "132/132 [==============================] - 59s 448ms/step - loss: 0.0502 - acc: 0.9776 - val_loss: 0.3233 - val_acc: 0.8415 - lr: 2.7000e-05\n",
            "Epoch 17/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0473 - acc: 0.9803\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
            "132/132 [==============================] - 59s 448ms/step - loss: 0.0473 - acc: 0.9803 - val_loss: 0.3536 - val_acc: 0.8522 - lr: 2.7000e-05\n",
            "Epoch 18/50\n",
            "132/132 [==============================] - 59s 448ms/step - loss: 0.0461 - acc: 0.9815 - val_loss: 0.3729 - val_acc: 0.8223 - lr: 8.1000e-06\n",
            "Epoch 19/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0421 - acc: 0.9826\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 2.429999949526973e-06.\n",
            "132/132 [==============================] - 60s 449ms/step - loss: 0.0421 - acc: 0.9826 - val_loss: 0.3296 - val_acc: 0.8608 - lr: 8.1000e-06\n",
            "Epoch 20/50\n",
            "132/132 [==============================] - 59s 447ms/step - loss: 0.0398 - acc: 0.9850 - val_loss: 0.3658 - val_acc: 0.8244 - lr: 2.4300e-06\n",
            "Epoch 21/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0412 - acc: 0.9855\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 7.289999985005124e-07.\n",
            "132/132 [==============================] - 60s 450ms/step - loss: 0.0412 - acc: 0.9855 - val_loss: 0.3657 - val_acc: 0.8351 - lr: 2.4300e-06\n",
            "Epoch 22/50\n",
            "132/132 [==============================] - 59s 448ms/step - loss: 0.0438 - acc: 0.9834 - val_loss: 0.3786 - val_acc: 0.8373 - lr: 7.2900e-07\n",
            "Epoch 23/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0434 - acc: 0.9850\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 2.1870000637136398e-07.\n",
            "132/132 [==============================] - 60s 449ms/step - loss: 0.0434 - acc: 0.9850 - val_loss: 0.3395 - val_acc: 0.8480 - lr: 7.2900e-07\n",
            "Epoch 24/50\n",
            "132/132 [==============================] - 60s 449ms/step - loss: 0.0431 - acc: 0.9831 - val_loss: 0.3722 - val_acc: 0.8373 - lr: 2.1870e-07\n"
          ]
        }
      ],
      "source": [
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', patience = 2, verbose=1,factor=0.3, min_lr=0.00000001)\n",
        "chkpt = ModelCheckpoint(filepath='best_model_effB3_4.hdf5', monitor='val_loss', save_best_only=True, save_weights_only=True)\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(patience=13, monitor='val_loss', restore_best_weights=True)\n",
        "\n",
        "history34 = model34.fit(train_gen, epochs=50, validation_data=valid_gen, callbacks=[learning_rate_reduction, chkpt, early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7rFyucID6hnk"
      },
      "outputs": [],
      "source": [
        "model34.load_weights(\"best_model_effB3_4.hdf5\")\n",
        "preds = model34.predict(X_test)\n",
        "labelled_preds = one_hot_encoder.inverse_transform(preds)\n",
        "pred = pd.DataFrame(labelled_preds, columns =[\"class_id\"])\n",
        "df = pd.read_csv('submission3.csv')\n",
        "df ['class_id']= pred\n",
        "df.to_csv(\"final_submission68.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVfy6dIW8x0B",
        "outputId": "b4dbbe78-24ed-4b17-f9a6-eacdcd7145b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "132/132 [==============================] - 117s 683ms/step - loss: 1.1094 - acc: 0.7391 - val_loss: 0.8978 - val_acc: 0.7495 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "132/132 [==============================] - 86s 646ms/step - loss: 0.7211 - acc: 0.7990 - val_loss: 0.6638 - val_acc: 0.7901 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "132/132 [==============================] - 86s 648ms/step - loss: 0.4933 - acc: 0.8214 - val_loss: 0.4531 - val_acc: 0.8009 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "132/132 [==============================] - 85s 638ms/step - loss: 0.3716 - acc: 0.8307 - val_loss: 0.6413 - val_acc: 0.5675 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.3299 - acc: 0.8235\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "132/132 [==============================] - 84s 635ms/step - loss: 0.3299 - acc: 0.8235 - val_loss: 0.3975 - val_acc: 0.7859 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "132/132 [==============================] - 86s 646ms/step - loss: 0.2584 - acc: 0.8697 - val_loss: 0.3002 - val_acc: 0.8266 - lr: 3.0000e-04\n",
            "Epoch 7/50\n",
            "132/132 [==============================] - 84s 635ms/step - loss: 0.2138 - acc: 0.8899 - val_loss: 0.3423 - val_acc: 0.8073 - lr: 3.0000e-04\n",
            "Epoch 8/50\n",
            "132/132 [==============================] - 85s 643ms/step - loss: 0.1839 - acc: 0.9058 - val_loss: 0.3305 - val_acc: 0.8394 - lr: 3.0000e-04\n",
            "Epoch 9/50\n",
            "132/132 [==============================] - 84s 634ms/step - loss: 0.1678 - acc: 0.9210 - val_loss: 0.3324 - val_acc: 0.8201 - lr: 3.0000e-04\n",
            "Epoch 10/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.1575 - acc: 0.9187\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "132/132 [==============================] - 84s 634ms/step - loss: 0.1575 - acc: 0.9187 - val_loss: 0.3315 - val_acc: 0.8030 - lr: 3.0000e-04\n",
            "Epoch 11/50\n",
            "132/132 [==============================] - 84s 637ms/step - loss: 0.1100 - acc: 0.9541 - val_loss: 0.2973 - val_acc: 0.8373 - lr: 9.0000e-05\n",
            "Epoch 12/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0865 - acc: 0.9691\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "132/132 [==============================] - 84s 635ms/step - loss: 0.0865 - acc: 0.9691 - val_loss: 0.3718 - val_acc: 0.8180 - lr: 9.0000e-05\n",
            "Epoch 13/50\n",
            "132/132 [==============================] - 84s 634ms/step - loss: 0.0762 - acc: 0.9717 - val_loss: 0.3490 - val_acc: 0.8287 - lr: 2.7000e-05\n",
            "Epoch 14/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0751 - acc: 0.9757\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
            "132/132 [==============================] - 84s 638ms/step - loss: 0.0751 - acc: 0.9757 - val_loss: 0.3313 - val_acc: 0.8330 - lr: 2.7000e-05\n",
            "Epoch 15/50\n",
            "132/132 [==============================] - 86s 646ms/step - loss: 0.0693 - acc: 0.9746 - val_loss: 0.3293 - val_acc: 0.8522 - lr: 8.1000e-06\n",
            "Epoch 16/50\n",
            "132/132 [==============================] - 84s 635ms/step - loss: 0.0639 - acc: 0.9765 - val_loss: 0.3538 - val_acc: 0.8330 - lr: 8.1000e-06\n",
            "Epoch 17/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0630 - acc: 0.9774\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 2.429999949526973e-06.\n",
            "132/132 [==============================] - 84s 637ms/step - loss: 0.0630 - acc: 0.9774 - val_loss: 0.3573 - val_acc: 0.8394 - lr: 8.1000e-06\n",
            "Epoch 18/50\n",
            "132/132 [==============================] - 84s 634ms/step - loss: 0.0612 - acc: 0.9788 - val_loss: 0.3458 - val_acc: 0.8437 - lr: 2.4300e-06\n",
            "Epoch 19/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0585 - acc: 0.9812\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 7.289999985005124e-07.\n",
            "132/132 [==============================] - 84s 634ms/step - loss: 0.0585 - acc: 0.9812 - val_loss: 0.3483 - val_acc: 0.8437 - lr: 2.4300e-06\n",
            "Epoch 20/50\n",
            "132/132 [==============================] - 84s 633ms/step - loss: 0.0557 - acc: 0.9822 - val_loss: 0.3803 - val_acc: 0.8308 - lr: 7.2900e-07\n",
            "Epoch 21/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0548 - acc: 0.9836\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 2.1870000637136398e-07.\n",
            "132/132 [==============================] - 84s 634ms/step - loss: 0.0548 - acc: 0.9836 - val_loss: 0.3557 - val_acc: 0.8373 - lr: 7.2900e-07\n",
            "Epoch 22/50\n",
            "132/132 [==============================] - 84s 632ms/step - loss: 0.0686 - acc: 0.9762 - val_loss: 0.3797 - val_acc: 0.8266 - lr: 2.1870e-07\n",
            "Epoch 23/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0622 - acc: 0.9781\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 6.561000276406048e-08.\n",
            "132/132 [==============================] - 84s 634ms/step - loss: 0.0622 - acc: 0.9781 - val_loss: 0.3768 - val_acc: 0.8266 - lr: 2.1870e-07\n",
            "Epoch 24/50\n",
            "132/132 [==============================] - 84s 635ms/step - loss: 0.0557 - acc: 0.9815 - val_loss: 0.3644 - val_acc: 0.8437 - lr: 6.5610e-08\n",
            "Epoch 25/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0606 - acc: 0.9793\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 1.9683000829218145e-08.\n",
            "132/132 [==============================] - 84s 634ms/step - loss: 0.0606 - acc: 0.9793 - val_loss: 0.3468 - val_acc: 0.8373 - lr: 6.5610e-08\n",
            "Epoch 26/50\n",
            "132/132 [==============================] - 84s 635ms/step - loss: 0.0568 - acc: 0.9815 - val_loss: 0.3645 - val_acc: 0.8394 - lr: 1.9683e-08\n",
            "Epoch 27/50\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0561 - acc: 0.9826\n",
            "Epoch 27: ReduceLROnPlateau reducing learning rate to 1e-08.\n",
            "132/132 [==============================] - 84s 634ms/step - loss: 0.0561 - acc: 0.9826 - val_loss: 0.3611 - val_acc: 0.8330 - lr: 1.9683e-08\n",
            "Epoch 28/50\n",
            "132/132 [==============================] - 84s 635ms/step - loss: 0.0617 - acc: 0.9805 - val_loss: 0.3707 - val_acc: 0.8373 - lr: 1.0000e-08\n"
          ]
        }
      ],
      "source": [
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience = 2, verbose=1,factor=0.3, min_lr=0.00000001)\n",
        "chkpt = ModelCheckpoint(filepath='best_model_effB3_4_vol2.hdf5', monitor='val_acc', save_best_only=True, save_weights_only=True)\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(patience=13, monitor='val_acc', restore_best_weights=True)\n",
        "\n",
        "history34 = model34.fit(train_gen, epochs=50, validation_data=valid_gen, callbacks=[learning_rate_reduction, chkpt, early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-DhNnJn8x3D"
      },
      "outputs": [],
      "source": [
        "model34.load_weights(\"best_model_effB3_4_vol2.hdf5\")\n",
        "preds = model34.predict(X_test)\n",
        "labelled_preds = one_hot_encoder.inverse_transform(preds)\n",
        "pred = pd.DataFrame(labelled_preds, columns =[\"class_id\"])\n",
        "df = pd.read_csv('submission3.csv')\n",
        "df ['class_id']= pred\n",
        "df.to_csv(\"final_submission68_vol2.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HGxAR-U60_2"
      },
      "source": [
        "35)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7hj5gxFW60xB"
      },
      "outputs": [],
      "source": [
        "base_model35 = tf.keras.applications.EfficientNetB3(include_top=False,\n",
        "                                     weights='imagenet',\n",
        "                                     input_shape=(224, 224, 3))\n",
        "x = base_model35.output\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = Dense(512, activation=None, kernel_regularizer = L1L2(l1=1e-5, l2=1e-3))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('swish')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(512, activation=None, kernel_regularizer = L1L2(l1=1e-5, l2=1e-3))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('swish')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "ouput1 = Dense(3, activation= 'sigmoid')(x)\n",
        "\n",
        "model35 = Model(inputs=base_model35.input, outputs=ouput1)\n",
        "\n",
        "model35.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', metrics=['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lD_I_zK97CYC",
        "outputId": "7217cd0a-33af-45af-d664-ad0bb2bcabc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "132/132 [==============================] - 78s 482ms/step - loss: 1.7684 - acc: 0.7386 - val_loss: 1.4336 - val_acc: 0.7602 - lr: 0.0010\n",
            "Epoch 2/20\n",
            "132/132 [==============================] - 60s 454ms/step - loss: 1.0814 - acc: 0.8050 - val_loss: 0.8540 - val_acc: 0.8116 - lr: 0.0010\n",
            "Epoch 3/20\n",
            "132/132 [==============================] - 60s 450ms/step - loss: 0.6843 - acc: 0.8138 - val_loss: 0.5644 - val_acc: 0.8244 - lr: 0.0010\n",
            "Epoch 4/20\n",
            "132/132 [==============================] - 60s 455ms/step - loss: 0.4615 - acc: 0.8254 - val_loss: 0.4187 - val_acc: 0.7987 - lr: 0.0010\n",
            "Epoch 5/20\n",
            "132/132 [==============================] - 60s 454ms/step - loss: 0.3706 - acc: 0.8400 - val_loss: 0.4150 - val_acc: 0.8030 - lr: 0.0010\n",
            "Epoch 6/20\n",
            "132/132 [==============================] - 60s 453ms/step - loss: 0.3371 - acc: 0.8466 - val_loss: 0.3942 - val_acc: 0.8030 - lr: 0.0010\n",
            "Epoch 7/20\n",
            "132/132 [==============================] - 60s 452ms/step - loss: 0.3220 - acc: 0.8480 - val_loss: 0.3849 - val_acc: 0.8009 - lr: 0.0010\n",
            "Epoch 8/20\n",
            "132/132 [==============================] - 59s 442ms/step - loss: 0.2814 - acc: 0.8566 - val_loss: 0.4111 - val_acc: 0.7923 - lr: 0.0010\n",
            "Epoch 9/20\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.2614 - acc: 0.8780\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "132/132 [==============================] - 59s 442ms/step - loss: 0.2614 - acc: 0.8780 - val_loss: 0.4778 - val_acc: 0.7623 - lr: 0.0010\n",
            "Epoch 10/20\n",
            "132/132 [==============================] - 60s 453ms/step - loss: 0.2085 - acc: 0.9027 - val_loss: 0.2969 - val_acc: 0.8158 - lr: 3.0000e-04\n",
            "Epoch 11/20\n",
            "132/132 [==============================] - 60s 454ms/step - loss: 0.1503 - acc: 0.9372 - val_loss: 0.2875 - val_acc: 0.8458 - lr: 3.0000e-04\n",
            "Epoch 12/20\n",
            "132/132 [==============================] - 59s 441ms/step - loss: 0.1291 - acc: 0.9465 - val_loss: 0.3727 - val_acc: 0.8116 - lr: 3.0000e-04\n",
            "Epoch 13/20\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.1241 - acc: 0.9463\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "132/132 [==============================] - 59s 443ms/step - loss: 0.1241 - acc: 0.9463 - val_loss: 0.4866 - val_acc: 0.7559 - lr: 3.0000e-04\n",
            "Epoch 14/20\n",
            "132/132 [==============================] - 58s 440ms/step - loss: 0.0904 - acc: 0.9679 - val_loss: 0.3376 - val_acc: 0.8094 - lr: 9.0000e-05\n",
            "Epoch 15/20\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0749 - acc: 0.9722\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "132/132 [==============================] - 59s 442ms/step - loss: 0.0749 - acc: 0.9722 - val_loss: 0.3476 - val_acc: 0.8458 - lr: 9.0000e-05\n",
            "Epoch 16/20\n",
            "132/132 [==============================] - 59s 441ms/step - loss: 0.0641 - acc: 0.9774 - val_loss: 0.3685 - val_acc: 0.8308 - lr: 2.7000e-05\n",
            "Epoch 17/20\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0617 - acc: 0.9798\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
            "132/132 [==============================] - 58s 441ms/step - loss: 0.0617 - acc: 0.9798 - val_loss: 0.3513 - val_acc: 0.8373 - lr: 2.7000e-05\n",
            "Epoch 18/20\n",
            "132/132 [==============================] - 59s 442ms/step - loss: 0.0560 - acc: 0.9826 - val_loss: 0.3560 - val_acc: 0.8351 - lr: 8.1000e-06\n",
            "Epoch 19/20\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0490 - acc: 0.9845\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 2.429999949526973e-06.\n",
            "132/132 [==============================] - 59s 443ms/step - loss: 0.0490 - acc: 0.9845 - val_loss: 0.3747 - val_acc: 0.8394 - lr: 8.1000e-06\n",
            "Epoch 20/20\n",
            "132/132 [==============================] - 59s 441ms/step - loss: 0.0522 - acc: 0.9810 - val_loss: 0.3965 - val_acc: 0.8287 - lr: 2.4300e-06\n"
          ]
        }
      ],
      "source": [
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', patience = 2, verbose=1,factor=0.3, min_lr=0.00000001)\n",
        "chkpt = ModelCheckpoint(filepath='best_model_effB3_5.hdf5', monitor='val_loss', save_best_only=True, save_weights_only=True)\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(patience=13, monitor='val_loss', restore_best_weights=True)\n",
        "\n",
        "history35 = model35.fit(train_gen, epochs=20, validation_data=valid_gen, callbacks=[learning_rate_reduction, chkpt, early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tuNC6W0W7Lo8"
      },
      "outputs": [],
      "source": [
        "model35.load_weights(\"best_model_effB3_5.hdf5\")\n",
        "preds = model35.predict(X_test)\n",
        "labelled_preds = one_hot_encoder.inverse_transform(preds)\n",
        "pred = pd.DataFrame(labelled_preds, columns =[\"class_id\"])\n",
        "df = pd.read_csv('submission3.csv')\n",
        "df ['class_id']= pred\n",
        "df.to_csv(\"final_submission69.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3Uqy5xe9N5x",
        "outputId": "66d1b6b3-2c8c-4f51-dd15-0a69d791d446"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/35\n",
            "132/132 [==============================] - 101s 660ms/step - loss: 1.7355 - acc: 0.7477 - val_loss: 1.4295 - val_acc: 0.7216 - lr: 0.0010\n",
            "Epoch 2/35\n",
            "132/132 [==============================] - 86s 646ms/step - loss: 1.0232 - acc: 0.7974 - val_loss: 0.8426 - val_acc: 0.7923 - lr: 0.0010\n",
            "Epoch 3/35\n",
            "132/132 [==============================] - 84s 634ms/step - loss: 0.6304 - acc: 0.8105 - val_loss: 0.5450 - val_acc: 0.7859 - lr: 0.0010\n",
            "Epoch 4/35\n",
            "132/132 [==============================] - 85s 645ms/step - loss: 0.4639 - acc: 0.8197 - val_loss: 0.4158 - val_acc: 0.8223 - lr: 0.0010\n",
            "Epoch 5/35\n",
            "132/132 [==============================] - 84s 633ms/step - loss: 0.3779 - acc: 0.8369 - val_loss: 0.4200 - val_acc: 0.7859 - lr: 0.0010\n",
            "Epoch 6/35\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.3422 - acc: 0.8376\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "132/132 [==============================] - 84s 633ms/step - loss: 0.3422 - acc: 0.8376 - val_loss: 0.3759 - val_acc: 0.7901 - lr: 0.0010\n",
            "Epoch 7/35\n",
            "132/132 [==============================] - 85s 643ms/step - loss: 0.2595 - acc: 0.8837 - val_loss: 0.3125 - val_acc: 0.8266 - lr: 3.0000e-04\n",
            "Epoch 8/35\n",
            "132/132 [==============================] - 84s 631ms/step - loss: 0.2062 - acc: 0.9061 - val_loss: 0.3561 - val_acc: 0.8094 - lr: 3.0000e-04\n",
            "Epoch 9/35\n",
            "132/132 [==============================] - 85s 644ms/step - loss: 0.1849 - acc: 0.9137 - val_loss: 0.3006 - val_acc: 0.8308 - lr: 3.0000e-04\n",
            "Epoch 10/35\n",
            "132/132 [==============================] - 86s 647ms/step - loss: 0.1682 - acc: 0.9270 - val_loss: 0.3015 - val_acc: 0.8458 - lr: 3.0000e-04\n",
            "Epoch 11/35\n",
            "132/132 [==============================] - 84s 633ms/step - loss: 0.1469 - acc: 0.9377 - val_loss: 0.3278 - val_acc: 0.8330 - lr: 3.0000e-04\n",
            "Epoch 12/35\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.1311 - acc: 0.9439\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "132/132 [==============================] - 84s 631ms/step - loss: 0.1311 - acc: 0.9439 - val_loss: 0.3471 - val_acc: 0.8223 - lr: 3.0000e-04\n",
            "Epoch 13/35\n",
            "132/132 [==============================] - 84s 632ms/step - loss: 0.1029 - acc: 0.9622 - val_loss: 0.3235 - val_acc: 0.8458 - lr: 9.0000e-05\n",
            "Epoch 14/35\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0749 - acc: 0.9757\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "132/132 [==============================] - 84s 632ms/step - loss: 0.0749 - acc: 0.9757 - val_loss: 0.3287 - val_acc: 0.8437 - lr: 9.0000e-05\n",
            "Epoch 15/35\n",
            "132/132 [==============================] - 84s 632ms/step - loss: 0.0652 - acc: 0.9767 - val_loss: 0.3558 - val_acc: 0.8394 - lr: 2.7000e-05\n",
            "Epoch 16/35\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0551 - acc: 0.9850\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
            "132/132 [==============================] - 84s 632ms/step - loss: 0.0551 - acc: 0.9850 - val_loss: 0.3674 - val_acc: 0.8458 - lr: 2.7000e-05\n",
            "Epoch 17/35\n",
            "132/132 [==============================] - 84s 634ms/step - loss: 0.0533 - acc: 0.9848 - val_loss: 0.3862 - val_acc: 0.8437 - lr: 8.1000e-06\n",
            "Epoch 18/35\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0471 - acc: 0.9881\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 2.429999949526973e-06.\n",
            "132/132 [==============================] - 84s 634ms/step - loss: 0.0471 - acc: 0.9881 - val_loss: 0.3617 - val_acc: 0.8458 - lr: 8.1000e-06\n",
            "Epoch 19/35\n",
            "132/132 [==============================] - 85s 644ms/step - loss: 0.0518 - acc: 0.9843 - val_loss: 0.3680 - val_acc: 0.8544 - lr: 2.4300e-06\n",
            "Epoch 20/35\n",
            "132/132 [==============================] - 84s 635ms/step - loss: 0.0475 - acc: 0.9857 - val_loss: 0.3756 - val_acc: 0.8351 - lr: 2.4300e-06\n",
            "Epoch 21/35\n",
            "132/132 [==============================] - 85s 645ms/step - loss: 0.0512 - acc: 0.9855 - val_loss: 0.3809 - val_acc: 0.8694 - lr: 2.4300e-06\n",
            "Epoch 22/35\n",
            "132/132 [==============================] - 84s 630ms/step - loss: 0.0493 - acc: 0.9862 - val_loss: 0.3865 - val_acc: 0.8565 - lr: 2.4300e-06\n",
            "Epoch 23/35\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0532 - acc: 0.9807\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 7.289999985005124e-07.\n",
            "132/132 [==============================] - 84s 634ms/step - loss: 0.0532 - acc: 0.9807 - val_loss: 0.3597 - val_acc: 0.8544 - lr: 2.4300e-06\n",
            "Epoch 24/35\n",
            "132/132 [==============================] - 84s 632ms/step - loss: 0.0471 - acc: 0.9850 - val_loss: 0.3824 - val_acc: 0.8458 - lr: 7.2900e-07\n",
            "Epoch 25/35\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0542 - acc: 0.9848\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 2.1870000637136398e-07.\n",
            "132/132 [==============================] - 83s 630ms/step - loss: 0.0542 - acc: 0.9848 - val_loss: 0.3752 - val_acc: 0.8522 - lr: 7.2900e-07\n",
            "Epoch 26/35\n",
            "132/132 [==============================] - 83s 629ms/step - loss: 0.0459 - acc: 0.9881 - val_loss: 0.3725 - val_acc: 0.8587 - lr: 2.1870e-07\n",
            "Epoch 27/35\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0458 - acc: 0.9881\n",
            "Epoch 27: ReduceLROnPlateau reducing learning rate to 6.561000276406048e-08.\n",
            "132/132 [==============================] - 84s 631ms/step - loss: 0.0458 - acc: 0.9881 - val_loss: 0.3627 - val_acc: 0.8544 - lr: 2.1870e-07\n",
            "Epoch 28/35\n",
            "132/132 [==============================] - 84s 631ms/step - loss: 0.0541 - acc: 0.9810 - val_loss: 0.3396 - val_acc: 0.8630 - lr: 6.5610e-08\n",
            "Epoch 29/35\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0456 - acc: 0.9872\n",
            "Epoch 29: ReduceLROnPlateau reducing learning rate to 1.9683000829218145e-08.\n",
            "132/132 [==============================] - 84s 631ms/step - loss: 0.0456 - acc: 0.9872 - val_loss: 0.3930 - val_acc: 0.8415 - lr: 6.5610e-08\n",
            "Epoch 30/35\n",
            "132/132 [==============================] - 84s 631ms/step - loss: 0.0504 - acc: 0.9848 - val_loss: 0.3723 - val_acc: 0.8458 - lr: 1.9683e-08\n",
            "Epoch 31/35\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0478 - acc: 0.9872\n",
            "Epoch 31: ReduceLROnPlateau reducing learning rate to 1e-08.\n",
            "132/132 [==============================] - 84s 632ms/step - loss: 0.0478 - acc: 0.9872 - val_loss: 0.3549 - val_acc: 0.8587 - lr: 1.9683e-08\n",
            "Epoch 32/35\n",
            "132/132 [==============================] - 84s 635ms/step - loss: 0.0502 - acc: 0.9850 - val_loss: 0.3608 - val_acc: 0.8501 - lr: 1.0000e-08\n",
            "Epoch 33/35\n",
            "132/132 [==============================] - 84s 633ms/step - loss: 0.0542 - acc: 0.9817 - val_loss: 0.3585 - val_acc: 0.8544 - lr: 1.0000e-08\n",
            "Epoch 34/35\n",
            "132/132 [==============================] - 84s 634ms/step - loss: 0.0521 - acc: 0.9848 - val_loss: 0.3584 - val_acc: 0.8587 - lr: 1.0000e-08\n"
          ]
        }
      ],
      "source": [
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience = 2, verbose=1,factor=0.3, min_lr=0.00000001)\n",
        "chkpt = ModelCheckpoint(filepath='best_model_effB3_5_vol2.hdf5', monitor='val_acc', save_best_only=True, save_weights_only=True)\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(patience=13, monitor='val_acc', restore_best_weights=True)\n",
        "\n",
        "history35 = model35.fit(train_gen, epochs=35, validation_data=valid_gen, callbacks=[learning_rate_reduction, chkpt, early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8maXSwkm9N8U"
      },
      "outputs": [],
      "source": [
        "model35.load_weights(\"best_model_effB3_5_vol2.hdf5\")\n",
        "preds = model35.predict(X_test)\n",
        "labelled_preds = one_hot_encoder.inverse_transform(preds)\n",
        "pred = pd.DataFrame(labelled_preds, columns =[\"class_id\"])\n",
        "df = pd.read_csv('submission3.csv')\n",
        "df ['class_id']= pred\n",
        "df.to_csv(\"final_submission69_vol2.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8NtpjGt7Xz0"
      },
      "source": [
        "36)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fpvne3RT7TcM"
      },
      "outputs": [],
      "source": [
        "base_model36 = tf.keras.applications.EfficientNetB3(include_top=False,\n",
        "                                     weights='imagenet',\n",
        "                                     input_shape=(224, 224, 3))\n",
        "x = base_model36.output\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = Dense(512, activation=None, kernel_regularizer = L1L2(l1=1e-5, l2=1e-3))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('swish')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(512, activation=None, kernel_regularizer = L1L2(l1=1e-5, l2=1e-3))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('swish')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "ouput1 = Dense(3, activation= 'sigmoid')(x)\n",
        "\n",
        "model36 = Model(inputs=base_model36.input, outputs=ouput1)\n",
        "\n",
        "model36.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', metrics=['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3Fl4yjg7hgk",
        "outputId": "aabec1ac-cd9f-4397-bce3-8b793aec6c47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "132/132 [==============================] - 75s 471ms/step - loss: 1.7492 - acc: 0.7444 - val_loss: 1.4678 - val_acc: 0.6981 - lr: 0.0010\n",
            "Epoch 2/60\n",
            "132/132 [==============================] - 61s 460ms/step - loss: 1.0570 - acc: 0.7957 - val_loss: 1.1470 - val_acc: 0.6745 - lr: 0.0010\n",
            "Epoch 3/60\n",
            "132/132 [==============================] - 61s 457ms/step - loss: 0.6548 - acc: 0.8174 - val_loss: 0.6082 - val_acc: 0.7580 - lr: 0.0010\n",
            "Epoch 4/60\n",
            "132/132 [==============================] - 61s 457ms/step - loss: 0.4551 - acc: 0.8328 - val_loss: 0.4720 - val_acc: 0.7987 - lr: 0.0010\n",
            "Epoch 5/60\n",
            "132/132 [==============================] - 61s 457ms/step - loss: 0.3764 - acc: 0.8326 - val_loss: 0.4345 - val_acc: 0.7730 - lr: 0.0010\n",
            "Epoch 6/60\n",
            "132/132 [==============================] - 61s 457ms/step - loss: 0.3332 - acc: 0.8523 - val_loss: 0.3688 - val_acc: 0.8073 - lr: 0.0010\n",
            "Epoch 7/60\n",
            "132/132 [==============================] - 61s 458ms/step - loss: 0.3078 - acc: 0.8485 - val_loss: 0.3545 - val_acc: 0.8266 - lr: 0.0010\n",
            "Epoch 8/60\n",
            "132/132 [==============================] - 59s 446ms/step - loss: 0.3185 - acc: 0.8599 - val_loss: 0.4046 - val_acc: 0.8009 - lr: 0.0010\n",
            "Epoch 9/60\n",
            "132/132 [==============================] - 60s 455ms/step - loss: 0.2799 - acc: 0.8721 - val_loss: 0.3392 - val_acc: 0.8073 - lr: 0.0010\n",
            "Epoch 10/60\n",
            "132/132 [==============================] - 59s 448ms/step - loss: 0.2534 - acc: 0.8849 - val_loss: 0.4106 - val_acc: 0.7666 - lr: 0.0010\n",
            "Epoch 11/60\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.2353 - acc: 0.8927\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "132/132 [==============================] - 59s 444ms/step - loss: 0.2353 - acc: 0.8927 - val_loss: 0.4069 - val_acc: 0.7987 - lr: 0.0010\n",
            "Epoch 12/60\n",
            "132/132 [==============================] - 61s 457ms/step - loss: 0.1845 - acc: 0.9206 - val_loss: 0.3234 - val_acc: 0.8244 - lr: 3.0000e-04\n",
            "Epoch 13/60\n",
            "132/132 [==============================] - 61s 457ms/step - loss: 0.1338 - acc: 0.9451 - val_loss: 0.3090 - val_acc: 0.8330 - lr: 3.0000e-04\n",
            "Epoch 14/60\n",
            "132/132 [==============================] - 59s 447ms/step - loss: 0.1104 - acc: 0.9579 - val_loss: 0.3502 - val_acc: 0.8287 - lr: 3.0000e-04\n",
            "Epoch 15/60\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0937 - acc: 0.9615\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "132/132 [==============================] - 59s 446ms/step - loss: 0.0937 - acc: 0.9615 - val_loss: 0.4073 - val_acc: 0.8073 - lr: 3.0000e-04\n",
            "Epoch 16/60\n",
            "132/132 [==============================] - 59s 443ms/step - loss: 0.0709 - acc: 0.9755 - val_loss: 0.3623 - val_acc: 0.8116 - lr: 9.0000e-05\n",
            "Epoch 17/60\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0560 - acc: 0.9788\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "132/132 [==============================] - 59s 447ms/step - loss: 0.0560 - acc: 0.9788 - val_loss: 0.3627 - val_acc: 0.8394 - lr: 9.0000e-05\n",
            "Epoch 18/60\n",
            "132/132 [==============================] - 59s 446ms/step - loss: 0.0565 - acc: 0.9805 - val_loss: 0.3849 - val_acc: 0.8373 - lr: 2.7000e-05\n",
            "Epoch 19/60\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0424 - acc: 0.9893\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
            "132/132 [==============================] - 59s 447ms/step - loss: 0.0424 - acc: 0.9893 - val_loss: 0.3715 - val_acc: 0.8351 - lr: 2.7000e-05\n",
            "Epoch 20/60\n",
            "132/132 [==============================] - 59s 447ms/step - loss: 0.0413 - acc: 0.9876 - val_loss: 0.3895 - val_acc: 0.8201 - lr: 8.1000e-06\n",
            "Epoch 21/60\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0387 - acc: 0.9883\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 2.429999949526973e-06.\n",
            "132/132 [==============================] - 59s 443ms/step - loss: 0.0387 - acc: 0.9883 - val_loss: 0.3995 - val_acc: 0.8394 - lr: 8.1000e-06\n",
            "Epoch 22/60\n",
            "132/132 [==============================] - 59s 446ms/step - loss: 0.0458 - acc: 0.9836 - val_loss: 0.4143 - val_acc: 0.8394 - lr: 2.4300e-06\n",
            "Epoch 23/60\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0393 - acc: 0.9874\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 7.289999985005124e-07.\n",
            "132/132 [==============================] - 60s 452ms/step - loss: 0.0393 - acc: 0.9874 - val_loss: 0.4327 - val_acc: 0.8223 - lr: 2.4300e-06\n",
            "Epoch 24/60\n",
            "132/132 [==============================] - 60s 450ms/step - loss: 0.0422 - acc: 0.9874 - val_loss: 0.4239 - val_acc: 0.8266 - lr: 7.2900e-07\n",
            "Epoch 25/60\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0420 - acc: 0.9848\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 2.1870000637136398e-07.\n",
            "132/132 [==============================] - 60s 450ms/step - loss: 0.0420 - acc: 0.9848 - val_loss: 0.4109 - val_acc: 0.8373 - lr: 7.2900e-07\n",
            "Epoch 26/60\n",
            "132/132 [==============================] - 59s 446ms/step - loss: 0.0416 - acc: 0.9872 - val_loss: 0.4448 - val_acc: 0.8373 - lr: 2.1870e-07\n"
          ]
        }
      ],
      "source": [
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', patience = 2, verbose=1,factor=0.3, min_lr=0.00000001)\n",
        "chkpt = ModelCheckpoint(filepath='best_model_effB3_6.hdf5', monitor='val_loss', save_best_only=True, save_weights_only=True)\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(patience=13, monitor='val_loss', restore_best_weights=True)\n",
        "\n",
        "history36 = model36.fit(train_gen, epochs=60, validation_data=valid_gen, callbacks=[learning_rate_reduction, chkpt, early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FjvQ1p_l7o3F"
      },
      "outputs": [],
      "source": [
        "model36.load_weights(\"best_model_effB3_6.hdf5\")\n",
        "preds = model36.predict(X_test)\n",
        "labelled_preds = one_hot_encoder.inverse_transform(preds)\n",
        "pred = pd.DataFrame(labelled_preds, columns =[\"class_id\"])\n",
        "df = pd.read_csv('submission3.csv')\n",
        "df ['class_id']= pred\n",
        "df.to_csv(\"final_submission70.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_LWCsLwWxKA",
        "outputId": "1a1295b9-a59b-4cb7-9347-d3b93e54527e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "132/132 [==============================] - 104s 673ms/step - loss: 1.7328 - acc: 0.7432 - val_loss: 1.7526 - val_acc: 0.7495 - lr: 0.0010\n",
            "Epoch 2/60\n",
            "132/132 [==============================] - 86s 649ms/step - loss: 1.0308 - acc: 0.8057 - val_loss: 0.8516 - val_acc: 0.7816 - lr: 0.0010\n",
            "Epoch 3/60\n",
            "132/132 [==============================] - 84s 630ms/step - loss: 0.6365 - acc: 0.8117 - val_loss: 0.6479 - val_acc: 0.7709 - lr: 0.0010\n",
            "Epoch 4/60\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.4479 - acc: 0.8281\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "132/132 [==============================] - 83s 629ms/step - loss: 0.4479 - acc: 0.8281 - val_loss: 0.4947 - val_acc: 0.7645 - lr: 0.0010\n",
            "Epoch 5/60\n",
            "132/132 [==============================] - 85s 641ms/step - loss: 0.3401 - acc: 0.8630 - val_loss: 0.3568 - val_acc: 0.8437 - lr: 3.0000e-04\n",
            "Epoch 6/60\n",
            "132/132 [==============================] - 83s 630ms/step - loss: 0.2727 - acc: 0.8892 - val_loss: 0.3528 - val_acc: 0.8051 - lr: 3.0000e-04\n",
            "Epoch 7/60\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.2528 - acc: 0.8977\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "132/132 [==============================] - 84s 630ms/step - loss: 0.2528 - acc: 0.8977 - val_loss: 0.3732 - val_acc: 0.8244 - lr: 3.0000e-04\n",
            "Epoch 8/60\n",
            "132/132 [==============================] - 83s 630ms/step - loss: 0.1999 - acc: 0.9182 - val_loss: 0.3161 - val_acc: 0.8330 - lr: 9.0000e-05\n",
            "Epoch 9/60\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.1691 - acc: 0.9434\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "132/132 [==============================] - 83s 629ms/step - loss: 0.1691 - acc: 0.9434 - val_loss: 0.3462 - val_acc: 0.8330 - lr: 9.0000e-05\n",
            "Epoch 10/60\n",
            "132/132 [==============================] - 83s 630ms/step - loss: 0.1423 - acc: 0.9489 - val_loss: 0.3535 - val_acc: 0.8415 - lr: 2.7000e-05\n",
            "Epoch 11/60\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.1402 - acc: 0.9560\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
            "132/132 [==============================] - 83s 630ms/step - loss: 0.1402 - acc: 0.9560 - val_loss: 0.3503 - val_acc: 0.8373 - lr: 2.7000e-05\n",
            "Epoch 12/60\n",
            "132/132 [==============================] - 83s 630ms/step - loss: 0.1325 - acc: 0.9529 - val_loss: 0.3614 - val_acc: 0.8394 - lr: 8.1000e-06\n",
            "Epoch 13/60\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.1176 - acc: 0.9650\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 2.429999949526973e-06.\n",
            "132/132 [==============================] - 83s 630ms/step - loss: 0.1176 - acc: 0.9650 - val_loss: 0.3626 - val_acc: 0.8437 - lr: 8.1000e-06\n",
            "Epoch 14/60\n",
            "132/132 [==============================] - 85s 641ms/step - loss: 0.1186 - acc: 0.9622 - val_loss: 0.3750 - val_acc: 0.8501 - lr: 2.4300e-06\n",
            "Epoch 15/60\n",
            "132/132 [==============================] - 83s 630ms/step - loss: 0.1224 - acc: 0.9593 - val_loss: 0.3834 - val_acc: 0.8330 - lr: 2.4300e-06\n",
            "Epoch 16/60\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.1190 - acc: 0.9631\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 7.289999985005124e-07.\n",
            "132/132 [==============================] - 83s 629ms/step - loss: 0.1190 - acc: 0.9631 - val_loss: 0.3689 - val_acc: 0.8351 - lr: 2.4300e-06\n",
            "Epoch 17/60\n",
            "132/132 [==============================] - 83s 629ms/step - loss: 0.1243 - acc: 0.9610 - val_loss: 0.3678 - val_acc: 0.8415 - lr: 7.2900e-07\n",
            "Epoch 18/60\n",
            "132/132 [==============================] - 85s 642ms/step - loss: 0.1235 - acc: 0.9608 - val_loss: 0.3612 - val_acc: 0.8522 - lr: 7.2900e-07\n",
            "Epoch 19/60\n",
            "132/132 [==============================] - 83s 630ms/step - loss: 0.1230 - acc: 0.9629 - val_loss: 0.3796 - val_acc: 0.8287 - lr: 7.2900e-07\n",
            "Epoch 20/60\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.1129 - acc: 0.9679\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 2.1870000637136398e-07.\n",
            "132/132 [==============================] - 83s 629ms/step - loss: 0.1129 - acc: 0.9679 - val_loss: 0.3669 - val_acc: 0.8522 - lr: 7.2900e-07\n",
            "Epoch 21/60\n",
            "132/132 [==============================] - 83s 629ms/step - loss: 0.1209 - acc: 0.9615 - val_loss: 0.3687 - val_acc: 0.8458 - lr: 2.1870e-07\n",
            "Epoch 22/60\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.1212 - acc: 0.9617\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 6.561000276406048e-08.\n",
            "132/132 [==============================] - 83s 630ms/step - loss: 0.1212 - acc: 0.9617 - val_loss: 0.3834 - val_acc: 0.8458 - lr: 2.1870e-07\n",
            "Epoch 23/60\n",
            "132/132 [==============================] - 85s 644ms/step - loss: 0.1200 - acc: 0.9622 - val_loss: 0.3762 - val_acc: 0.8544 - lr: 6.5610e-08\n",
            "Epoch 24/60\n",
            "132/132 [==============================] - 84s 630ms/step - loss: 0.1157 - acc: 0.9660 - val_loss: 0.3862 - val_acc: 0.8308 - lr: 6.5610e-08\n",
            "Epoch 25/60\n",
            "132/132 [==============================] - 85s 641ms/step - loss: 0.1173 - acc: 0.9634 - val_loss: 0.3560 - val_acc: 0.8587 - lr: 6.5610e-08\n",
            "Epoch 26/60\n",
            "132/132 [==============================] - 83s 630ms/step - loss: 0.1104 - acc: 0.9655 - val_loss: 0.3713 - val_acc: 0.8458 - lr: 6.5610e-08\n",
            "Epoch 27/60\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.1147 - acc: 0.9639\n",
            "Epoch 27: ReduceLROnPlateau reducing learning rate to 1.9683000829218145e-08.\n",
            "132/132 [==============================] - 83s 629ms/step - loss: 0.1147 - acc: 0.9639 - val_loss: 0.3733 - val_acc: 0.8522 - lr: 6.5610e-08\n",
            "Epoch 28/60\n",
            "132/132 [==============================] - 84s 631ms/step - loss: 0.1160 - acc: 0.9677 - val_loss: 0.3825 - val_acc: 0.8437 - lr: 1.9683e-08\n",
            "Epoch 29/60\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.1179 - acc: 0.9598\n",
            "Epoch 29: ReduceLROnPlateau reducing learning rate to 1e-08.\n",
            "132/132 [==============================] - 84s 633ms/step - loss: 0.1179 - acc: 0.9598 - val_loss: 0.3784 - val_acc: 0.8373 - lr: 1.9683e-08\n",
            "Epoch 30/60\n",
            "132/132 [==============================] - 84s 637ms/step - loss: 0.1185 - acc: 0.9624 - val_loss: 0.3823 - val_acc: 0.8522 - lr: 1.0000e-08\n",
            "Epoch 31/60\n",
            "132/132 [==============================] - 84s 635ms/step - loss: 0.1221 - acc: 0.9610 - val_loss: 0.3912 - val_acc: 0.8244 - lr: 1.0000e-08\n",
            "Epoch 32/60\n",
            "132/132 [==============================] - 84s 636ms/step - loss: 0.1163 - acc: 0.9639 - val_loss: 0.3792 - val_acc: 0.8480 - lr: 1.0000e-08\n",
            "Epoch 33/60\n",
            "132/132 [==============================] - 84s 634ms/step - loss: 0.1242 - acc: 0.9617 - val_loss: 0.3778 - val_acc: 0.8351 - lr: 1.0000e-08\n",
            "Epoch 34/60\n",
            "132/132 [==============================] - 84s 634ms/step - loss: 0.1242 - acc: 0.9648 - val_loss: 0.3825 - val_acc: 0.8287 - lr: 1.0000e-08\n",
            "Epoch 35/60\n",
            "132/132 [==============================] - 84s 634ms/step - loss: 0.1191 - acc: 0.9629 - val_loss: 0.3914 - val_acc: 0.8351 - lr: 1.0000e-08\n",
            "Epoch 36/60\n",
            "132/132 [==============================] - 84s 634ms/step - loss: 0.1162 - acc: 0.9662 - val_loss: 0.3800 - val_acc: 0.8373 - lr: 1.0000e-08\n",
            "Epoch 37/60\n",
            "132/132 [==============================] - 84s 634ms/step - loss: 0.1169 - acc: 0.9629 - val_loss: 0.3962 - val_acc: 0.8373 - lr: 1.0000e-08\n",
            "Epoch 38/60\n",
            "132/132 [==============================] - 84s 634ms/step - loss: 0.1209 - acc: 0.9615 - val_loss: 0.4083 - val_acc: 0.8180 - lr: 1.0000e-08\n"
          ]
        }
      ],
      "source": [
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience = 2, verbose=1,factor=0.3, min_lr=0.00000001)\n",
        "chkpt = ModelCheckpoint(filepath='best_model_effB3_6_vol2.hdf5', monitor='val_acc', save_best_only=True, save_weights_only=True)\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(patience=13, monitor='val_acc', restore_best_weights=True)\n",
        "\n",
        "history36 = model36.fit(train_gen, epochs=60, validation_data=valid_gen, callbacks=[learning_rate_reduction, chkpt, early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVv9RSdaWxM_"
      },
      "outputs": [],
      "source": [
        "model36.load_weights(\"best_model_effB3_6_vol2.hdf5\")\n",
        "preds = model36.predict(X_test)\n",
        "labelled_preds = one_hot_encoder.inverse_transform(preds)\n",
        "pred = pd.DataFrame(labelled_preds, columns =[\"class_id\"])\n",
        "df = pd.read_csv('submission3.csv')\n",
        "df ['class_id']= pred\n",
        "df.to_csv(\"final_submission70_vol2.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BorqZTDSHhR"
      },
      "source": [
        "37)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVQRH-D-7hjM"
      },
      "outputs": [],
      "source": [
        "base_model37 = tf.keras.applications.EfficientNetB3(include_top=False,\n",
        "                                     weights='imagenet',\n",
        "                                     input_shape=(224, 224, 3))\n",
        "x = base_model37.output\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = Dense(512, activation=None, kernel_regularizer = L1L2(l1=1e-5, l2=1e-3))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('swish')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "x = Dense(512, activation=None, kernel_regularizer = L1L2(l1=1e-5, l2=1e-3))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('swish')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "ouput1 = Dense(3, activation= 'softmax')(x)\n",
        "\n",
        "model37 = Model(inputs=base_model37.input, outputs=ouput1)\n",
        "\n",
        "model37.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', metrics=['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6TInFoRScQP",
        "outputId": "b32ee3a5-2f55-4797-ab65-ecdfe67b0877"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "132/132 [==============================] - 84s 512ms/step - loss: 1.6017 - acc: 0.7581 - val_loss: 1.0996 - val_acc: 0.7794 - lr: 0.0010\n",
            "Epoch 2/60\n",
            "132/132 [==============================] - 61s 464ms/step - loss: 0.7945 - acc: 0.8029 - val_loss: 0.5698 - val_acc: 0.8009 - lr: 0.0010\n",
            "Epoch 3/60\n",
            "132/132 [==============================] - 62s 467ms/step - loss: 0.4592 - acc: 0.8126 - val_loss: 0.5153 - val_acc: 0.7794 - lr: 0.0010\n",
            "Epoch 4/60\n",
            "132/132 [==============================] - 69s 518ms/step - loss: 0.3498 - acc: 0.8380 - val_loss: 0.3975 - val_acc: 0.7709 - lr: 0.0010\n",
            "Epoch 5/60\n",
            "132/132 [==============================] - 67s 506ms/step - loss: 0.3183 - acc: 0.8407 - val_loss: 0.3613 - val_acc: 0.8223 - lr: 0.0010\n",
            "Epoch 6/60\n",
            "132/132 [==============================] - 68s 510ms/step - loss: 0.2820 - acc: 0.8537 - val_loss: 0.3116 - val_acc: 0.8116 - lr: 0.0010\n",
            "Epoch 7/60\n",
            "132/132 [==============================] - 60s 453ms/step - loss: 0.2675 - acc: 0.8559 - val_loss: 0.3508 - val_acc: 0.8073 - lr: 0.0010\n",
            "Epoch 8/60\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.2713 - acc: 0.8644\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "132/132 [==============================] - 60s 453ms/step - loss: 0.2713 - acc: 0.8644 - val_loss: 0.3223 - val_acc: 0.7966 - lr: 0.0010\n",
            "Epoch 9/60\n",
            "132/132 [==============================] - 61s 460ms/step - loss: 0.1859 - acc: 0.9082 - val_loss: 0.3059 - val_acc: 0.8394 - lr: 3.0000e-04\n",
            "Epoch 10/60\n",
            "132/132 [==============================] - 61s 458ms/step - loss: 0.1434 - acc: 0.9303 - val_loss: 0.2854 - val_acc: 0.8287 - lr: 3.0000e-04\n",
            "Epoch 11/60\n",
            "132/132 [==============================] - 60s 449ms/step - loss: 0.1339 - acc: 0.9339 - val_loss: 0.3668 - val_acc: 0.8266 - lr: 3.0000e-04\n",
            "Epoch 12/60\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.1185 - acc: 0.9439\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "132/132 [==============================] - 60s 451ms/step - loss: 0.1185 - acc: 0.9439 - val_loss: 0.3646 - val_acc: 0.8394 - lr: 3.0000e-04\n",
            "Epoch 13/60\n",
            "132/132 [==============================] - 60s 449ms/step - loss: 0.0871 - acc: 0.9648 - val_loss: 0.3258 - val_acc: 0.8394 - lr: 9.0000e-05\n",
            "Epoch 14/60\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0669 - acc: 0.9719\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "132/132 [==============================] - 64s 486ms/step - loss: 0.0669 - acc: 0.9719 - val_loss: 0.3146 - val_acc: 0.8394 - lr: 9.0000e-05\n",
            "Epoch 15/60\n",
            "132/132 [==============================] - 69s 518ms/step - loss: 0.0565 - acc: 0.9781 - val_loss: 0.3212 - val_acc: 0.8651 - lr: 2.7000e-05\n",
            "Epoch 16/60\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0497 - acc: 0.9798\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
            "132/132 [==============================] - 69s 523ms/step - loss: 0.0497 - acc: 0.9798 - val_loss: 0.3381 - val_acc: 0.8544 - lr: 2.7000e-05\n",
            "Epoch 17/60\n",
            "132/132 [==============================] - 67s 507ms/step - loss: 0.0427 - acc: 0.9841 - val_loss: 0.3678 - val_acc: 0.8501 - lr: 8.1000e-06\n",
            "Epoch 18/60\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0478 - acc: 0.9791\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 2.429999949526973e-06.\n",
            "132/132 [==============================] - 68s 515ms/step - loss: 0.0478 - acc: 0.9791 - val_loss: 0.3550 - val_acc: 0.8501 - lr: 8.1000e-06\n",
            "Epoch 19/60\n",
            "132/132 [==============================] - 67s 507ms/step - loss: 0.0393 - acc: 0.9836 - val_loss: 0.3900 - val_acc: 0.8458 - lr: 2.4300e-06\n",
            "Epoch 20/60\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0453 - acc: 0.9795\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 7.289999985005124e-07.\n",
            "132/132 [==============================] - 61s 457ms/step - loss: 0.0453 - acc: 0.9795 - val_loss: 0.3764 - val_acc: 0.8608 - lr: 2.4300e-06\n",
            "Epoch 21/60\n",
            "132/132 [==============================] - 60s 450ms/step - loss: 0.0403 - acc: 0.9867 - val_loss: 0.3938 - val_acc: 0.8330 - lr: 7.2900e-07\n",
            "Epoch 22/60\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0432 - acc: 0.9824\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 2.1870000637136398e-07.\n",
            "132/132 [==============================] - 60s 451ms/step - loss: 0.0432 - acc: 0.9824 - val_loss: 0.4122 - val_acc: 0.8415 - lr: 7.2900e-07\n",
            "Epoch 23/60\n",
            "132/132 [==============================] - 60s 450ms/step - loss: 0.0392 - acc: 0.9862 - val_loss: 0.3613 - val_acc: 0.8501 - lr: 2.1870e-07\n"
          ]
        }
      ],
      "source": [
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', patience = 2, verbose=1,factor=0.3, min_lr=0.00000001)\n",
        "chkpt = ModelCheckpoint(filepath='best_model_effB3_7.hdf5', monitor='val_loss', save_best_only=True, save_weights_only=True)\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(patience=13, monitor='val_loss', restore_best_weights=True)\n",
        "\n",
        "history37 = model37.fit(train_gen, epochs=60, validation_data=valid_gen, callbacks=[learning_rate_reduction, chkpt, early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8miwyWuTBjP"
      },
      "outputs": [],
      "source": [
        "model37.load_weights(\"best_model_effB3_7.hdf5\")\n",
        "preds = model37.predict(X_test)\n",
        "labelled_preds = one_hot_encoder.inverse_transform(preds)\n",
        "pred = pd.DataFrame(labelled_preds, columns =[\"class_id\"])\n",
        "df = pd.read_csv('submission3.csv')\n",
        "df ['class_id']= pred\n",
        "df.to_csv(\"final_submission71.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvIgHdL5XA3Z",
        "outputId": "e640202a-24a9-4184-e575-3c3883f4911b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "132/132 [==============================] - 101s 660ms/step - loss: 1.6541 - acc: 0.7501 - val_loss: 1.2589 - val_acc: 0.7923 - lr: 0.0010\n",
            "Epoch 2/60\n",
            "132/132 [==============================] - 84s 631ms/step - loss: 0.8735 - acc: 0.7993 - val_loss: 0.9295 - val_acc: 0.6338 - lr: 0.0010\n",
            "Epoch 3/60\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.4874 - acc: 0.8171\n",
            "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "132/132 [==============================] - 83s 629ms/step - loss: 0.4874 - acc: 0.8171 - val_loss: 0.5778 - val_acc: 0.7323 - lr: 0.0010\n",
            "Epoch 4/60\n",
            "132/132 [==============================] - 85s 639ms/step - loss: 0.3404 - acc: 0.8499 - val_loss: 0.3527 - val_acc: 0.8287 - lr: 3.0000e-04\n",
            "Epoch 5/60\n",
            "132/132 [==============================] - 83s 626ms/step - loss: 0.2771 - acc: 0.8768 - val_loss: 0.3548 - val_acc: 0.8223 - lr: 3.0000e-04\n",
            "Epoch 6/60\n",
            "132/132 [==============================] - 85s 643ms/step - loss: 0.2470 - acc: 0.8835 - val_loss: 0.3309 - val_acc: 0.8330 - lr: 3.0000e-04\n",
            "Epoch 7/60\n",
            "132/132 [==============================] - 83s 628ms/step - loss: 0.2086 - acc: 0.9030 - val_loss: 0.3382 - val_acc: 0.8137 - lr: 3.0000e-04\n",
            "Epoch 8/60\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.1972 - acc: 0.9084\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "132/132 [==============================] - 83s 628ms/step - loss: 0.1972 - acc: 0.9084 - val_loss: 0.3365 - val_acc: 0.8030 - lr: 3.0000e-04\n",
            "Epoch 9/60\n",
            "132/132 [==============================] - 83s 628ms/step - loss: 0.1452 - acc: 0.9365 - val_loss: 0.3163 - val_acc: 0.8201 - lr: 9.0000e-05\n",
            "Epoch 10/60\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.1089 - acc: 0.9579\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "132/132 [==============================] - 83s 629ms/step - loss: 0.1089 - acc: 0.9579 - val_loss: 0.3428 - val_acc: 0.8223 - lr: 9.0000e-05\n",
            "Epoch 11/60\n",
            "132/132 [==============================] - 83s 628ms/step - loss: 0.0968 - acc: 0.9605 - val_loss: 0.3536 - val_acc: 0.8137 - lr: 2.7000e-05\n",
            "Epoch 12/60\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0845 - acc: 0.9684\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
            "132/132 [==============================] - 83s 625ms/step - loss: 0.0845 - acc: 0.9684 - val_loss: 0.3615 - val_acc: 0.8287 - lr: 2.7000e-05\n",
            "Epoch 13/60\n",
            "132/132 [==============================] - 83s 629ms/step - loss: 0.0799 - acc: 0.9686 - val_loss: 0.3934 - val_acc: 0.8223 - lr: 8.1000e-06\n",
            "Epoch 14/60\n",
            "132/132 [==============================] - 85s 638ms/step - loss: 0.0745 - acc: 0.9703 - val_loss: 0.3558 - val_acc: 0.8394 - lr: 8.1000e-06\n",
            "Epoch 15/60\n",
            "132/132 [==============================] - 83s 628ms/step - loss: 0.0697 - acc: 0.9755 - val_loss: 0.4067 - val_acc: 0.8223 - lr: 8.1000e-06\n",
            "Epoch 16/60\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0738 - acc: 0.9710\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 2.429999949526973e-06.\n",
            "132/132 [==============================] - 83s 628ms/step - loss: 0.0738 - acc: 0.9710 - val_loss: 0.3819 - val_acc: 0.8180 - lr: 8.1000e-06\n",
            "Epoch 17/60\n",
            "132/132 [==============================] - 84s 630ms/step - loss: 0.0674 - acc: 0.9748 - val_loss: 0.4081 - val_acc: 0.8223 - lr: 2.4300e-06\n",
            "Epoch 18/60\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0698 - acc: 0.9736\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 7.289999985005124e-07.\n",
            "132/132 [==============================] - 83s 628ms/step - loss: 0.0698 - acc: 0.9736 - val_loss: 0.4171 - val_acc: 0.8330 - lr: 2.4300e-06\n",
            "Epoch 19/60\n",
            "132/132 [==============================] - 83s 628ms/step - loss: 0.0712 - acc: 0.9719 - val_loss: 0.3922 - val_acc: 0.8223 - lr: 7.2900e-07\n",
            "Epoch 20/60\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0682 - acc: 0.9736\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 2.1870000637136398e-07.\n",
            "132/132 [==============================] - 83s 624ms/step - loss: 0.0682 - acc: 0.9736 - val_loss: 0.4065 - val_acc: 0.8287 - lr: 7.2900e-07\n",
            "Epoch 21/60\n",
            "132/132 [==============================] - 83s 627ms/step - loss: 0.0656 - acc: 0.9762 - val_loss: 0.4046 - val_acc: 0.8201 - lr: 2.1870e-07\n",
            "Epoch 22/60\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0688 - acc: 0.9731\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 6.561000276406048e-08.\n",
            "132/132 [==============================] - 83s 629ms/step - loss: 0.0688 - acc: 0.9731 - val_loss: 0.3874 - val_acc: 0.8223 - lr: 2.1870e-07\n",
            "Epoch 23/60\n",
            "132/132 [==============================] - 84s 631ms/step - loss: 0.0668 - acc: 0.9738 - val_loss: 0.4016 - val_acc: 0.8201 - lr: 6.5610e-08\n",
            "Epoch 24/60\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0657 - acc: 0.9753\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 1.9683000829218145e-08.\n",
            "132/132 [==============================] - 83s 629ms/step - loss: 0.0657 - acc: 0.9753 - val_loss: 0.3853 - val_acc: 0.8394 - lr: 6.5610e-08\n",
            "Epoch 25/60\n",
            "132/132 [==============================] - 83s 628ms/step - loss: 0.0626 - acc: 0.9769 - val_loss: 0.3830 - val_acc: 0.8137 - lr: 1.9683e-08\n",
            "Epoch 26/60\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0646 - acc: 0.9772\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 1e-08.\n",
            "132/132 [==============================] - 83s 629ms/step - loss: 0.0646 - acc: 0.9772 - val_loss: 0.4042 - val_acc: 0.8266 - lr: 1.9683e-08\n",
            "Epoch 27/60\n",
            "132/132 [==============================] - 83s 630ms/step - loss: 0.0676 - acc: 0.9753 - val_loss: 0.3933 - val_acc: 0.8223 - lr: 1.0000e-08\n"
          ]
        }
      ],
      "source": [
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience = 2, verbose=1,factor=0.3, min_lr=0.00000001)\n",
        "chkpt = ModelCheckpoint(filepath='best_model_effB3_7_vol2.hdf5', monitor='val_acc', save_best_only=True, save_weights_only=True)\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(patience=13, monitor='val_acc', restore_best_weights=True)\n",
        "\n",
        "history37 = model37.fit(train_gen, epochs=60, validation_data=valid_gen, callbacks=[learning_rate_reduction, chkpt, early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vr9uB5cjXA65"
      },
      "outputs": [],
      "source": [
        "model37.load_weights(\"best_model_effB3_7_vol2.hdf5\")\n",
        "preds = model37.predict(X_test)\n",
        "labelled_preds = one_hot_encoder.inverse_transform(preds)\n",
        "pred = pd.DataFrame(labelled_preds, columns =[\"class_id\"])\n",
        "df = pd.read_csv('submission3.csv')\n",
        "df ['class_id']= pred\n",
        "df.to_csv(\"final_submission71_vol2.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upwaNl0sTKfO"
      },
      "source": [
        "38)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-o-0y62TKLX"
      },
      "outputs": [],
      "source": [
        "base_model38 = tf.keras.applications.EfficientNetB3(include_top=False,\n",
        "                                     weights='imagenet',\n",
        "                                     input_shape=(224, 224, 3))\n",
        "x = base_model38.output\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = Dense(256, activation=None, kernel_regularizer = L1L2(l1=1e-5, l2=1e-3))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('swish')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(256, activation=None, kernel_regularizer = L1L2(l1=1e-5, l2=1e-3))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('swish')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "ouput1 = Dense(3, activation= 'softmax')(x)\n",
        "\n",
        "model38 = Model(inputs=base_model38.input, outputs=ouput1)\n",
        "\n",
        "model38.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', metrics=['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u05eA4q6US3z",
        "outputId": "4a35ea7b-50d5-4885-dc9f-922dbeb79010"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/80\n",
            "132/132 [==============================] - 76s 472ms/step - loss: 1.1023 - acc: 0.7512 - val_loss: 1.0913 - val_acc: 0.6488 - lr: 0.0010\n",
            "Epoch 2/80\n",
            "132/132 [==============================] - 60s 455ms/step - loss: 0.7122 - acc: 0.8062 - val_loss: 0.6104 - val_acc: 0.7837 - lr: 0.0010\n",
            "Epoch 3/80\n",
            "132/132 [==============================] - 59s 446ms/step - loss: 0.4743 - acc: 0.8254 - val_loss: 0.6584 - val_acc: 0.6403 - lr: 0.0010\n",
            "Epoch 4/80\n",
            "132/132 [==============================] - 60s 456ms/step - loss: 0.3759 - acc: 0.8266 - val_loss: 0.4159 - val_acc: 0.7837 - lr: 0.0010\n",
            "Epoch 5/80\n",
            "132/132 [==============================] - 61s 457ms/step - loss: 0.3312 - acc: 0.8350 - val_loss: 0.3529 - val_acc: 0.7837 - lr: 0.0010\n",
            "Epoch 6/80\n",
            "132/132 [==============================] - 61s 457ms/step - loss: 0.2900 - acc: 0.8385 - val_loss: 0.3382 - val_acc: 0.8009 - lr: 0.0010\n",
            "Epoch 7/80\n",
            "132/132 [==============================] - 61s 457ms/step - loss: 0.2752 - acc: 0.8535 - val_loss: 0.3241 - val_acc: 0.8223 - lr: 0.0010\n",
            "Epoch 8/80\n",
            "132/132 [==============================] - 59s 447ms/step - loss: 0.2539 - acc: 0.8671 - val_loss: 0.3720 - val_acc: 0.8180 - lr: 0.0010\n",
            "Epoch 9/80\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.2286 - acc: 0.8823\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "132/132 [==============================] - 59s 447ms/step - loss: 0.2286 - acc: 0.8823 - val_loss: 0.4902 - val_acc: 0.7666 - lr: 0.0010\n",
            "Epoch 10/80\n",
            "132/132 [==============================] - 61s 457ms/step - loss: 0.1817 - acc: 0.9118 - val_loss: 0.2931 - val_acc: 0.7880 - lr: 3.0000e-04\n",
            "Epoch 11/80\n",
            "132/132 [==============================] - 59s 446ms/step - loss: 0.1316 - acc: 0.9379 - val_loss: 0.3079 - val_acc: 0.8437 - lr: 3.0000e-04\n",
            "Epoch 12/80\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.1127 - acc: 0.9460\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "132/132 [==============================] - 59s 448ms/step - loss: 0.1127 - acc: 0.9460 - val_loss: 0.3787 - val_acc: 0.8073 - lr: 3.0000e-04\n",
            "Epoch 13/80\n",
            "132/132 [==============================] - 59s 447ms/step - loss: 0.0988 - acc: 0.9584 - val_loss: 0.3261 - val_acc: 0.8287 - lr: 9.0000e-05\n",
            "Epoch 14/80\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0829 - acc: 0.9622\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "132/132 [==============================] - 59s 447ms/step - loss: 0.0829 - acc: 0.9622 - val_loss: 0.3111 - val_acc: 0.8522 - lr: 9.0000e-05\n",
            "Epoch 15/80\n",
            "132/132 [==============================] - 59s 447ms/step - loss: 0.0676 - acc: 0.9731 - val_loss: 0.3203 - val_acc: 0.8308 - lr: 2.7000e-05\n",
            "Epoch 16/80\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0626 - acc: 0.9767\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
            "132/132 [==============================] - 59s 447ms/step - loss: 0.0626 - acc: 0.9767 - val_loss: 0.3374 - val_acc: 0.8287 - lr: 2.7000e-05\n",
            "Epoch 17/80\n",
            "132/132 [==============================] - 59s 447ms/step - loss: 0.0608 - acc: 0.9748 - val_loss: 0.3487 - val_acc: 0.8351 - lr: 8.1000e-06\n",
            "Epoch 18/80\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0574 - acc: 0.9753\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 2.429999949526973e-06.\n",
            "132/132 [==============================] - 59s 447ms/step - loss: 0.0574 - acc: 0.9753 - val_loss: 0.3579 - val_acc: 0.8308 - lr: 8.1000e-06\n",
            "Epoch 19/80\n",
            "132/132 [==============================] - 59s 448ms/step - loss: 0.0570 - acc: 0.9767 - val_loss: 0.3412 - val_acc: 0.8308 - lr: 2.4300e-06\n",
            "Epoch 20/80\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0547 - acc: 0.9795\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 7.289999985005124e-07.\n",
            "132/132 [==============================] - 59s 446ms/step - loss: 0.0547 - acc: 0.9795 - val_loss: 0.3447 - val_acc: 0.8415 - lr: 2.4300e-06\n",
            "Epoch 21/80\n",
            "132/132 [==============================] - 59s 446ms/step - loss: 0.0536 - acc: 0.9793 - val_loss: 0.3319 - val_acc: 0.8480 - lr: 7.2900e-07\n",
            "Epoch 22/80\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0532 - acc: 0.9805\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 2.1870000637136398e-07.\n",
            "132/132 [==============================] - 59s 447ms/step - loss: 0.0532 - acc: 0.9805 - val_loss: 0.3764 - val_acc: 0.8244 - lr: 7.2900e-07\n",
            "Epoch 23/80\n",
            "132/132 [==============================] - 59s 449ms/step - loss: 0.0575 - acc: 0.9774 - val_loss: 0.3846 - val_acc: 0.8458 - lr: 2.1870e-07\n"
          ]
        }
      ],
      "source": [
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', patience = 2, verbose=1,factor=0.3, min_lr=0.00000001)\n",
        "chkpt = ModelCheckpoint(filepath='best_model_effB3_8.hdf5', monitor='val_loss', save_best_only=True, save_weights_only=True)\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(patience=13, monitor='val_loss', restore_best_weights=True)\n",
        "\n",
        "history38 = model38.fit(train_gen, epochs=80, validation_data=valid_gen, callbacks=[learning_rate_reduction, chkpt, early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HLE2B3w6UVrv"
      },
      "outputs": [],
      "source": [
        "model38.load_weights(\"best_model_effB3_8.hdf5\")\n",
        "preds = model38.predict(X_test)\n",
        "labelled_preds = one_hot_encoder.inverse_transform(preds)\n",
        "pred = pd.DataFrame(labelled_preds, columns =[\"class_id\"])\n",
        "df = pd.read_csv('submission3.csv')\n",
        "df ['class_id']= pred\n",
        "df.to_csv(\"final_submission72.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsWE-EBhXQBM",
        "outputId": "1448279d-5d59-4c81-8644-dffd885ad152"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/80\n",
            "132/132 [==============================] - 100s 655ms/step - loss: 1.1049 - acc: 0.7441 - val_loss: 1.0144 - val_acc: 0.7131 - lr: 0.0010\n",
            "Epoch 2/80\n",
            "132/132 [==============================] - 85s 641ms/step - loss: 0.7147 - acc: 0.7988 - val_loss: 0.5825 - val_acc: 0.7901 - lr: 0.0010\n",
            "Epoch 3/80\n",
            "132/132 [==============================] - 83s 628ms/step - loss: 0.4835 - acc: 0.8150 - val_loss: 0.5238 - val_acc: 0.7687 - lr: 0.0010\n",
            "Epoch 4/80\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.3768 - acc: 0.8361\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "132/132 [==============================] - 83s 629ms/step - loss: 0.3768 - acc: 0.8361 - val_loss: 0.4569 - val_acc: 0.7430 - lr: 0.0010\n",
            "Epoch 5/80\n",
            "132/132 [==============================] - 85s 644ms/step - loss: 0.2856 - acc: 0.8652 - val_loss: 0.3333 - val_acc: 0.8137 - lr: 3.0000e-04\n",
            "Epoch 6/80\n",
            "132/132 [==============================] - 83s 627ms/step - loss: 0.2441 - acc: 0.8882 - val_loss: 0.3120 - val_acc: 0.8116 - lr: 3.0000e-04\n",
            "Epoch 7/80\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.2164 - acc: 0.8982\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "132/132 [==============================] - 84s 631ms/step - loss: 0.2164 - acc: 0.8982 - val_loss: 0.3422 - val_acc: 0.8051 - lr: 3.0000e-04\n",
            "Epoch 8/80\n",
            "132/132 [==============================] - 85s 640ms/step - loss: 0.1684 - acc: 0.9329 - val_loss: 0.3490 - val_acc: 0.8287 - lr: 9.0000e-05\n",
            "Epoch 9/80\n",
            "132/132 [==============================] - 85s 639ms/step - loss: 0.1491 - acc: 0.9386 - val_loss: 0.3276 - val_acc: 0.8458 - lr: 9.0000e-05\n",
            "Epoch 10/80\n",
            "132/132 [==============================] - 83s 629ms/step - loss: 0.1227 - acc: 0.9558 - val_loss: 0.3485 - val_acc: 0.8308 - lr: 9.0000e-05\n",
            "Epoch 11/80\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.1160 - acc: 0.9558\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "132/132 [==============================] - 84s 631ms/step - loss: 0.1160 - acc: 0.9558 - val_loss: 0.3327 - val_acc: 0.8308 - lr: 9.0000e-05\n",
            "Epoch 12/80\n",
            "132/132 [==============================] - 83s 626ms/step - loss: 0.1016 - acc: 0.9658 - val_loss: 0.3722 - val_acc: 0.8308 - lr: 2.7000e-05\n",
            "Epoch 13/80\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0983 - acc: 0.9653\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
            "132/132 [==============================] - 83s 628ms/step - loss: 0.0983 - acc: 0.9653 - val_loss: 0.3598 - val_acc: 0.8351 - lr: 2.7000e-05\n",
            "Epoch 14/80\n",
            "132/132 [==============================] - 83s 627ms/step - loss: 0.0898 - acc: 0.9691 - val_loss: 0.3513 - val_acc: 0.8394 - lr: 8.1000e-06\n",
            "Epoch 15/80\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0837 - acc: 0.9736\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 2.429999949526973e-06.\n",
            "132/132 [==============================] - 83s 627ms/step - loss: 0.0837 - acc: 0.9736 - val_loss: 0.4020 - val_acc: 0.8287 - lr: 8.1000e-06\n",
            "Epoch 16/80\n",
            "132/132 [==============================] - 83s 628ms/step - loss: 0.0777 - acc: 0.9769 - val_loss: 0.3808 - val_acc: 0.8458 - lr: 2.4300e-06\n",
            "Epoch 17/80\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0813 - acc: 0.9743\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 7.289999985005124e-07.\n",
            "132/132 [==============================] - 84s 632ms/step - loss: 0.0813 - acc: 0.9743 - val_loss: 0.3895 - val_acc: 0.8394 - lr: 2.4300e-06\n",
            "Epoch 18/80\n",
            "132/132 [==============================] - 83s 626ms/step - loss: 0.0814 - acc: 0.9772 - val_loss: 0.3795 - val_acc: 0.8415 - lr: 7.2900e-07\n",
            "Epoch 19/80\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0838 - acc: 0.9719\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 2.1870000637136398e-07.\n",
            "132/132 [==============================] - 83s 630ms/step - loss: 0.0838 - acc: 0.9719 - val_loss: 0.3790 - val_acc: 0.8330 - lr: 7.2900e-07\n",
            "Epoch 20/80\n",
            "132/132 [==============================] - 85s 643ms/step - loss: 0.0838 - acc: 0.9748 - val_loss: 0.3615 - val_acc: 0.8608 - lr: 2.1870e-07\n",
            "Epoch 21/80\n",
            "132/132 [==============================] - 83s 627ms/step - loss: 0.0788 - acc: 0.9769 - val_loss: 0.3491 - val_acc: 0.8565 - lr: 2.1870e-07\n",
            "Epoch 22/80\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0804 - acc: 0.9753\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 6.561000276406048e-08.\n",
            "132/132 [==============================] - 84s 631ms/step - loss: 0.0804 - acc: 0.9753 - val_loss: 0.3926 - val_acc: 0.8330 - lr: 2.1870e-07\n",
            "Epoch 23/80\n",
            "132/132 [==============================] - 83s 629ms/step - loss: 0.0818 - acc: 0.9738 - val_loss: 0.3918 - val_acc: 0.8351 - lr: 6.5610e-08\n",
            "Epoch 24/80\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0816 - acc: 0.9750\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 1.9683000829218145e-08.\n",
            "132/132 [==============================] - 83s 629ms/step - loss: 0.0816 - acc: 0.9750 - val_loss: 0.3846 - val_acc: 0.8351 - lr: 6.5610e-08\n",
            "Epoch 25/80\n",
            "132/132 [==============================] - 83s 625ms/step - loss: 0.0805 - acc: 0.9767 - val_loss: 0.3637 - val_acc: 0.8458 - lr: 1.9683e-08\n",
            "Epoch 26/80\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0783 - acc: 0.9784\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 1e-08.\n",
            "132/132 [==============================] - 83s 629ms/step - loss: 0.0783 - acc: 0.9784 - val_loss: 0.3853 - val_acc: 0.8330 - lr: 1.9683e-08\n",
            "Epoch 27/80\n",
            "132/132 [==============================] - 83s 627ms/step - loss: 0.0783 - acc: 0.9765 - val_loss: 0.3668 - val_acc: 0.8330 - lr: 1.0000e-08\n",
            "Epoch 28/80\n",
            "132/132 [==============================] - 83s 625ms/step - loss: 0.0819 - acc: 0.9741 - val_loss: 0.3909 - val_acc: 0.8308 - lr: 1.0000e-08\n",
            "Epoch 29/80\n",
            "132/132 [==============================] - 83s 626ms/step - loss: 0.0827 - acc: 0.9748 - val_loss: 0.3733 - val_acc: 0.8394 - lr: 1.0000e-08\n",
            "Epoch 30/80\n",
            "132/132 [==============================] - 83s 630ms/step - loss: 0.0876 - acc: 0.9715 - val_loss: 0.3576 - val_acc: 0.8437 - lr: 1.0000e-08\n",
            "Epoch 31/80\n",
            "132/132 [==============================] - 83s 627ms/step - loss: 0.0814 - acc: 0.9762 - val_loss: 0.3510 - val_acc: 0.8522 - lr: 1.0000e-08\n",
            "Epoch 32/80\n",
            "132/132 [==============================] - 83s 628ms/step - loss: 0.0812 - acc: 0.9736 - val_loss: 0.3923 - val_acc: 0.8308 - lr: 1.0000e-08\n",
            "Epoch 33/80\n",
            "132/132 [==============================] - 83s 628ms/step - loss: 0.0807 - acc: 0.9769 - val_loss: 0.3813 - val_acc: 0.8308 - lr: 1.0000e-08\n"
          ]
        }
      ],
      "source": [
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience = 2, verbose=1,factor=0.3, min_lr=0.00000001)\n",
        "chkpt = ModelCheckpoint(filepath='best_model_effB3_8_vol2.hdf5', monitor='val_acc', save_best_only=True, save_weights_only=True)\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(patience=13, monitor='val_acc', restore_best_weights=True)\n",
        "\n",
        "history38 = model38.fit(train_gen, epochs=80, validation_data=valid_gen, callbacks=[learning_rate_reduction, chkpt, early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwjtFHMbXQE1"
      },
      "outputs": [],
      "source": [
        "model38.load_weights(\"best_model_effB3_8_vol2.hdf5\")\n",
        "preds = model38.predict(X_test)\n",
        "labelled_preds = one_hot_encoder.inverse_transform(preds)\n",
        "pred = pd.DataFrame(labelled_preds, columns =[\"class_id\"])\n",
        "df = pd.read_csv('submission3.csv')\n",
        "df ['class_id']= pred\n",
        "df.to_csv(\"final_submission72_vol2.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###EfficientNetV2B0\n"
      ],
      "metadata": {
        "id": "CypbrvSq1esj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model4 = tf.keras.applications.EfficientNetV2B0(include_top=False,\n",
        "                                     weights='imagenet',\n",
        "                                     input_shape=(224, 224, 3))\n",
        "x = base_model4.output\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = Dense(512, activation=None, kernel_regularizer = L1L2(l1=1e-5, l2=1e-3))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('swish')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(512, activation=None, kernel_regularizer = L1L2(l1=1e-5, l2=1e-3))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('swish')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "ouput1 = Dense(3, activation= 'softmax')(x)\n",
        "\n",
        "model4 = Model(inputs=base_model4.input, outputs=ouput1)\n",
        "\n",
        "model4.compile(loss='categorical_crossentropy', \n",
        "              optimizer=tf.keras.optimizers.Adam(1e-3, decay = 1e-3 * 0.1), metrics=['acc'])"
      ],
      "metadata": {
        "id": "oEsBuKl81liI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d319a916-3ea3-495e-988c-4a7f318e9eb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-b0_notop.h5\n",
            "24281088/24274472 [==============================] - 0s 0us/step\n",
            "24289280/24274472 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', patience = 2, verbose=1,factor=0.3, min_lr=0.00000001)\n",
        "chkpt = ModelCheckpoint(filepath='best_model_effV2B0.hdf5', monitor='val_loss', save_best_only=True, save_weights_only=True)\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(patience=13, monitor='val_loss', restore_best_weights=True)\n",
        "\n",
        "history4 = model4.fit(train_gen, epochs=25, validation_data=valid_gen, callbacks=[learning_rate_reduction, chkpt, early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVkLqqKb16Xg",
        "outputId": "ec8ef451-9e22-41e0-a3e1-04817d085a28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "132/132 [==============================] - 63s 403ms/step - loss: 2.0764 - acc: 0.7520 - val_loss: 1.7443 - val_acc: 0.8030 - lr: 0.0010\n",
            "Epoch 2/25\n",
            "132/132 [==============================] - 53s 400ms/step - loss: 1.5988 - acc: 0.8086 - val_loss: 1.5081 - val_acc: 0.7709 - lr: 0.0010\n",
            "Epoch 3/25\n",
            "132/132 [==============================] - 51s 385ms/step - loss: 1.2613 - acc: 0.8088 - val_loss: 1.1855 - val_acc: 0.7944 - lr: 0.0010\n",
            "Epoch 4/25\n",
            "132/132 [==============================] - 51s 387ms/step - loss: 0.9894 - acc: 0.8150 - val_loss: 0.9316 - val_acc: 0.7859 - lr: 0.0010\n",
            "Epoch 5/25\n",
            "132/132 [==============================] - 51s 386ms/step - loss: 0.7816 - acc: 0.8316 - val_loss: 0.7755 - val_acc: 0.8073 - lr: 0.0010\n",
            "Epoch 6/25\n",
            "132/132 [==============================] - 51s 389ms/step - loss: 0.6321 - acc: 0.8411 - val_loss: 0.6085 - val_acc: 0.8223 - lr: 0.0010\n",
            "Epoch 7/25\n",
            "132/132 [==============================] - 51s 387ms/step - loss: 0.5285 - acc: 0.8502 - val_loss: 0.5511 - val_acc: 0.8330 - lr: 0.0010\n",
            "Epoch 8/25\n",
            "132/132 [==============================] - 51s 387ms/step - loss: 0.4587 - acc: 0.8649 - val_loss: 0.5178 - val_acc: 0.8266 - lr: 0.0010\n",
            "Epoch 9/25\n",
            "132/132 [==============================] - 51s 388ms/step - loss: 0.4196 - acc: 0.8642 - val_loss: 0.4728 - val_acc: 0.8330 - lr: 0.0010\n",
            "Epoch 10/25\n",
            "132/132 [==============================] - 50s 379ms/step - loss: 0.3889 - acc: 0.8706 - val_loss: 0.5383 - val_acc: 0.8158 - lr: 0.0010\n",
            "Epoch 11/25\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.3594 - acc: 0.8856\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "132/132 [==============================] - 50s 378ms/step - loss: 0.3594 - acc: 0.8856 - val_loss: 0.5068 - val_acc: 0.8244 - lr: 0.0010\n",
            "Epoch 12/25\n",
            "132/132 [==============================] - 51s 385ms/step - loss: 0.2506 - acc: 0.9222 - val_loss: 0.3999 - val_acc: 0.8501 - lr: 3.0000e-04\n",
            "Epoch 13/25\n",
            "132/132 [==============================] - 50s 381ms/step - loss: 0.1985 - acc: 0.9439 - val_loss: 0.4313 - val_acc: 0.8437 - lr: 3.0000e-04\n",
            "Epoch 14/25\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.1719 - acc: 0.9515\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "132/132 [==============================] - 50s 378ms/step - loss: 0.1719 - acc: 0.9515 - val_loss: 0.4363 - val_acc: 0.8501 - lr: 3.0000e-04\n",
            "Epoch 15/25\n",
            "132/132 [==============================] - 50s 380ms/step - loss: 0.1247 - acc: 0.9669 - val_loss: 0.4927 - val_acc: 0.8544 - lr: 9.0000e-05\n",
            "Epoch 16/25\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.1065 - acc: 0.9741\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "132/132 [==============================] - 50s 380ms/step - loss: 0.1065 - acc: 0.9741 - val_loss: 0.5417 - val_acc: 0.8587 - lr: 9.0000e-05\n",
            "Epoch 17/25\n",
            "132/132 [==============================] - 50s 378ms/step - loss: 0.0944 - acc: 0.9800 - val_loss: 0.5067 - val_acc: 0.8758 - lr: 2.7000e-05\n",
            "Epoch 18/25\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0815 - acc: 0.9841\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
            "132/132 [==============================] - 50s 379ms/step - loss: 0.0815 - acc: 0.9841 - val_loss: 0.5391 - val_acc: 0.8651 - lr: 2.7000e-05\n",
            "Epoch 19/25\n",
            "132/132 [==============================] - 50s 381ms/step - loss: 0.0795 - acc: 0.9810 - val_loss: 0.5284 - val_acc: 0.8565 - lr: 8.1000e-06\n",
            "Epoch 20/25\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0817 - acc: 0.9817\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 2.429999949526973e-06.\n",
            "132/132 [==============================] - 53s 398ms/step - loss: 0.0817 - acc: 0.9817 - val_loss: 0.5536 - val_acc: 0.8608 - lr: 8.1000e-06\n",
            "Epoch 21/25\n",
            "132/132 [==============================] - 51s 385ms/step - loss: 0.0805 - acc: 0.9817 - val_loss: 0.5912 - val_acc: 0.8608 - lr: 2.4300e-06\n",
            "Epoch 22/25\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0810 - acc: 0.9822\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 7.289999985005124e-07.\n",
            "132/132 [==============================] - 55s 416ms/step - loss: 0.0810 - acc: 0.9822 - val_loss: 0.5275 - val_acc: 0.8608 - lr: 2.4300e-06\n",
            "Epoch 23/25\n",
            "132/132 [==============================] - 50s 379ms/step - loss: 0.0739 - acc: 0.9864 - val_loss: 0.6083 - val_acc: 0.8587 - lr: 7.2900e-07\n",
            "Epoch 24/25\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0749 - acc: 0.9838\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 2.1870000637136398e-07.\n",
            "132/132 [==============================] - 50s 380ms/step - loss: 0.0749 - acc: 0.9838 - val_loss: 0.5984 - val_acc: 0.8501 - lr: 7.2900e-07\n",
            "Epoch 25/25\n",
            "132/132 [==============================] - 50s 379ms/step - loss: 0.0770 - acc: 0.9857 - val_loss: 0.5952 - val_acc: 0.8672 - lr: 2.1870e-07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model4.load_weights(\"best_model_effV2B0.hdf5\")\n",
        "preds = model4.predict(X_test)\n",
        "labelled_preds = one_hot_encoder.inverse_transform(preds)\n",
        "pred = pd.DataFrame(labelled_preds, columns =[\"class_id\"])\n",
        "df = pd.read_csv('submission3.csv')\n",
        "df ['class_id']= pred\n",
        "df.to_csv(\"final_submission55.csv\", index=False)"
      ],
      "metadata": {
        "id": "xgnYuDMM2Ddz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###EfficientNetV2B1"
      ],
      "metadata": {
        "id": "vP1yh4MKI8wl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model5 = tf.keras.applications.EfficientNetV2B1(include_top=False,\n",
        "                                     weights='imagenet',\n",
        "                                     input_shape=(224, 224, 3))\n",
        "x = base_model5.output\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = Dense(512, activation=None, kernel_regularizer = L1L2(l1=1e-5, l2=1e-3))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('swish')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(512, activation=None, kernel_regularizer = L1L2(l1=1e-5, l2=1e-3))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('swish')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "ouput1 = Dense(3, activation= 'softmax')(x)\n",
        "\n",
        "model5 = Model(inputs=base_model5.input, outputs=ouput1)\n",
        "\n",
        "model5.compile(loss='categorical_crossentropy', \n",
        "              optimizer=tf.keras.optimizers.Adam(1e-3, decay = 1e-3 * 0.1), metrics=['acc'])"
      ],
      "metadata": {
        "id": "sEOZB1FpJDsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', patience = 2, verbose=1,factor=0.3, min_lr=0.00000001)\n",
        "chkpt = ModelCheckpoint(filepath='best_model_effV2B1.hdf5', monitor='val_loss', save_best_only=True, save_weights_only=True)\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(patience=13, monitor='val_loss', restore_best_weights=True)\n",
        "\n",
        "history5 = model5.fit(train_gen, epochs=25, validation_data=valid_gen, callbacks=[learning_rate_reduction, chkpt, early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5qNt-DLJPqH",
        "outputId": "906ff868-836c-42fc-c006-74f94e4cfc34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "132/132 [==============================] - 69s 430ms/step - loss: 2.0388 - acc: 0.7536 - val_loss: 1.7417 - val_acc: 0.7859 - lr: 0.0010\n",
            "Epoch 2/25\n",
            "132/132 [==============================] - 54s 408ms/step - loss: 1.5591 - acc: 0.7950 - val_loss: 1.3031 - val_acc: 0.8351 - lr: 0.0010\n",
            "Epoch 3/25\n",
            "132/132 [==============================] - 54s 405ms/step - loss: 1.1790 - acc: 0.8174 - val_loss: 1.0184 - val_acc: 0.8308 - lr: 0.0010\n",
            "Epoch 4/25\n",
            "132/132 [==============================] - 54s 405ms/step - loss: 0.9325 - acc: 0.8183 - val_loss: 0.8075 - val_acc: 0.8351 - lr: 0.0010\n",
            "Epoch 5/25\n",
            "132/132 [==============================] - 53s 403ms/step - loss: 0.7205 - acc: 0.8347 - val_loss: 0.7073 - val_acc: 0.8094 - lr: 0.0010\n",
            "Epoch 6/25\n",
            "132/132 [==============================] - 53s 399ms/step - loss: 0.5782 - acc: 0.8514 - val_loss: 0.7917 - val_acc: 0.7580 - lr: 0.0010\n",
            "Epoch 7/25\n",
            "132/132 [==============================] - 54s 405ms/step - loss: 0.4961 - acc: 0.8606 - val_loss: 0.4996 - val_acc: 0.8522 - lr: 0.0010\n",
            "Epoch 8/25\n",
            "132/132 [==============================] - 53s 400ms/step - loss: 0.4298 - acc: 0.8690 - val_loss: 0.5554 - val_acc: 0.7880 - lr: 0.0010\n",
            "Epoch 9/25\n",
            "132/132 [==============================] - 54s 406ms/step - loss: 0.4138 - acc: 0.8640 - val_loss: 0.4422 - val_acc: 0.8608 - lr: 0.0010\n",
            "Epoch 10/25\n",
            "132/132 [==============================] - 53s 397ms/step - loss: 0.3584 - acc: 0.8897 - val_loss: 0.4684 - val_acc: 0.8287 - lr: 0.0010\n",
            "Epoch 11/25\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.3474 - acc: 0.8882\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "132/132 [==============================] - 53s 400ms/step - loss: 0.3474 - acc: 0.8882 - val_loss: 0.4916 - val_acc: 0.8330 - lr: 0.0010\n",
            "Epoch 12/25\n",
            "132/132 [==============================] - 53s 400ms/step - loss: 0.2317 - acc: 0.9334 - val_loss: 0.4497 - val_acc: 0.8501 - lr: 3.0000e-04\n",
            "Epoch 13/25\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.1725 - acc: 0.9536\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "132/132 [==============================] - 53s 401ms/step - loss: 0.1725 - acc: 0.9536 - val_loss: 0.4527 - val_acc: 0.8587 - lr: 3.0000e-04\n",
            "Epoch 14/25\n",
            "132/132 [==============================] - 53s 401ms/step - loss: 0.1235 - acc: 0.9705 - val_loss: 0.4704 - val_acc: 0.8565 - lr: 9.0000e-05\n",
            "Epoch 15/25\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.1093 - acc: 0.9715\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "132/132 [==============================] - 53s 397ms/step - loss: 0.1093 - acc: 0.9715 - val_loss: 0.4920 - val_acc: 0.8608 - lr: 9.0000e-05\n",
            "Epoch 16/25\n",
            "132/132 [==============================] - 53s 397ms/step - loss: 0.1009 - acc: 0.9765 - val_loss: 0.5760 - val_acc: 0.8480 - lr: 2.7000e-05\n",
            "Epoch 17/25\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0844 - acc: 0.9824\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
            "132/132 [==============================] - 53s 398ms/step - loss: 0.0844 - acc: 0.9824 - val_loss: 0.5140 - val_acc: 0.8715 - lr: 2.7000e-05\n",
            "Epoch 18/25\n",
            "132/132 [==============================] - 53s 397ms/step - loss: 0.0758 - acc: 0.9845 - val_loss: 0.5904 - val_acc: 0.8801 - lr: 8.1000e-06\n",
            "Epoch 19/25\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0770 - acc: 0.9864\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 2.429999949526973e-06.\n",
            "132/132 [==============================] - 53s 398ms/step - loss: 0.0770 - acc: 0.9864 - val_loss: 0.6133 - val_acc: 0.8608 - lr: 8.1000e-06\n",
            "Epoch 20/25\n",
            "132/132 [==============================] - 53s 399ms/step - loss: 0.0747 - acc: 0.9862 - val_loss: 0.6029 - val_acc: 0.8630 - lr: 2.4300e-06\n",
            "Epoch 21/25\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0767 - acc: 0.9857\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 7.289999985005124e-07.\n",
            "132/132 [==============================] - 53s 401ms/step - loss: 0.0767 - acc: 0.9857 - val_loss: 0.6087 - val_acc: 0.8544 - lr: 2.4300e-06\n",
            "Epoch 22/25\n",
            "132/132 [==============================] - 53s 400ms/step - loss: 0.0876 - acc: 0.9800 - val_loss: 0.5387 - val_acc: 0.8565 - lr: 7.2900e-07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model5.load_weights(\"best_model_effV2B1.hdf5\")\n",
        "preds = model5.predict(X_test)\n",
        "labelled_preds = one_hot_encoder.inverse_transform(preds)\n",
        "pred = pd.DataFrame(labelled_preds, columns =[\"class_id\"])\n",
        "df = pd.read_csv('submission3.csv')\n",
        "df ['class_id']= pred\n",
        "df.to_csv(\"final_submission41.csv\", index=False)"
      ],
      "metadata": {
        "id": "RHs5d14BJcx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###EfficientNetV2B2 -> Removed on Final Results"
      ],
      "metadata": {
        "id": "rKWKCHYvJx6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model6 = tf.keras.applications.EfficientNetV2B2(include_top=False,\n",
        "                                     weights='imagenet',\n",
        "                                     input_shape=(224, 224, 3))\n",
        "x = base_model6.output\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = Dense(512, activation=None, kernel_regularizer = L1L2(l1=1e-5, l2=1e-3))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('swish')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(512, activation=None, kernel_regularizer = L1L2(l1=1e-5, l2=1e-3))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('swish')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "ouput1 = Dense(3, activation= 'softmax')(x)\n",
        "\n",
        "model6 = Model(inputs=base_model6.input, outputs=ouput1)\n",
        "\n",
        "model6.compile(loss='categorical_crossentropy', \n",
        "              optimizer=tf.keras.optimizers.Adam(1e-3, decay = 1e-3 * 0.1), metrics=['acc'])"
      ],
      "metadata": {
        "id": "r9yrnH6GJ2v2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', patience = 2, verbose=1,factor=0.3, min_lr=0.00000001)\n",
        "chkpt = ModelCheckpoint(filepath='best_model_effV2B2.hdf5', monitor='val_loss', save_best_only=True, save_weights_only=True)\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(patience=13, monitor='val_loss', restore_best_weights=True)\n",
        "\n",
        "history6 = model6.fit(train_gen, epochs=26, validation_data=valid_gen, callbacks=[learning_rate_reduction, chkpt, early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUD6G-71Kvfh",
        "outputId": "92757384-3bf8-4ed4-fb57-0e007371856f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/26\n",
            "132/132 [==============================] - 68s 421ms/step - loss: 2.1432 - acc: 0.7375 - val_loss: 1.8277 - val_acc: 0.7901 - lr: 0.0010\n",
            "Epoch 2/26\n",
            "132/132 [==============================] - 55s 415ms/step - loss: 1.6833 - acc: 0.7788 - val_loss: 1.4623 - val_acc: 0.8051 - lr: 0.0010\n",
            "Epoch 3/26\n",
            "132/132 [==============================] - 55s 412ms/step - loss: 1.3108 - acc: 0.8010 - val_loss: 1.0951 - val_acc: 0.8223 - lr: 0.0010\n",
            "Epoch 4/26\n",
            "132/132 [==============================] - 54s 407ms/step - loss: 1.0322 - acc: 0.8090 - val_loss: 0.9331 - val_acc: 0.8009 - lr: 0.0010\n",
            "Epoch 5/26\n",
            "132/132 [==============================] - 54s 408ms/step - loss: 0.8992 - acc: 0.7931 - val_loss: 0.8836 - val_acc: 0.7987 - lr: 0.0010\n",
            "Epoch 6/26\n",
            "132/132 [==============================] - 53s 402ms/step - loss: 0.8437 - acc: 0.7717 - val_loss: 2.8764 - val_acc: 0.6831 - lr: 0.0010\n",
            "Epoch 7/26\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.7614 - acc: 0.7636\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "132/132 [==============================] - 53s 396ms/step - loss: 0.7614 - acc: 0.7636 - val_loss: 9.9570 - val_acc: 0.4540 - lr: 0.0010\n",
            "Epoch 8/26\n",
            "132/132 [==============================] - 54s 407ms/step - loss: 0.6905 - acc: 0.7822 - val_loss: 0.6279 - val_acc: 0.8201 - lr: 3.0000e-04\n",
            "Epoch 9/26\n",
            "132/132 [==============================] - 55s 411ms/step - loss: 0.6096 - acc: 0.8062 - val_loss: 0.5523 - val_acc: 0.8266 - lr: 3.0000e-04\n",
            "Epoch 10/26\n",
            "132/132 [==============================] - 54s 407ms/step - loss: 0.5485 - acc: 0.8190 - val_loss: 0.5129 - val_acc: 0.8351 - lr: 3.0000e-04\n",
            "Epoch 11/26\n",
            "132/132 [==============================] - 54s 410ms/step - loss: 0.5293 - acc: 0.8273 - val_loss: 0.5070 - val_acc: 0.8094 - lr: 3.0000e-04\n",
            "Epoch 12/26\n",
            "132/132 [==============================] - 53s 401ms/step - loss: 0.4990 - acc: 0.8345 - val_loss: 0.5181 - val_acc: 0.8308 - lr: 3.0000e-04\n",
            "Epoch 13/26\n",
            "132/132 [==============================] - 54s 408ms/step - loss: 0.4697 - acc: 0.8430 - val_loss: 0.4989 - val_acc: 0.8287 - lr: 3.0000e-04\n",
            "Epoch 14/26\n",
            "132/132 [==============================] - 54s 410ms/step - loss: 0.4377 - acc: 0.8552 - val_loss: 0.4767 - val_acc: 0.8351 - lr: 3.0000e-04\n",
            "Epoch 15/26\n",
            "132/132 [==============================] - 53s 400ms/step - loss: 0.4337 - acc: 0.8509 - val_loss: 0.4779 - val_acc: 0.8458 - lr: 3.0000e-04\n",
            "Epoch 16/26\n",
            "132/132 [==============================] - 54s 410ms/step - loss: 0.4052 - acc: 0.8578 - val_loss: 0.4562 - val_acc: 0.8308 - lr: 3.0000e-04\n",
            "Epoch 17/26\n",
            "132/132 [==============================] - 54s 406ms/step - loss: 0.3897 - acc: 0.8668 - val_loss: 0.4465 - val_acc: 0.8394 - lr: 3.0000e-04\n",
            "Epoch 18/26\n",
            "132/132 [==============================] - 53s 399ms/step - loss: 0.3622 - acc: 0.8702 - val_loss: 0.4613 - val_acc: 0.8244 - lr: 3.0000e-04\n",
            "Epoch 19/26\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.3449 - acc: 0.8801\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "132/132 [==============================] - 53s 399ms/step - loss: 0.3449 - acc: 0.8801 - val_loss: 0.5434 - val_acc: 0.8351 - lr: 3.0000e-04\n",
            "Epoch 20/26\n",
            "132/132 [==============================] - 54s 409ms/step - loss: 0.2961 - acc: 0.8994 - val_loss: 0.4231 - val_acc: 0.8501 - lr: 9.0000e-05\n",
            "Epoch 21/26\n",
            "132/132 [==============================] - 53s 398ms/step - loss: 0.2416 - acc: 0.9268 - val_loss: 0.4663 - val_acc: 0.8544 - lr: 9.0000e-05\n",
            "Epoch 22/26\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.2479 - acc: 0.9201\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "132/132 [==============================] - 53s 400ms/step - loss: 0.2479 - acc: 0.9201 - val_loss: 0.4492 - val_acc: 0.8458 - lr: 9.0000e-05\n",
            "Epoch 23/26\n",
            "132/132 [==============================] - 53s 399ms/step - loss: 0.2032 - acc: 0.9382 - val_loss: 0.4322 - val_acc: 0.8630 - lr: 2.7000e-05\n",
            "Epoch 24/26\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.2066 - acc: 0.9377\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
            "132/132 [==============================] - 53s 399ms/step - loss: 0.2066 - acc: 0.9377 - val_loss: 0.4555 - val_acc: 0.8480 - lr: 2.7000e-05\n",
            "Epoch 25/26\n",
            "132/132 [==============================] - 53s 398ms/step - loss: 0.1984 - acc: 0.9358 - val_loss: 0.5021 - val_acc: 0.8437 - lr: 8.1000e-06\n",
            "Epoch 26/26\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.2011 - acc: 0.9382\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 2.429999949526973e-06.\n",
            "132/132 [==============================] - 53s 398ms/step - loss: 0.2011 - acc: 0.9382 - val_loss: 0.4776 - val_acc: 0.8672 - lr: 8.1000e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model6.load_weights(\"best_model_effV2B2.hdf5\")\n",
        "preds = model6.predict(X_test)\n",
        "labelled_preds = one_hot_encoder.inverse_transform(preds)\n",
        "pred = pd.DataFrame(labelled_preds, columns =[\"class_id\"])\n",
        "df = pd.read_csv('submission3.csv')\n",
        "df ['class_id']= pred\n",
        "df.to_csv(\"final_submission42.csv\", index=False)"
      ],
      "metadata": {
        "id": "dT2mSZy4K1oI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###EfficientNetV2B3"
      ],
      "metadata": {
        "id": "jqwUHGq0LC35"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model7 = tf.keras.applications.EfficientNetV2B3(include_top=False,\n",
        "                                     weights='imagenet',\n",
        "                                     input_shape=(224, 224, 3))\n",
        "x = base_model7.output\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = Dense(512, activation=None, kernel_regularizer = L1L2(l1=1e-5, l2=1e-3))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('swish')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(512, activation=None, kernel_regularizer = L1L2(l1=1e-5, l2=1e-3))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('swish')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "ouput1 = Dense(3, activation= 'softmax')(x)\n",
        "\n",
        "model7 = Model(inputs=base_model7.input, outputs=ouput1)\n",
        "\n",
        "model7.compile(loss='categorical_crossentropy', \n",
        "              optimizer=tf.keras.optimizers.Adam(1e-3, decay = 1e-3 * 0.1), metrics=['acc'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCKwM8zNLIxK",
        "outputId": "76c3eb16-c381-4603-de98-ee1ae8af5d09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-b3_notop.h5\n",
            "52609024/52606240 [==============================] - 1s 0us/step\n",
            "52617216/52606240 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', patience = 2, verbose=1,factor=0.3, min_lr=0.00000001)\n",
        "chkpt = ModelCheckpoint(filepath='best_model_effV2B3.hdf5', monitor='val_loss', save_best_only=True, save_weights_only=True)\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(patience=13, monitor='val_loss', restore_best_weights=True)\n",
        "\n",
        "history7 = model7.fit(train_gen, epochs=26, validation_data=valid_gen, callbacks=[learning_rate_reduction, chkpt, early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9Edj18ILP8v",
        "outputId": "892a261f-7c71-43ea-ef52-b4d991f7e20b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/26\n",
            "132/132 [==============================] - 74s 446ms/step - loss: 2.1729 - acc: 0.7187 - val_loss: 1.8387 - val_acc: 0.7859 - lr: 0.0010\n",
            "Epoch 2/26\n",
            "132/132 [==============================] - 55s 413ms/step - loss: 1.6485 - acc: 0.7936 - val_loss: 1.4412 - val_acc: 0.8094 - lr: 0.0010\n",
            "Epoch 3/26\n",
            "132/132 [==============================] - 55s 417ms/step - loss: 1.2910 - acc: 0.8055 - val_loss: 1.0758 - val_acc: 0.8394 - lr: 0.0010\n",
            "Epoch 4/26\n",
            "132/132 [==============================] - 55s 417ms/step - loss: 0.9843 - acc: 0.8143 - val_loss: 0.9656 - val_acc: 0.7666 - lr: 0.0010\n",
            "Epoch 5/26\n",
            "132/132 [==============================] - 55s 416ms/step - loss: 0.8081 - acc: 0.8117 - val_loss: 0.6967 - val_acc: 0.8373 - lr: 0.0010\n",
            "Epoch 6/26\n",
            "132/132 [==============================] - 55s 414ms/step - loss: 0.6213 - acc: 0.8380 - val_loss: 0.5853 - val_acc: 0.8394 - lr: 0.0010\n",
            "Epoch 7/26\n",
            "132/132 [==============================] - 56s 419ms/step - loss: 0.5456 - acc: 0.8445 - val_loss: 0.5844 - val_acc: 0.8051 - lr: 0.0010\n",
            "Epoch 8/26\n",
            "132/132 [==============================] - 56s 418ms/step - loss: 0.4807 - acc: 0.8552 - val_loss: 0.5443 - val_acc: 0.8009 - lr: 0.0010\n",
            "Epoch 9/26\n",
            "132/132 [==============================] - 55s 416ms/step - loss: 0.4236 - acc: 0.8647 - val_loss: 0.5299 - val_acc: 0.8330 - lr: 0.0010\n",
            "Epoch 10/26\n",
            "132/132 [==============================] - 56s 421ms/step - loss: 0.3909 - acc: 0.8723 - val_loss: 0.4964 - val_acc: 0.8030 - lr: 0.0010\n",
            "Epoch 11/26\n",
            "132/132 [==============================] - 54s 405ms/step - loss: 0.3618 - acc: 0.8778 - val_loss: 0.5277 - val_acc: 0.8137 - lr: 0.0010\n",
            "Epoch 12/26\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.3426 - acc: 0.8866\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "132/132 [==============================] - 54s 405ms/step - loss: 0.3426 - acc: 0.8866 - val_loss: 0.5338 - val_acc: 0.7730 - lr: 0.0010\n",
            "Epoch 13/26\n",
            "132/132 [==============================] - 55s 416ms/step - loss: 0.2537 - acc: 0.9187 - val_loss: 0.4915 - val_acc: 0.8394 - lr: 3.0000e-04\n",
            "Epoch 14/26\n",
            "132/132 [==============================] - 54s 406ms/step - loss: 0.1881 - acc: 0.9486 - val_loss: 0.5116 - val_acc: 0.8351 - lr: 3.0000e-04\n",
            "Epoch 15/26\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.1535 - acc: 0.9579\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "132/132 [==============================] - 54s 404ms/step - loss: 0.1535 - acc: 0.9579 - val_loss: 0.5051 - val_acc: 0.8608 - lr: 3.0000e-04\n",
            "Epoch 16/26\n",
            "132/132 [==============================] - 54s 407ms/step - loss: 0.1190 - acc: 0.9665 - val_loss: 0.5189 - val_acc: 0.8480 - lr: 9.0000e-05\n",
            "Epoch 17/26\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0940 - acc: 0.9779\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "132/132 [==============================] - 54s 403ms/step - loss: 0.0940 - acc: 0.9779 - val_loss: 0.5702 - val_acc: 0.8522 - lr: 9.0000e-05\n",
            "Epoch 18/26\n",
            "132/132 [==============================] - 54s 403ms/step - loss: 0.0904 - acc: 0.9781 - val_loss: 0.6262 - val_acc: 0.8501 - lr: 2.7000e-05\n",
            "Epoch 19/26\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0767 - acc: 0.9843\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
            "132/132 [==============================] - 54s 404ms/step - loss: 0.0767 - acc: 0.9843 - val_loss: 0.6469 - val_acc: 0.8373 - lr: 2.7000e-05\n",
            "Epoch 20/26\n",
            "132/132 [==============================] - 54s 407ms/step - loss: 0.0741 - acc: 0.9824 - val_loss: 0.6323 - val_acc: 0.8565 - lr: 8.1000e-06\n",
            "Epoch 21/26\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0650 - acc: 0.9862\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 2.429999949526973e-06.\n",
            "132/132 [==============================] - 54s 404ms/step - loss: 0.0650 - acc: 0.9862 - val_loss: 0.5707 - val_acc: 0.8501 - lr: 8.1000e-06\n",
            "Epoch 22/26\n",
            "132/132 [==============================] - 54s 405ms/step - loss: 0.0671 - acc: 0.9864 - val_loss: 0.6231 - val_acc: 0.8415 - lr: 2.4300e-06\n",
            "Epoch 23/26\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0655 - acc: 0.9848\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 7.289999985005124e-07.\n",
            "132/132 [==============================] - 54s 407ms/step - loss: 0.0655 - acc: 0.9848 - val_loss: 0.5973 - val_acc: 0.8544 - lr: 2.4300e-06\n",
            "Epoch 24/26\n",
            "132/132 [==============================] - 54s 404ms/step - loss: 0.0634 - acc: 0.9883 - val_loss: 0.6099 - val_acc: 0.8458 - lr: 7.2900e-07\n",
            "Epoch 25/26\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0648 - acc: 0.9883\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 2.1870000637136398e-07.\n",
            "132/132 [==============================] - 54s 405ms/step - loss: 0.0648 - acc: 0.9883 - val_loss: 0.5867 - val_acc: 0.8415 - lr: 7.2900e-07\n",
            "Epoch 26/26\n",
            "132/132 [==============================] - 54s 407ms/step - loss: 0.0776 - acc: 0.9864 - val_loss: 0.6382 - val_acc: 0.8415 - lr: 2.1870e-07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model7.load_weights(\"best_model_effV2B3.hdf5\")\n",
        "preds = model7.predict(X_test)\n",
        "labelled_preds = one_hot_encoder.inverse_transform(preds)\n",
        "pred = pd.DataFrame(labelled_preds, columns =[\"class_id\"])\n",
        "df = pd.read_csv('submission3.csv')\n",
        "df ['class_id']= pred\n",
        "df.to_csv(\"final_submission43.csv\", index=False)"
      ],
      "metadata": {
        "id": "pa1Uja6DLTCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###EfficientNetV2M -> base_model19 Removed on Final Results"
      ],
      "metadata": {
        "id": "1tBeyxo348rC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "        rotation_range = 2,\n",
        "        zoom_range = 0.1, \n",
        "        width_shift_range = 0.1, \n",
        "        height_shift_range = 0.1,\n",
        "        brightness_range=[0.6,1.4],\n",
        "        fill_mode= \"nearest\",validation_split=0.1)"
      ],
      "metadata": {
        "id": "SAPW7KBE5HYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datagen.fit(X_train)\n",
        "train_gen = datagen.flow(X_train, y_train, batch_size=40, subset=\"training\")\n",
        "valid_gen = datagen.flow(X_train, y_train, batch_size=40, subset= \"validation\")"
      ],
      "metadata": {
        "id": "AtmHiWbA5HfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model14 = tf.keras.applications.EfficientNetV2M(include_top=False,\n",
        "                                     weights='imagenet',\n",
        "                                     input_shape=(224, 224, 3))\n",
        "x = base_model14.output\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = Dense(224, activation=None, kernel_regularizer = L1L2(l1=1e-5, l2=1e-3))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('swish')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "x = Dense(224, activation=None, kernel_regularizer = L1L2(l1=1e-5, l2=1e-3))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('swish')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "ouput1 = Dense(3, activation= 'softmax')(x)\n",
        "\n",
        "model14 = Model(inputs=base_model14.input, outputs=ouput1)\n",
        "model14.compile(loss='categorical_crossentropy', \n",
        "              optimizer=tf.keras.optimizers.Adam(1e-3, decay = 1e-3 * 0.1), metrics=['acc'])\n",
        "\n"
      ],
      "metadata": {
        "id": "cyD1CWYy48rI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checkpoints\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience = 2, verbose=1,factor=0.3, min_lr=0.000001)\n",
        "chkpt = ModelCheckpoint(filepath='best_model_EfficientNetV2M_50epochs_40.hdf5', monitor='val_acc', save_best_only=True, save_weights_only=True)\n",
        "\n",
        "#fit\n",
        "history = model14.fit(train_gen, epochs=50, validation_data=valid_gen, callbacks=[learning_rate_reduction, chkpt])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4f40b85-0dfb-4c23-988c-c1b97f1011a8",
        "id": "MwCpFV2t48rI"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "106/106 [==============================] - 144s 1s/step - loss: 1.3349 - acc: 0.7334 - val_loss: 1.1964 - val_acc: 0.7752 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "106/106 [==============================] - 109s 1s/step - loss: 1.0486 - acc: 0.7936 - val_loss: 1.1152 - val_acc: 0.7216 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "106/106 [==============================] - ETA: 0s - loss: 0.8915 - acc: 0.8081\n",
            "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "106/106 [==============================] - 112s 1s/step - loss: 0.8915 - acc: 0.8081 - val_loss: 2.5287 - val_acc: 0.6060 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "106/106 [==============================] - 115s 1s/step - loss: 0.7764 - acc: 0.8162 - val_loss: 0.7484 - val_acc: 0.8201 - lr: 3.0000e-04\n",
            "Epoch 5/50\n",
            "106/106 [==============================] - 115s 1s/step - loss: 0.6601 - acc: 0.8568 - val_loss: 0.6927 - val_acc: 0.8373 - lr: 3.0000e-04\n",
            "Epoch 6/50\n",
            "106/106 [==============================] - 112s 1s/step - loss: 0.6199 - acc: 0.8576 - val_loss: 0.6827 - val_acc: 0.8073 - lr: 3.0000e-04\n",
            "Epoch 7/50\n",
            "106/106 [==============================] - ETA: 0s - loss: 0.5475 - acc: 0.8799\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "106/106 [==============================] - 112s 1s/step - loss: 0.5475 - acc: 0.8799 - val_loss: 0.6331 - val_acc: 0.8308 - lr: 3.0000e-04\n",
            "Epoch 8/50\n",
            "106/106 [==============================] - 112s 1s/step - loss: 0.4497 - acc: 0.9182 - val_loss: 0.6386 - val_acc: 0.8287 - lr: 9.0000e-05\n",
            "Epoch 9/50\n",
            "106/106 [==============================] - 115s 1s/step - loss: 0.3996 - acc: 0.9360 - val_loss: 0.6312 - val_acc: 0.8437 - lr: 9.0000e-05\n",
            "Epoch 10/50\n",
            "106/106 [==============================] - 112s 1s/step - loss: 0.3629 - acc: 0.9453 - val_loss: 0.6539 - val_acc: 0.8373 - lr: 9.0000e-05\n",
            "Epoch 11/50\n",
            "106/106 [==============================] - ETA: 0s - loss: 0.3549 - acc: 0.9453\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "106/106 [==============================] - 112s 1s/step - loss: 0.3549 - acc: 0.9453 - val_loss: 0.6213 - val_acc: 0.8437 - lr: 9.0000e-05\n",
            "Epoch 12/50\n",
            "106/106 [==============================] - 112s 1s/step - loss: 0.2980 - acc: 0.9688 - val_loss: 0.6707 - val_acc: 0.8180 - lr: 2.7000e-05\n",
            "Epoch 13/50\n",
            "106/106 [==============================] - ETA: 0s - loss: 0.2839 - acc: 0.9698\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
            "106/106 [==============================] - 112s 1s/step - loss: 0.2839 - acc: 0.9698 - val_loss: 0.6990 - val_acc: 0.8373 - lr: 2.7000e-05\n",
            "Epoch 14/50\n",
            "106/106 [==============================] - 115s 1s/step - loss: 0.2728 - acc: 0.9750 - val_loss: 0.6853 - val_acc: 0.8480 - lr: 8.1000e-06\n",
            "Epoch 15/50\n",
            "106/106 [==============================] - 115s 1s/step - loss: 0.2607 - acc: 0.9784 - val_loss: 0.6516 - val_acc: 0.8522 - lr: 8.1000e-06\n",
            "Epoch 16/50\n",
            "106/106 [==============================] - 112s 1s/step - loss: 0.2646 - acc: 0.9765 - val_loss: 0.7029 - val_acc: 0.8437 - lr: 8.1000e-06\n",
            "Epoch 17/50\n",
            "106/106 [==============================] - ETA: 0s - loss: 0.2635 - acc: 0.9757\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 2.429999949526973e-06.\n",
            "106/106 [==============================] - 112s 1s/step - loss: 0.2635 - acc: 0.9757 - val_loss: 0.7101 - val_acc: 0.8373 - lr: 8.1000e-06\n",
            "Epoch 18/50\n",
            "106/106 [==============================] - 112s 1s/step - loss: 0.2639 - acc: 0.9755 - val_loss: 0.6931 - val_acc: 0.8373 - lr: 2.4300e-06\n",
            "Epoch 19/50\n",
            "106/106 [==============================] - ETA: 0s - loss: 0.2559 - acc: 0.9788\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "106/106 [==============================] - 112s 1s/step - loss: 0.2559 - acc: 0.9788 - val_loss: 0.7309 - val_acc: 0.8330 - lr: 2.4300e-06\n",
            "Epoch 20/50\n",
            "106/106 [==============================] - 112s 1s/step - loss: 0.2587 - acc: 0.9779 - val_loss: 0.6888 - val_acc: 0.8437 - lr: 1.0000e-06\n",
            "Epoch 21/50\n",
            "106/106 [==============================] - 112s 1s/step - loss: 0.2581 - acc: 0.9774 - val_loss: 0.6918 - val_acc: 0.8415 - lr: 1.0000e-06\n",
            "Epoch 22/50\n",
            "106/106 [==============================] - 115s 1s/step - loss: 0.2536 - acc: 0.9795 - val_loss: 0.6905 - val_acc: 0.8565 - lr: 1.0000e-06\n",
            "Epoch 23/50\n",
            "106/106 [==============================] - 112s 1s/step - loss: 0.2515 - acc: 0.9822 - val_loss: 0.7190 - val_acc: 0.8394 - lr: 1.0000e-06\n",
            "Epoch 24/50\n",
            "106/106 [==============================] - 112s 1s/step - loss: 0.2500 - acc: 0.9826 - val_loss: 0.6916 - val_acc: 0.8394 - lr: 1.0000e-06\n",
            "Epoch 25/50\n",
            "106/106 [==============================] - 112s 1s/step - loss: 0.2588 - acc: 0.9772 - val_loss: 0.7045 - val_acc: 0.8501 - lr: 1.0000e-06\n",
            "Epoch 26/50\n",
            "106/106 [==============================] - 112s 1s/step - loss: 0.2499 - acc: 0.9810 - val_loss: 0.7100 - val_acc: 0.8480 - lr: 1.0000e-06\n",
            "Epoch 27/50\n",
            "106/106 [==============================] - 112s 1s/step - loss: 0.2471 - acc: 0.9819 - val_loss: 0.7191 - val_acc: 0.8308 - lr: 1.0000e-06\n",
            "Epoch 28/50\n",
            "106/106 [==============================] - 112s 1s/step - loss: 0.2510 - acc: 0.9810 - val_loss: 0.7460 - val_acc: 0.8201 - lr: 1.0000e-06\n",
            "Epoch 29/50\n",
            "106/106 [==============================] - 112s 1s/step - loss: 0.2509 - acc: 0.9800 - val_loss: 0.7360 - val_acc: 0.8351 - lr: 1.0000e-06\n",
            "Epoch 30/50\n",
            "106/106 [==============================] - 112s 1s/step - loss: 0.2538 - acc: 0.9803 - val_loss: 0.7304 - val_acc: 0.8437 - lr: 1.0000e-06\n",
            "Epoch 31/50\n",
            "106/106 [==============================] - 112s 1s/step - loss: 0.2534 - acc: 0.9786 - val_loss: 0.7360 - val_acc: 0.8458 - lr: 1.0000e-06\n",
            "Epoch 32/50\n",
            "106/106 [==============================] - 115s 1s/step - loss: 0.2467 - acc: 0.9819 - val_loss: 0.6717 - val_acc: 0.8587 - lr: 1.0000e-06\n",
            "Epoch 33/50\n",
            "106/106 [==============================] - 112s 1s/step - loss: 0.2544 - acc: 0.9779 - val_loss: 0.6918 - val_acc: 0.8544 - lr: 1.0000e-06\n",
            "Epoch 34/50\n",
            "106/106 [==============================] - 112s 1s/step - loss: 0.2476 - acc: 0.9853 - val_loss: 0.7143 - val_acc: 0.8373 - lr: 1.0000e-06\n",
            "Epoch 35/50\n",
            "106/106 [==============================] - 115s 1s/step - loss: 0.2459 - acc: 0.9815 - val_loss: 0.7060 - val_acc: 0.8608 - lr: 1.0000e-06\n",
            "Epoch 36/50\n",
            "106/106 [==============================] - 112s 1s/step - loss: 0.2428 - acc: 0.9826 - val_loss: 0.7578 - val_acc: 0.8373 - lr: 1.0000e-06\n",
            "Epoch 37/50\n",
            "106/106 [==============================] - 112s 1s/step - loss: 0.2506 - acc: 0.9798 - val_loss: 0.7028 - val_acc: 0.8522 - lr: 1.0000e-06\n",
            "Epoch 38/50\n",
            "106/106 [==============================] - 112s 1s/step - loss: 0.2452 - acc: 0.9819 - val_loss: 0.7105 - val_acc: 0.8437 - lr: 1.0000e-06\n",
            "Epoch 39/50\n",
            "106/106 [==============================] - 112s 1s/step - loss: 0.2451 - acc: 0.9812 - val_loss: 0.7273 - val_acc: 0.8330 - lr: 1.0000e-06\n",
            "Epoch 40/50\n",
            "106/106 [==============================] - 112s 1s/step - loss: 0.2490 - acc: 0.9798 - val_loss: 0.6793 - val_acc: 0.8437 - lr: 1.0000e-06\n",
            "Epoch 41/50\n",
            "106/106 [==============================] - 112s 1s/step - loss: 0.2476 - acc: 0.9812 - val_loss: 0.7212 - val_acc: 0.8394 - lr: 1.0000e-06\n",
            "Epoch 42/50\n",
            "106/106 [==============================] - 112s 1s/step - loss: 0.2477 - acc: 0.9810 - val_loss: 0.7042 - val_acc: 0.8373 - lr: 1.0000e-06\n",
            "Epoch 43/50\n",
            "106/106 [==============================] - 116s 1s/step - loss: 0.2525 - acc: 0.9781 - val_loss: 0.6381 - val_acc: 0.8672 - lr: 1.0000e-06\n",
            "Epoch 44/50\n",
            "106/106 [==============================] - 112s 1s/step - loss: 0.2394 - acc: 0.9845 - val_loss: 0.7280 - val_acc: 0.8415 - lr: 1.0000e-06\n",
            "Epoch 45/50\n",
            "106/106 [==============================] - 112s 1s/step - loss: 0.2471 - acc: 0.9805 - val_loss: 0.6778 - val_acc: 0.8415 - lr: 1.0000e-06\n",
            "Epoch 46/50\n",
            "106/106 [==============================] - 112s 1s/step - loss: 0.2461 - acc: 0.9803 - val_loss: 0.7122 - val_acc: 0.8458 - lr: 1.0000e-06\n",
            "Epoch 47/50\n",
            "106/106 [==============================] - 112s 1s/step - loss: 0.2438 - acc: 0.9834 - val_loss: 0.7348 - val_acc: 0.8394 - lr: 1.0000e-06\n",
            "Epoch 48/50\n",
            "106/106 [==============================] - 112s 1s/step - loss: 0.2499 - acc: 0.9807 - val_loss: 0.6957 - val_acc: 0.8373 - lr: 1.0000e-06\n",
            "Epoch 49/50\n",
            "106/106 [==============================] - 112s 1s/step - loss: 0.2493 - acc: 0.9815 - val_loss: 0.7177 - val_acc: 0.8437 - lr: 1.0000e-06\n",
            "Epoch 50/50\n",
            "106/106 [==============================] - 112s 1s/step - loss: 0.2410 - acc: 0.9836 - val_loss: 0.7316 - val_acc: 0.8480 - lr: 1.0000e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model14.load_weights(\"best_model_EfficientNetV2M_50epochs_40.hdf5\")\n",
        "preds = model14.predict(X_test)\n",
        "labelled_preds = one_hot_encoder.inverse_transform(preds)\n",
        "pred = pd.DataFrame(labelled_preds, columns =[\"class_id\"])\n",
        "df = pd.read_csv('submission3.csv')\n",
        "df ['class_id']= pred\n",
        "df.to_csv(\"final_submission_EfficientNetV2M_50epochs_40.csv\", index=False)"
      ],
      "metadata": {
        "id": "fzqDyU1j48rJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "        rotation_range = 2,\n",
        "        zoom_range = 0.1, \n",
        "        width_shift_range = 0.1, \n",
        "        height_shift_range = 0.1,\n",
        "        brightness_range=[0.6,1.4],\n",
        "        fill_mode= \"nearest\",validation_split=0.1)"
      ],
      "metadata": {
        "id": "2oI5XYdaT1xC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datagen.fit(X_train)\n",
        "train_gen = datagen.flow(X_train, y_train, batch_size=45, subset=\"training\")\n",
        "valid_gen = datagen.flow(X_train, y_train, batch_size=45, subset= \"validation\")"
      ],
      "metadata": {
        "id": "I-uLYw1rT1xC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model16 = tf.keras.applications.EfficientNetV2M(include_top=False,\n",
        "                                     weights='imagenet',\n",
        "                                     input_shape=(224, 224, 3))\n",
        "x = base_model16.output\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = Dense(512, activation=None, kernel_regularizer = L1L2(l1=1e-5, l2=1e-3))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(512, activation=None, kernel_regularizer = L1L2(l1=1e-5, l2=1e-3))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "ouput1 = Dense(3, activation= 'softmax')(x)\n",
        "\n",
        "model16 = Model(inputs=base_model16.input, outputs=ouput1)\n",
        "model16.compile(loss='categorical_crossentropy', \n",
        "              optimizer=tf.keras.optimizers.Adam(1e-3, decay = 1e-3 * 0.1), metrics=['acc'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUm4H7z5aO2V",
        "outputId": "fdc6872b-4f53-4b27-989e-cb99301b4246"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-m_notop.h5\n",
            "214204416/214201816 [==============================] - 1s 0us/step\n",
            "214212608/214201816 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#checkpoints\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience = 2, verbose=1,factor=0.3, min_lr=0.000001)\n",
        "chkpt = ModelCheckpoint(filepath='best_model_EfficientNetV2M_vol2.hdf5', monitor='val_acc', save_best_only=True, save_weights_only=True)\n",
        "\n",
        "#fit\n",
        "history = model16.fit(train_gen, epochs=10, validation_data=valid_gen, callbacks=[learning_rate_reduction, chkpt])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d42c115d-f3e8-4caa-8873-6112803ab79c",
        "id": "PQ8DWNZnaO2W"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "104/104 [==============================] - 210s 2s/step - loss: 2.0884 - acc: 0.7453 - val_loss: 2.0835 - val_acc: 0.7018 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "104/104 [==============================] - 172s 2s/step - loss: 1.6448 - acc: 0.7928 - val_loss: 1.5949 - val_acc: 0.7339 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "104/104 [==============================] - 173s 2s/step - loss: 1.2627 - acc: 0.8183 - val_loss: 1.0442 - val_acc: 0.8555 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "104/104 [==============================] - 172s 2s/step - loss: 0.9819 - acc: 0.8221 - val_loss: 0.8369 - val_acc: 0.8553 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.8213 - acc: 0.8283\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "104/104 [==============================] - 171s 2s/step - loss: 0.8213 - acc: 0.8283 - val_loss: 0.8169 - val_acc: 0.7992 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "104/104 [==============================] - 174s 2s/step - loss: 0.7131 - acc: 0.8343 - val_loss: 0.6027 - val_acc: 0.8784 - lr: 3.0000e-04\n",
            "Epoch 7/10\n",
            "104/104 [==============================] - 174s 2s/step - loss: 0.6024 - acc: 0.8619 - val_loss: 0.5264 - val_acc: 0.8973 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "104/104 [==============================] - 178s 2s/step - loss: 0.5273 - acc: 0.8840 - val_loss: 0.4706 - val_acc: 0.8985 - lr: 3.0000e-04\n",
            "Epoch 9/10\n",
            "104/104 [==============================] - 175s 2s/step - loss: 0.4670 - acc: 0.8932 - val_loss: 0.4021 - val_acc: 0.9204 - lr: 3.0000e-04\n",
            "Epoch 10/10\n",
            "104/104 [==============================] - 179s 2s/step - loss: 0.3998 - acc: 0.9163 - val_loss: 0.3352 - val_acc: 0.9362 - lr: 3.0000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model16.load_weights('best_model_EfficientNetV2M_vol2.hdf5')\n",
        "preds = model16.predict(X_test)\n",
        "labelled_preds = one_hot_encoder.inverse_transform(preds)\n",
        "pred = pd.DataFrame(labelled_preds, columns =[\"class_id\"])\n",
        "df = pd.read_csv('submission3.csv')\n",
        "df ['class_id']= pred\n",
        "df.to_csv(\"final_submission_EfficientNetV2M_vol2.csv\", index=False)"
      ],
      "metadata": {
        "id": "dEdbd1YIhY_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model19 = tf.keras.applications.EfficientNetV2M(include_top=False,\n",
        "                                     weights='imagenet',\n",
        "                                     input_shape=(224, 224, 3))\n",
        "x = base_model19.output\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = Dense(512, activation=None, kernel_regularizer = L1L2(l1=1e-5, l2=1e-3))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('swish')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(512, activation=None, kernel_regularizer = L1L2(l1=1e-5, l2=1e-3))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('swish')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "ouput1 = Dense(3, activation= 'softmax')(x)\n",
        "\n",
        "model19 = Model(inputs=base_model19.input, outputs=ouput1)\n",
        "model19.compile(loss='categorical_crossentropy', \n",
        "              optimizer=tf.keras.optimizers.Adam(1e-3, decay = 1e-3 * 0.1), metrics=['acc'])"
      ],
      "metadata": {
        "id": "KxyFo3jKT1xC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checkpoints\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience = 2, verbose=1,factor=0.3, min_lr=0.000001)\n",
        "chkpt = ModelCheckpoint(filepath='best_model_EfficientNetV2M_vol6.hdf5', monitor='val_acc', save_best_only=True, save_weights_only=True)\n",
        "\n",
        "#fit\n",
        "history = model19.fit(train_gen, epochs=10, validation_data=valid_gen, callbacks=[learning_rate_reduction, chkpt])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c826cb77-aa50-4962-b1aa-4382008d047e",
        "id": "ZEas3ei1T1xD"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "104/104 [==============================] - 200s 2s/step - loss: 2.0952 - acc: 0.7380 - val_loss: 1.7505 - val_acc: 0.8266 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "104/104 [==============================] - 170s 2s/step - loss: 1.6983 - acc: 0.7770 - val_loss: 1.5436 - val_acc: 0.7975 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "104/104 [==============================] - 174s 2s/step - loss: 1.3640 - acc: 0.7729 - val_loss: 1.1381 - val_acc: 0.8307 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "104/104 [==============================] - 171s 2s/step - loss: 1.1220 - acc: 0.7920 - val_loss: 0.9992 - val_acc: 0.8035 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.0344 - acc: 0.7601\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "104/104 [==============================] - 171s 2s/step - loss: 1.0344 - acc: 0.7601 - val_loss: 0.8978 - val_acc: 0.7821 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "104/104 [==============================] - 171s 2s/step - loss: 0.8465 - acc: 0.7964 - val_loss: 0.7746 - val_acc: 0.8179 - lr: 3.0000e-04\n",
            "Epoch 7/10\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.7552 - acc: 0.8146\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "104/104 [==============================] - 171s 2s/step - loss: 0.7552 - acc: 0.8146 - val_loss: 0.7075 - val_acc: 0.8219 - lr: 3.0000e-04\n",
            "Epoch 8/10\n",
            "104/104 [==============================] - 174s 2s/step - loss: 0.6957 - acc: 0.8277 - val_loss: 0.6509 - val_acc: 0.8478 - lr: 9.0000e-05\n",
            "Epoch 9/10\n",
            "104/104 [==============================] - 174s 2s/step - loss: 0.6509 - acc: 0.8457 - val_loss: 0.6119 - val_acc: 0.8654 - lr: 9.0000e-05\n",
            "Epoch 10/10\n",
            "104/104 [==============================] - 174s 2s/step - loss: 0.6315 - acc: 0.8508 - val_loss: 0.5752 - val_acc: 0.8786 - lr: 9.0000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model19.load_weights('best_model_EfficientNetV2M_vol6.hdf5')\n",
        "preds = model19.predict(X_test)\n",
        "labelled_preds = one_hot_encoder.inverse_transform(preds)\n",
        "pred = pd.DataFrame(labelled_preds, columns =[\"class_id\"])\n",
        "df = pd.read_csv('submission3.csv')\n",
        "df ['class_id']= pred\n",
        "df.to_csv(\"final_submission_EfficientNetV2M_vol6.csv\", index=False)"
      ],
      "metadata": {
        "id": "g2npB6GVT1xD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model20 = tf.keras.applications.EfficientNetV2M(include_top=False,\n",
        "                                     weights='imagenet',\n",
        "                                     input_shape=(224, 224, 3))\n",
        "x = base_model20.output\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = Dense(512, activation=None, kernel_regularizer = L1L2(l1=1e-5, l2=1e-3))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('swish')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(512, activation=None, kernel_regularizer = L1L2(l1=1e-5, l2=1e-3))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('swish')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "ouput1 = Dense(3, activation= 'softmax')(x)\n",
        "\n",
        "model20 = Model(inputs=base_model20.input, outputs=ouput1)\n",
        "model20.compile(loss='categorical_crossentropy', \n",
        "              optimizer=tf.keras.optimizers.Adam(1e-3, decay = 1e-3 * 0.1), metrics=['acc'])"
      ],
      "metadata": {
        "id": "ZJqhbK0EgNRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checkpoints\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience = 2, verbose=1,factor=0.3, min_lr=0.000001)\n",
        "chkpt = ModelCheckpoint(filepath='best_model_EfficientNetV2M_vol7.hdf5', monitor='val_acc', save_best_only=True, save_weights_only=True)\n",
        "\n",
        "#fit\n",
        "history = model20.fit(train_gen, epochs=50, validation_data=valid_gen, callbacks=[learning_rate_reduction, chkpt])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bab9af0a-ef8b-489b-9af9-562e6325e0b8",
        "id": "eL3yc_6OgNRP"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "104/104 [==============================] - 209s 2s/step - loss: 2.1217 - acc: 0.7179 - val_loss: 1.8074 - val_acc: 0.8039 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 170s 2s/step - loss: 1.6724 - acc: 0.8031 - val_loss: 1.5628 - val_acc: 0.7990 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 1.5122 - acc: 0.7661\n",
            "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "104/104 [==============================] - 170s 2s/step - loss: 1.5122 - acc: 0.7661 - val_loss: 4.3048 - val_acc: 0.6203 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 173s 2s/step - loss: 1.2637 - acc: 0.7864 - val_loss: 1.1842 - val_acc: 0.8061 - lr: 3.0000e-04\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 172s 2s/step - loss: 1.1417 - acc: 0.8097 - val_loss: 1.0507 - val_acc: 0.8266 - lr: 3.0000e-04\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 173s 2s/step - loss: 1.0201 - acc: 0.8281 - val_loss: 0.9685 - val_acc: 0.8328 - lr: 3.0000e-04\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 173s 2s/step - loss: 0.9294 - acc: 0.8345 - val_loss: 0.8789 - val_acc: 0.8560 - lr: 3.0000e-04\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 174s 2s/step - loss: 0.8386 - acc: 0.8521 - val_loss: 0.7629 - val_acc: 0.8707 - lr: 3.0000e-04\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 173s 2s/step - loss: 0.7655 - acc: 0.8510 - val_loss: 0.7224 - val_acc: 0.8735 - lr: 3.0000e-04\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 172s 2s/step - loss: 0.6786 - acc: 0.8701 - val_loss: 0.6084 - val_acc: 0.8932 - lr: 3.0000e-04\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 170s 2s/step - loss: 0.6146 - acc: 0.8763 - val_loss: 0.5631 - val_acc: 0.8823 - lr: 3.0000e-04\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 172s 2s/step - loss: 0.5549 - acc: 0.8870 - val_loss: 0.5201 - val_acc: 0.8975 - lr: 3.0000e-04\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 173s 2s/step - loss: 0.4948 - acc: 0.8975 - val_loss: 0.4481 - val_acc: 0.9103 - lr: 3.0000e-04\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 173s 2s/step - loss: 0.4446 - acc: 0.9037 - val_loss: 0.4008 - val_acc: 0.9187 - lr: 3.0000e-04\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 173s 2s/step - loss: 0.3881 - acc: 0.9229 - val_loss: 0.3629 - val_acc: 0.9206 - lr: 3.0000e-04\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 173s 2s/step - loss: 0.3553 - acc: 0.9277 - val_loss: 0.3115 - val_acc: 0.9381 - lr: 3.0000e-04\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 173s 2s/step - loss: 0.3320 - acc: 0.9313 - val_loss: 0.2623 - val_acc: 0.9568 - lr: 3.0000e-04\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 173s 2s/step - loss: 0.2825 - acc: 0.9452 - val_loss: 0.2342 - val_acc: 0.9591 - lr: 3.0000e-04\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 173s 2s/step - loss: 0.2640 - acc: 0.9405 - val_loss: 0.2166 - val_acc: 0.9630 - lr: 3.0000e-04\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 170s 2s/step - loss: 0.2132 - acc: 0.9613 - val_loss: 0.2513 - val_acc: 0.9424 - lr: 3.0000e-04\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 173s 2s/step - loss: 0.2149 - acc: 0.9568 - val_loss: 0.1624 - val_acc: 0.9750 - lr: 3.0000e-04\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 174s 2s/step - loss: 0.1965 - acc: 0.9602 - val_loss: 0.1449 - val_acc: 0.9801 - lr: 3.0000e-04\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 170s 2s/step - loss: 0.1673 - acc: 0.9715 - val_loss: 0.1428 - val_acc: 0.9747 - lr: 3.0000e-04\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.1700 - acc: 0.9625\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "104/104 [==============================] - 170s 2s/step - loss: 0.1700 - acc: 0.9625 - val_loss: 0.1596 - val_acc: 0.9688 - lr: 3.0000e-04\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 173s 2s/step - loss: 0.1157 - acc: 0.9857 - val_loss: 0.0860 - val_acc: 0.9949 - lr: 9.0000e-05\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 173s 2s/step - loss: 0.0882 - acc: 0.9923 - val_loss: 0.0791 - val_acc: 0.9955 - lr: 9.0000e-05\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 172s 2s/step - loss: 0.0794 - acc: 0.9951 - val_loss: 0.0696 - val_acc: 0.9979 - lr: 9.0000e-05\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 170s 2s/step - loss: 0.0777 - acc: 0.9929 - val_loss: 0.0654 - val_acc: 0.9979 - lr: 9.0000e-05\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.0676 - acc: 0.9968\n",
            "Epoch 29: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "104/104 [==============================] - 170s 2s/step - loss: 0.0676 - acc: 0.9968 - val_loss: 0.0633 - val_acc: 0.9974 - lr: 9.0000e-05\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 173s 2s/step - loss: 0.0689 - acc: 0.9957 - val_loss: 0.0582 - val_acc: 0.9991 - lr: 2.7000e-05\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 170s 2s/step - loss: 0.0643 - acc: 0.9964 - val_loss: 0.0571 - val_acc: 0.9983 - lr: 2.7000e-05\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 173s 2s/step - loss: 0.0599 - acc: 0.9970 - val_loss: 0.0545 - val_acc: 0.9994 - lr: 2.7000e-05\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 170s 2s/step - loss: 0.0579 - acc: 0.9981 - val_loss: 0.0549 - val_acc: 0.9983 - lr: 2.7000e-05\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.0575 - acc: 0.9979\n",
            "Epoch 34: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
            "104/104 [==============================] - 170s 2s/step - loss: 0.0575 - acc: 0.9979 - val_loss: 0.0523 - val_acc: 0.9989 - lr: 2.7000e-05\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 173s 2s/step - loss: 0.0553 - acc: 0.9981 - val_loss: 0.0515 - val_acc: 0.9996 - lr: 8.1000e-06\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 170s 2s/step - loss: 0.0569 - acc: 0.9974 - val_loss: 0.0520 - val_acc: 0.9989 - lr: 8.1000e-06\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.0526 - acc: 0.9985\n",
            "Epoch 37: ReduceLROnPlateau reducing learning rate to 2.429999949526973e-06.\n",
            "104/104 [==============================] - 170s 2s/step - loss: 0.0526 - acc: 0.9985 - val_loss: 0.0505 - val_acc: 0.9991 - lr: 8.1000e-06\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 174s 2s/step - loss: 0.0544 - acc: 0.9981 - val_loss: 0.0501 - val_acc: 0.9998 - lr: 2.4300e-06\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 170s 2s/step - loss: 0.0517 - acc: 0.9994 - val_loss: 0.0502 - val_acc: 0.9996 - lr: 2.4300e-06\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.0526 - acc: 0.9989\n",
            "Epoch 40: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "104/104 [==============================] - 170s 2s/step - loss: 0.0526 - acc: 0.9989 - val_loss: 0.0501 - val_acc: 0.9994 - lr: 2.4300e-06\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 170s 2s/step - loss: 0.0529 - acc: 0.9985 - val_loss: 0.0503 - val_acc: 0.9994 - lr: 1.0000e-06\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 170s 2s/step - loss: 0.0536 - acc: 0.9983 - val_loss: 0.0496 - val_acc: 0.9998 - lr: 1.0000e-06\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 170s 2s/step - loss: 0.0515 - acc: 0.9994 - val_loss: 0.0493 - val_acc: 0.9996 - lr: 1.0000e-06\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 170s 2s/step - loss: 0.0535 - acc: 0.9981 - val_loss: 0.0498 - val_acc: 0.9994 - lr: 1.0000e-06\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 170s 2s/step - loss: 0.0522 - acc: 0.9989 - val_loss: 0.0494 - val_acc: 0.9996 - lr: 1.0000e-06\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 170s 2s/step - loss: 0.0518 - acc: 0.9989 - val_loss: 0.0491 - val_acc: 0.9998 - lr: 1.0000e-06\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 170s 2s/step - loss: 0.0517 - acc: 0.9991 - val_loss: 0.0499 - val_acc: 0.9991 - lr: 1.0000e-06\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 170s 2s/step - loss: 0.0504 - acc: 0.9996 - val_loss: 0.0490 - val_acc: 0.9996 - lr: 1.0000e-06\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 170s 2s/step - loss: 0.0529 - acc: 0.9985 - val_loss: 0.0489 - val_acc: 0.9998 - lr: 1.0000e-06\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 170s 2s/step - loss: 0.0525 - acc: 0.9981 - val_loss: 0.0491 - val_acc: 0.9998 - lr: 1.0000e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model20.load_weights('best_model_EfficientNetV2M_vol7.hdf5')\n",
        "preds = model20.predict(X_test)\n",
        "labelled_preds = one_hot_encoder.inverse_transform(preds)\n",
        "pred = pd.DataFrame(labelled_preds, columns =[\"class_id\"])\n",
        "df = pd.read_csv('submission3.csv')\n",
        "df ['class_id']= pred\n",
        "df.to_csv(\"final_submission_EfficientNetV2M_vol7.csv\", index=False)"
      ],
      "metadata": {
        "id": "e8AiHbNigNRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###MobileNet"
      ],
      "metadata": {
        "id": "-5n68tdlp-9i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model8 = tf.keras.applications.MobileNet(include_top=False,\n",
        "                                     weights='imagenet',\n",
        "                                     input_shape=(224, 224, 3))\n",
        "x = base_model8.output\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = Dense(512, activation=None, kernel_regularizer = L1L2(l1=1e-5, l2=1e-3))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('swish')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(512, activation=None, kernel_regularizer = L1L2(l1=1e-5, l2=1e-3))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('swish')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "ouput1 = Dense(3, activation= 'softmax')(x)\n",
        "\n",
        "model8 = Model(inputs=base_model8.input, outputs=ouput1)\n",
        "\n",
        "model8.compile(loss='categorical_crossentropy', \n",
        "              optimizer=tf.keras.optimizers.Adam(1e-3, decay = 1e-3 * 0.1), metrics=['acc'])\n",
        "model8.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Stf933V_qEcg",
        "outputId": "4724aaca-cd5c-4039-b4e6-a882db4b26a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_12 (InputLayer)       [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " conv1 (Conv2D)              (None, 112, 112, 32)      864       \n",
            "                                                                 \n",
            " conv1_bn (BatchNormalizatio  (None, 112, 112, 32)     128       \n",
            " n)                                                              \n",
            "                                                                 \n",
            " conv1_relu (ReLU)           (None, 112, 112, 32)      0         \n",
            "                                                                 \n",
            " conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 32)     288       \n",
            "                                                                 \n",
            " conv_dw_1_bn (BatchNormaliz  (None, 112, 112, 32)     128       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_1_relu (ReLU)       (None, 112, 112, 32)      0         \n",
            "                                                                 \n",
            " conv_pw_1 (Conv2D)          (None, 112, 112, 64)      2048      \n",
            "                                                                 \n",
            " conv_pw_1_bn (BatchNormaliz  (None, 112, 112, 64)     256       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_1_relu (ReLU)       (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " conv_pad_2 (ZeroPadding2D)  (None, 113, 113, 64)      0         \n",
            "                                                                 \n",
            " conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 64)       576       \n",
            "                                                                 \n",
            " conv_dw_2_bn (BatchNormaliz  (None, 56, 56, 64)       256       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_2_relu (ReLU)       (None, 56, 56, 64)        0         \n",
            "                                                                 \n",
            " conv_pw_2 (Conv2D)          (None, 56, 56, 128)       8192      \n",
            "                                                                 \n",
            " conv_pw_2_bn (BatchNormaliz  (None, 56, 56, 128)      512       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_2_relu (ReLU)       (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 128)      1152      \n",
            "                                                                 \n",
            " conv_dw_3_bn (BatchNormaliz  (None, 56, 56, 128)      512       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_3_relu (ReLU)       (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " conv_pw_3 (Conv2D)          (None, 56, 56, 128)       16384     \n",
            "                                                                 \n",
            " conv_pw_3_bn (BatchNormaliz  (None, 56, 56, 128)      512       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_3_relu (ReLU)       (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " conv_pad_4 (ZeroPadding2D)  (None, 57, 57, 128)       0         \n",
            "                                                                 \n",
            " conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 128)      1152      \n",
            "                                                                 \n",
            " conv_dw_4_bn (BatchNormaliz  (None, 28, 28, 128)      512       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_4_relu (ReLU)       (None, 28, 28, 128)       0         \n",
            "                                                                 \n",
            " conv_pw_4 (Conv2D)          (None, 28, 28, 256)       32768     \n",
            "                                                                 \n",
            " conv_pw_4_bn (BatchNormaliz  (None, 28, 28, 256)      1024      \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_4_relu (ReLU)       (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 256)      2304      \n",
            "                                                                 \n",
            " conv_dw_5_bn (BatchNormaliz  (None, 28, 28, 256)      1024      \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_5_relu (ReLU)       (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " conv_pw_5 (Conv2D)          (None, 28, 28, 256)       65536     \n",
            "                                                                 \n",
            " conv_pw_5_bn (BatchNormaliz  (None, 28, 28, 256)      1024      \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_5_relu (ReLU)       (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " conv_pad_6 (ZeroPadding2D)  (None, 29, 29, 256)       0         \n",
            "                                                                 \n",
            " conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 256)      2304      \n",
            "                                                                 \n",
            " conv_dw_6_bn (BatchNormaliz  (None, 14, 14, 256)      1024      \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_6_relu (ReLU)       (None, 14, 14, 256)       0         \n",
            "                                                                 \n",
            " conv_pw_6 (Conv2D)          (None, 14, 14, 512)       131072    \n",
            "                                                                 \n",
            " conv_pw_6_bn (BatchNormaliz  (None, 14, 14, 512)      2048      \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_6_relu (ReLU)       (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 512)      4608      \n",
            "                                                                 \n",
            " conv_dw_7_bn (BatchNormaliz  (None, 14, 14, 512)      2048      \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_7_relu (ReLU)       (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " conv_pw_7 (Conv2D)          (None, 14, 14, 512)       262144    \n",
            "                                                                 \n",
            " conv_pw_7_bn (BatchNormaliz  (None, 14, 14, 512)      2048      \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_7_relu (ReLU)       (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 512)      4608      \n",
            "                                                                 \n",
            " conv_dw_8_bn (BatchNormaliz  (None, 14, 14, 512)      2048      \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_8_relu (ReLU)       (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " conv_pw_8 (Conv2D)          (None, 14, 14, 512)       262144    \n",
            "                                                                 \n",
            " conv_pw_8_bn (BatchNormaliz  (None, 14, 14, 512)      2048      \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_8_relu (ReLU)       (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 512)      4608      \n",
            "                                                                 \n",
            " conv_dw_9_bn (BatchNormaliz  (None, 14, 14, 512)      2048      \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_9_relu (ReLU)       (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " conv_pw_9 (Conv2D)          (None, 14, 14, 512)       262144    \n",
            "                                                                 \n",
            " conv_pw_9_bn (BatchNormaliz  (None, 14, 14, 512)      2048      \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_9_relu (ReLU)       (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " conv_dw_10 (DepthwiseConv2D  (None, 14, 14, 512)      4608      \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv_dw_10_bn (BatchNormali  (None, 14, 14, 512)      2048      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_dw_10_relu (ReLU)      (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " conv_pw_10 (Conv2D)         (None, 14, 14, 512)       262144    \n",
            "                                                                 \n",
            " conv_pw_10_bn (BatchNormali  (None, 14, 14, 512)      2048      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_pw_10_relu (ReLU)      (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " conv_dw_11 (DepthwiseConv2D  (None, 14, 14, 512)      4608      \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv_dw_11_bn (BatchNormali  (None, 14, 14, 512)      2048      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_dw_11_relu (ReLU)      (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " conv_pw_11 (Conv2D)         (None, 14, 14, 512)       262144    \n",
            "                                                                 \n",
            " conv_pw_11_bn (BatchNormali  (None, 14, 14, 512)      2048      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_pw_11_relu (ReLU)      (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " conv_pad_12 (ZeroPadding2D)  (None, 15, 15, 512)      0         \n",
            "                                                                 \n",
            " conv_dw_12 (DepthwiseConv2D  (None, 7, 7, 512)        4608      \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv_dw_12_bn (BatchNormali  (None, 7, 7, 512)        2048      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_dw_12_relu (ReLU)      (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " conv_pw_12 (Conv2D)         (None, 7, 7, 1024)        524288    \n",
            "                                                                 \n",
            " conv_pw_12_bn (BatchNormali  (None, 7, 7, 1024)       4096      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_pw_12_relu (ReLU)      (None, 7, 7, 1024)        0         \n",
            "                                                                 \n",
            " conv_dw_13 (DepthwiseConv2D  (None, 7, 7, 1024)       9216      \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv_dw_13_bn (BatchNormali  (None, 7, 7, 1024)       4096      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_dw_13_relu (ReLU)      (None, 7, 7, 1024)        0         \n",
            "                                                                 \n",
            " conv_pw_13 (Conv2D)         (None, 7, 7, 1024)        1048576   \n",
            "                                                                 \n",
            " conv_pw_13_bn (BatchNormali  (None, 7, 7, 1024)       4096      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_pw_13_relu (ReLU)      (None, 7, 7, 1024)        0         \n",
            "                                                                 \n",
            " global_average_pooling2d_11  (None, 1024)             0         \n",
            "  (GlobalAveragePooling2D)                                       \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 512)               524800    \n",
            "                                                                 \n",
            " batch_normalization_22 (Bat  (None, 512)              2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_22 (Activation)  (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_22 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " batch_normalization_23 (Bat  (None, 512)              2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_23 (Activation)  (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_23 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 3)                 1539      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,021,955\n",
            "Trainable params: 3,998,019\n",
            "Non-trainable params: 23,936\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', patience = 2, verbose=1,factor=0.3, min_lr=0.00000001)\n",
        "chkpt = ModelCheckpoint(filepath='best_model_MN.hdf5', monitor='val_loss', save_best_only=True, save_weights_only=True)\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(patience=13, monitor='val_loss', restore_best_weights=True)\n",
        "\n",
        "history8 = model8.fit(train_gen, epochs=20, validation_data=valid_gen, callbacks=[learning_rate_reduction, chkpt, early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwqmGhgeqW0M",
        "outputId": "73fc3781-3180-4689-8bdd-59c88aca9bf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "132/132 [==============================] - 68s 487ms/step - loss: 2.0216 - acc: 0.7389 - val_loss: 2.1545 - val_acc: 0.7816 - lr: 0.0010\n",
            "Epoch 2/20\n",
            "132/132 [==============================] - 56s 423ms/step - loss: 1.5712 - acc: 0.8017 - val_loss: 1.7701 - val_acc: 0.7131 - lr: 0.0010\n",
            "Epoch 3/20\n",
            "132/132 [==============================] - 53s 398ms/step - loss: 1.2306 - acc: 0.8162 - val_loss: 1.1688 - val_acc: 0.8094 - lr: 0.0010\n",
            "Epoch 4/20\n",
            "132/132 [==============================] - 54s 410ms/step - loss: 0.9619 - acc: 0.8288 - val_loss: 0.8996 - val_acc: 0.8373 - lr: 0.0010\n",
            "Epoch 5/20\n",
            "132/132 [==============================] - 53s 399ms/step - loss: 0.7599 - acc: 0.8361 - val_loss: 0.8362 - val_acc: 0.7966 - lr: 0.0010\n",
            "Epoch 6/20\n",
            "132/132 [==============================] - 53s 399ms/step - loss: 0.6119 - acc: 0.8485 - val_loss: 0.6912 - val_acc: 0.7923 - lr: 0.0010\n",
            "Epoch 7/20\n",
            "132/132 [==============================] - 52s 392ms/step - loss: 0.5250 - acc: 0.8623 - val_loss: 0.7040 - val_acc: 0.7966 - lr: 0.0010\n",
            "Epoch 8/20\n",
            "132/132 [==============================] - 52s 396ms/step - loss: 0.4663 - acc: 0.8578 - val_loss: 0.5448 - val_acc: 0.8116 - lr: 0.0010\n",
            "Epoch 9/20\n",
            "132/132 [==============================] - 52s 394ms/step - loss: 0.4242 - acc: 0.8621 - val_loss: 0.4557 - val_acc: 0.8608 - lr: 0.0010\n",
            "Epoch 10/20\n",
            "132/132 [==============================] - 52s 389ms/step - loss: 0.3675 - acc: 0.8799 - val_loss: 0.7024 - val_acc: 0.7109 - lr: 0.0010\n",
            "Epoch 11/20\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.3538 - acc: 0.8823\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "132/132 [==============================] - 52s 389ms/step - loss: 0.3538 - acc: 0.8823 - val_loss: 0.4724 - val_acc: 0.8266 - lr: 0.0010\n",
            "Epoch 12/20\n",
            "132/132 [==============================] - 52s 391ms/step - loss: 0.2536 - acc: 0.9208 - val_loss: 0.4609 - val_acc: 0.8394 - lr: 3.0000e-04\n",
            "Epoch 13/20\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.2016 - acc: 0.9370\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "132/132 [==============================] - 52s 391ms/step - loss: 0.2016 - acc: 0.9370 - val_loss: 0.5058 - val_acc: 0.8137 - lr: 3.0000e-04\n",
            "Epoch 14/20\n",
            "132/132 [==============================] - 52s 391ms/step - loss: 0.1590 - acc: 0.9581 - val_loss: 0.4931 - val_acc: 0.8351 - lr: 9.0000e-05\n",
            "Epoch 15/20\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.1335 - acc: 0.9624\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "132/132 [==============================] - 51s 388ms/step - loss: 0.1335 - acc: 0.9624 - val_loss: 0.5623 - val_acc: 0.8223 - lr: 9.0000e-05\n",
            "Epoch 16/20\n",
            "132/132 [==============================] - 52s 391ms/step - loss: 0.1222 - acc: 0.9693 - val_loss: 0.5652 - val_acc: 0.8415 - lr: 2.7000e-05\n",
            "Epoch 17/20\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.1146 - acc: 0.9727\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
            "132/132 [==============================] - 52s 390ms/step - loss: 0.1146 - acc: 0.9727 - val_loss: 0.5375 - val_acc: 0.8544 - lr: 2.7000e-05\n",
            "Epoch 18/20\n",
            "132/132 [==============================] - 52s 391ms/step - loss: 0.1034 - acc: 0.9736 - val_loss: 0.5314 - val_acc: 0.8480 - lr: 8.1000e-06\n",
            "Epoch 19/20\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.0972 - acc: 0.9776\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 2.429999949526973e-06.\n",
            "132/132 [==============================] - 52s 390ms/step - loss: 0.0972 - acc: 0.9776 - val_loss: 0.5721 - val_acc: 0.8394 - lr: 8.1000e-06\n",
            "Epoch 20/20\n",
            "132/132 [==============================] - 52s 391ms/step - loss: 0.0978 - acc: 0.9765 - val_loss: 0.5361 - val_acc: 0.8415 - lr: 2.4300e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model8.load_weights(\"best_model_MN.hdf5\")\n",
        "preds = model8.predict(X_test)\n",
        "labelled_preds = one_hot_encoder.inverse_transform(preds)\n",
        "pred = pd.DataFrame(labelled_preds, columns =[\"class_id\"])\n",
        "df = pd.read_csv('submission3.csv')\n",
        "df ['class_id']= pred\n",
        "df.to_csv(\"final_submission46.csv\", index=False)"
      ],
      "metadata": {
        "id": "AeZfn63_qegV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###MobileNetV2 ->  Removed on Final Results"
      ],
      "metadata": {
        "id": "g1pTRhgaqwmd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model9 = tf.keras.applications.MobileNetV2(include_top=False,\n",
        "                                     weights='imagenet',\n",
        "                                     input_shape=(224, 224, 3))\n",
        "x = base_model9.output\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = Dense(512, activation=None, kernel_regularizer = L1L2(l1=1e-5, l2=1e-3))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('swish')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(512, activation=None, kernel_regularizer = L1L2(l1=1e-5, l2=1e-3))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('swish')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "ouput1 = Dense(3, activation= 'softmax')(x)\n",
        "\n",
        "model9 = Model(inputs=base_model9.input, outputs=ouput1)\n",
        "\n",
        "model9.compile(loss='categorical_crossentropy', \n",
        "              optimizer=tf.keras.optimizers.Adam(1e-3, decay = 1e-3 * 0.1), metrics=['acc'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HJx3jMnqzby",
        "outputId": "dca70a18-5af4-4cbe-8897-d8c175fca9e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9412608/9406464 [==============================] - 0s 0us/step\n",
            "9420800/9406464 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', patience = 2, verbose=1,factor=0.3, min_lr=0.00000001)\n",
        "chkpt = ModelCheckpoint(filepath='best_model_MNV2.hdf5', monitor='val_loss', save_best_only=True, save_weights_only=True)\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(patience=13, monitor='val_loss', restore_best_weights=True)\n",
        "\n",
        "history9 = model9.fit(train_gen, epochs=20, validation_data=valid_gen, callbacks=[learning_rate_reduction, chkpt, early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoJqT3NIq-64",
        "outputId": "3fe1a0b6-a0f5-4e50-cfcd-118d4f041d29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "132/132 [==============================] - 60s 412ms/step - loss: 2.1421 - acc: 0.7146 - val_loss: 5.1924 - val_acc: 0.2998 - lr: 0.0010\n",
            "Epoch 2/20\n",
            "132/132 [==============================] - 54s 405ms/step - loss: 1.6561 - acc: 0.7857 - val_loss: 4.8682 - val_acc: 0.4069 - lr: 0.0010\n",
            "Epoch 3/20\n",
            "132/132 [==============================] - 53s 401ms/step - loss: 1.2740 - acc: 0.7990 - val_loss: 2.7762 - val_acc: 0.4347 - lr: 0.0010\n",
            "Epoch 4/20\n",
            "132/132 [==============================] - 53s 401ms/step - loss: 1.0031 - acc: 0.8209 - val_loss: 1.2577 - val_acc: 0.7666 - lr: 0.0010\n",
            "Epoch 5/20\n",
            "132/132 [==============================] - 52s 395ms/step - loss: 0.8178 - acc: 0.8140 - val_loss: 3.0075 - val_acc: 0.4861 - lr: 0.0010\n",
            "Epoch 6/20\n",
            "132/132 [==============================] - 53s 397ms/step - loss: 0.6889 - acc: 0.8193 - val_loss: 1.0821 - val_acc: 0.6253 - lr: 0.0010\n",
            "Epoch 7/20\n",
            "132/132 [==============================] - 52s 395ms/step - loss: 0.5899 - acc: 0.8333 - val_loss: 1.7274 - val_acc: 0.4968 - lr: 0.0010\n",
            "Epoch 8/20\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.5326 - acc: 0.8331\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "132/132 [==============================] - 52s 394ms/step - loss: 0.5326 - acc: 0.8331 - val_loss: 6.7646 - val_acc: 0.3298 - lr: 0.0010\n",
            "Epoch 9/20\n",
            "132/132 [==============================] - 52s 390ms/step - loss: 0.4195 - acc: 0.8702 - val_loss: 1.1069 - val_acc: 0.6831 - lr: 3.0000e-04\n",
            "Epoch 10/20\n",
            "132/132 [==============================] - 53s 398ms/step - loss: 0.3771 - acc: 0.8820 - val_loss: 0.8199 - val_acc: 0.7173 - lr: 3.0000e-04\n",
            "Epoch 11/20\n",
            "132/132 [==============================] - 52s 396ms/step - loss: 0.3447 - acc: 0.8968 - val_loss: 0.8022 - val_acc: 0.7409 - lr: 3.0000e-04\n",
            "Epoch 12/20\n",
            "132/132 [==============================] - 52s 392ms/step - loss: 0.3279 - acc: 0.8980 - val_loss: 0.8922 - val_acc: 0.7045 - lr: 3.0000e-04\n",
            "Epoch 13/20\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.2956 - acc: 0.9096\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "132/132 [==============================] - 52s 392ms/step - loss: 0.2956 - acc: 0.9096 - val_loss: 1.1577 - val_acc: 0.6510 - lr: 3.0000e-04\n",
            "Epoch 14/20\n",
            "132/132 [==============================] - 53s 398ms/step - loss: 0.2277 - acc: 0.9306 - val_loss: 0.7364 - val_acc: 0.7687 - lr: 9.0000e-05\n",
            "Epoch 15/20\n",
            "132/132 [==============================] - 52s 391ms/step - loss: 0.2125 - acc: 0.9353 - val_loss: 0.8028 - val_acc: 0.7516 - lr: 9.0000e-05\n",
            "Epoch 16/20\n",
            "132/132 [==============================] - 53s 399ms/step - loss: 0.1904 - acc: 0.9496 - val_loss: 0.6677 - val_acc: 0.8009 - lr: 9.0000e-05\n",
            "Epoch 17/20\n",
            "132/132 [==============================] - 52s 392ms/step - loss: 0.1644 - acc: 0.9572 - val_loss: 0.8184 - val_acc: 0.7816 - lr: 9.0000e-05\n",
            "Epoch 18/20\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.1641 - acc: 0.9572\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "132/132 [==============================] - 52s 390ms/step - loss: 0.1641 - acc: 0.9572 - val_loss: 0.6825 - val_acc: 0.8030 - lr: 9.0000e-05\n",
            "Epoch 19/20\n",
            "132/132 [==============================] - 52s 392ms/step - loss: 0.1347 - acc: 0.9672 - val_loss: 0.7378 - val_acc: 0.8137 - lr: 2.7000e-05\n",
            "Epoch 20/20\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.1392 - acc: 0.9677\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
            "132/132 [==============================] - 52s 393ms/step - loss: 0.1392 - acc: 0.9677 - val_loss: 0.6790 - val_acc: 0.8158 - lr: 2.7000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model9.load_weights(\"best_model_MNV2.hdf5\")\n",
        "preds = model9.predict(X_test)\n",
        "labelled_preds = one_hot_encoder.inverse_transform(preds)\n",
        "pred = pd.DataFrame(labelled_preds, columns =[\"class_id\"])\n",
        "df = pd.read_csv('submission3.csv')\n",
        "df ['class_id']= pred\n",
        "df.to_csv(\"final_submission47.csv\", index=False)"
      ],
      "metadata": {
        "id": "wmiblIWDrDt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXahXAf23bP0"
      },
      "source": [
        "#Majority Voting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Owp_c8lp4EZI"
      },
      "source": [
        "###Get the predictions -> Keep only the 16 predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "d7WVjHYI3erx"
      },
      "outputs": [],
      "source": [
        "#removed \n",
        "#model.load_weights(\"best_model_effB0.hdf5\")\n",
        "#preds = model.predict(X_test) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1tObNiUy3v-j"
      },
      "outputs": [],
      "source": [
        "model1.load_weights(\"best_model_effB1.hdf5\")\n",
        "preds1 = model1.predict(X_test) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pg1Nfx__31aO"
      },
      "outputs": [],
      "source": [
        "model2.load_weights(\"best_model_effB2.hdf5\")\n",
        "preds2 = model2.predict(X_test) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ouZqjAmN3523"
      },
      "outputs": [],
      "source": [
        "model3.load_weights(\"best_model_effB3.hdf5\")\n",
        "preds3 = model3.predict(X_test) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ucLYXDcKWeTl"
      },
      "outputs": [],
      "source": [
        "model31.load_weights(\"best_model_effB3_1.hdf5\")\n",
        "preds31 = model31.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UygBGTMBWeau"
      },
      "outputs": [],
      "source": [
        "#removed \n",
        "#model32.load_weights(\"best_model_effB3_2.hdf5\")\n",
        "#preds32 = model32.predict(X_test) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypFfJBcgWehf"
      },
      "outputs": [],
      "source": [
        "model33.load_weights(\"best_model_effB3_3.hdf5\")\n",
        "preds33 = model33.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yw0SGLLlWen7"
      },
      "outputs": [],
      "source": [
        "model34.load_weights(\"best_model_effB3_4.hdf5\")\n",
        "preds34 = model34.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDil9tM5Wetf"
      },
      "outputs": [],
      "source": [
        "model35.load_weights(\"best_model_effB3_5.hdf5\")\n",
        "preds35 = model35.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95jOenf1WezU"
      },
      "outputs": [],
      "source": [
        "#removed\n",
        "#model36.load_weights(\"best_model_effB3_6.hdf5\")\n",
        "#preds36 = model36.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDtHqp7fWe6L"
      },
      "outputs": [],
      "source": [
        "model37.load_weights(\"best_model_effB3_7.hdf5\")\n",
        "preds37 = model37.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ef1OTZKNWe_0"
      },
      "outputs": [],
      "source": [
        "model38.load_weights(\"best_model_effB3_8.hdf5\")\n",
        "preds38 = model38.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kfcEkUjR39vB"
      },
      "outputs": [],
      "source": [
        "model4.load_weights(\"best_model_effV2B0.hdf5\")\n",
        "preds4 = model4.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tyivwEgKL6oH"
      },
      "outputs": [],
      "source": [
        "model5.load_weights(\"best_model_effV2B1.hdf5\")\n",
        "preds5 = model5.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3yMXF4KMCHf"
      },
      "outputs": [],
      "source": [
        "#removed\n",
        "#model6.load_weights(\"best_model_effV2B2.hdf5\")\n",
        "#preds6 = model6.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v9O1HRLoMG9e"
      },
      "outputs": [],
      "source": [
        "model7.load_weights(\"best_model_effV2B3.hdf5\")\n",
        "preds7 = model7.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42LwsvBKrL5S"
      },
      "outputs": [],
      "source": [
        "model8.load_weights(\"best_model_MN.hdf5\")\n",
        "preds8 = model8.predict(X_test) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sv3L07tnrT2l"
      },
      "outputs": [],
      "source": [
        "#removed\n",
        "#model9.load_weights(\"best_model_MNV2.hdf5\")\n",
        "#preds9 = model9.predict(X_test) "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model14.load_weights('best_model_EfficientNetV2M_50epochs_40.hdf5')\n",
        "preds14 = model14.predict(X_test)"
      ],
      "metadata": {
        "id": "kU0vmVPhmQjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model16.load_weights('best_model_EfficientNetV2M_vol2.hdf5')\n",
        "preds16 = model16.predict(X_test) "
      ],
      "metadata": {
        "id": "pCw6O8EcmQmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#removed\n",
        "#model19.load_weights('best_model_EfficientNetV2M_vol6.hdf5')\n",
        "#preds19 = model19.predict(X_test)"
      ],
      "metadata": {
        "id": "hM73TZDXmQo-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model20.load_weights('best_model_EfficientNetV2M_vol7.hdf5')\n",
        "preds20 = model20.predict(X_test)"
      ],
      "metadata": {
        "id": "qQuaVcS7mRC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Soft voting"
      ],
      "metadata": {
        "id": "A89lDQZMnIAF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.mean( np.array([preds1, preds2, preds3, preds31, preds33, preds34, preds35, preds37, preds38, preds4, preds5, preds7, preds8, preds14, preds16, preds20]), axis=0 )\n",
        "final_labels = one_hot_encoder.inverse_transform(a)\n",
        "final_labels"
      ],
      "metadata": {
        "id": "cxvb1glGnJ1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = pd.DataFrame(final_labels, columns =[\"class_id\"])\n",
        "df = pd.read_csv('submission3.csv')\n",
        "df ['class_id']= pred\n",
        "df.to_csv(\"final_submission_last_day_2.csv.csv\", index=False)"
      ],
      "metadata": {
        "id": "HGUervFMnNzB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}